<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>小刘的杂货铺</title>
  
  <subtitle>In order to be irreplaceable, one must always be different</subtitle>
  <link href="http://chengqian90.com/atom.xml" rel="self"/>
  
  <link href="http://chengqian90.com/"/>
  <updated>2022-03-08T16:23:40.432Z</updated>
  <id>http://chengqian90.com/</id>
  
  <author>
    <name>Chengqian</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>BFD与BGP联动实现路由快速收敛</title>
    <link href="http://chengqian90.com/Linux%E5%86%85%E6%A0%B8/BFD%E4%B8%8EBGP%E8%81%94%E5%8A%A8%E5%AE%9E%E7%8E%B0%E8%B7%AF%E7%94%B1%E5%BF%AB%E9%80%9F%E6%94%B6%E6%95%9B.html"/>
    <id>http://chengqian90.com/Linux%E5%86%85%E6%A0%B8/BFD%E4%B8%8EBGP%E8%81%94%E5%8A%A8%E5%AE%9E%E7%8E%B0%E8%B7%AF%E7%94%B1%E5%BF%AB%E9%80%9F%E6%94%B6%E6%95%9B.html</id>
    <published>2022-01-27T01:57:52.000Z</published>
    <updated>2022-03-08T16:23:40.432Z</updated>
    
    <content type="html"><![CDATA[<h2 id="BFD简介"><a href="#BFD简介" class="headerlink" title="BFD简介"></a>BFD简介</h2><p>为了减小设备故障对业务的影响、提高网络的可用性，设备需要能够尽快检测到与相邻设备间的通信故障，以便能够及时采取措施，从而保证业务继续进行。</p><p>现有的故障检测方法主要包括以下几种：</p><ul><li>硬件检测：例如通过SDH（Synchronous Digital Hierarchy，同步数字体系）告警检测链路故障。硬件检测的优点是可以很快发现故障，但并不是所有介质都能提供硬件检测。</li><li>慢Hello机制：通常采用路由协议中的Hello报文机制。这种机制检测到故障<strong>所需时间为秒级</strong>。对于高速数据传输，例如吉比特速率级，超过1秒的检测时间将导致大量数据丢失；对于时延敏感的业务，例如语音业务，超过1秒的延迟也是不能接受的。并且，这种<strong>机制依赖于路由协议</strong>。</li><li>其他检测机制：不同的协议有时会提供专用的检测机制，但在系统间互联互通时，这样的专用检测机制通常难以部署。</li></ul><span id="more"></span><p>BFD（Bidirectional Forwarding Detection，双向转发检测）是一个通用的、标准化的、介质无关和协议无关的快速故障检测机制，用于检测转发路径的连通状况，保证设备之间能够快速检测到通信故障，以便能够及时采取措施，保证业务持续运行。</p><p>BFD可以为各种上层协议（如路由协议）快速检测两台设备间双向转发路径的故障。相比于慢Hello报文机制的秒级检测，BFD可以提供<strong>毫秒级检测</strong>。</p><h3 id="工作机制"><a href="#工作机制" class="headerlink" title="工作机制"></a>工作机制</h3><p>BFD可以为各上层协议如路由协议、MPLS等统一地快速检测两台路由器间双向转发路径的故障。</p><p>BFD在两台路由器或路由交换机上建立会话，用来监测两台路由器间的双向转发路径，为上层协议服务。</p><p>BFD本身并没有发现机制，而是靠被服务的上层协议通知其该与谁建立会话，会话建立后如果在检测时间内没有收到对端的BFD控制报文则认为发生故障，通知被服务的上层协议，上层协议进行相应的处理。</p><h4 id="工作流程"><a href="#工作流程" class="headerlink" title="工作流程"></a>工作流程</h4><p><img src="/images/BFD%E4%B8%8EBGP%E8%81%94%E5%8A%A8%E5%AE%9E%E7%8E%B0%E8%B7%AF%E7%94%B1%E5%BF%AB%E9%80%9F%E6%94%B6%E6%95%9B/BFD%E4%BC%9A%E8%AF%9D%E5%BB%BA%E7%AB%8B%E6%B5%81%E7%A8%8B%E5%9B%BE.png" alt="BFD会话建立流程"></p><p>BFD会话建立过程：</p><ol><li>上层协议通过自己的Hello机制发现邻居并建立连接；</li><li>上层协议在建立了新的邻居关系时，将邻居的参数及检测参数都（包括目的地址和源地址等）通告给BFD；</li><li>BFD根据收到的参数进行计算并建立邻居。</li></ol><p><img src="/images/BFD%E4%B8%8EBGP%E8%81%94%E5%8A%A8%E5%AE%9E%E7%8E%B0%E8%B7%AF%E7%94%B1%E5%BF%AB%E9%80%9F%E6%94%B6%E6%95%9B/BFD%E5%A4%84%E7%90%86%E7%BD%91%E7%BB%9C%E6%95%85%E9%9A%9C%E6%B5%81%E7%A8%8B%E5%9B%BE.png" alt="BFD处理网络故障流程图"></p><p>当网络出现故障时：</p><ol><li>BFD检测到链路/网络故障；</li><li>拆除BFD邻居会话；</li><li>BFD通知本地上层协议进程BFD邻居不可达；</li><li>本地上层协议中止上层协议邻居关系；</li><li>如果网络中存在备用路径，路由器将选择备用路径。</li></ol><h4 id="检测方式"><a href="#检测方式" class="headerlink" title="检测方式"></a>检测方式</h4><ul><li>单跳检测：BFD单跳检测是指对两个直连系统进行IP连通性检测，这里所说的“单跳”是IP的一跳。</li><li>多跳检测：BFD可以检测两个系统间的任意路径，这些路径可能跨越很多跳，也可能在某些部分发生重叠。</li><li>双向检测：BFD通过在双向链路两端同时发送检测报文，检测两个方向上的链路状态，实现毫秒级的链路故障检测。（BFD检测LSP是一种特殊情况，只需在一个方向发送BFD控制报文，对端通过其他路径报告链路状况。）</li></ul><h4 id="BFD会话工作方式"><a href="#BFD会话工作方式" class="headerlink" title="BFD会话工作方式"></a>BFD会话工作方式</h4><p>BFD会话通过echo报文和控制报文实现。</p><p><strong>echo报文方式</strong></p><p>echo报文封装在<strong>UDP报文</strong>中传送，其UDP目的端口号为<strong>3785</strong>。</p><p>本端发送echo报文建立BFD会话，对链路进行检测。对端不建立BFD会话，只需把收到的echo报文转发回本端。如果在检测时间内没有收到对端转发回的echo报文，则认为会话down。</p><p>当BFD会话工作于echo报文方式时，仅在MPLS TE隧道的场景中支持多跳检测，其他应用的BFD会话仅支持单跳检测，两种应用均不受检测模式的控制。</p><p><strong>控制报文方式</strong></p><p>控制报文封装在<strong>UDP</strong>报文中传送，对于单跳检测其UDP目的端口号为<strong>3784</strong>，对于多跳检测其UDP目的端口号为<strong>4784</strong>。</p><p>链路两端的设备通过控制报文中携带的参数（会话标识符、期望的收发报文最小时间间隔、本端BFD会话状态等）协商建立BFD会话。BFD会话建立后，缺省情况下，系统将以协商的报文收发时间间隔在彼此之间的路径上发送BFD控制报文。</p><h4 id="运行模式"><a href="#运行模式" class="headerlink" title="运行模式"></a>运行模式</h4><p>BFD会话建立前有两种模式：主动模式和被动模式。</p><ul><li><strong>主动模式</strong>：在建立会话前不管是否收到对端发来的BFD控制报文，都会主动发送BFD控制报文；</li><li><strong>被动模式</strong>：在建立会话前不会主动发送BFD控制报文，直到收到对端发送来的控制报文。</li></ul><p>通信双方<strong>至少要有一方运行在主动模式</strong>才能成功建立起BFD会话。</p><p>BFD会话<strong>建立后</strong>有两种模式：异步模式和查询模式。</p><ul><li>异步模式：设备周期性发送BFD控制报文，如果在检测时间内没有收到对端发送的BFD控制报文，则认为会话down。</li><li>查询模式：假定每个系统都有一个独立的方法，确认自己连接到其他系统（比如Hello报文机制、硬件检测机制等）。这样，只要有一个BFD会话建立，系统停止发送BFD控制报文，除非某个系统需要显式地验证连接性。</li></ul><h2 id="报文格式"><a href="#报文格式" class="headerlink" title="报文格式"></a>报文格式</h2><p><img src="/images/BFD%E4%B8%8EBGP%E8%81%94%E5%8A%A8%E5%AE%9E%E7%8E%B0%E8%B7%AF%E7%94%B1%E5%BF%AB%E9%80%9F%E6%94%B6%E6%95%9B/BFD%E6%8A%A5%E6%96%87%E6%A0%BC%E5%BC%8F.png" alt="BFD报文格式"></p><ul><li>Vers：协议的版本号，默认协议版本为1。</li><li>Diag：本地会话最后一次从up状态转换到其他状态的原因。</li><li> State（Sta）：<strong>BFD会话当前状态</strong>，取值为：0代表AdminDown，1代表Down，2代表Init，3代表Up。</li><li>Poll（P）：设置为1，表示发送方请求进行连接确认，或者发送请求参数改变的确认；设置为0，表示发送方不请求确认。</li><li>Final（F）：设置为1，表示发送方响应一个接收到P比特为1的BFD控制报文；设置为0，表示发送方不响应一个接收到P比特为1的BFD控制报文。</li><li>Control Plane Independent（C）：设置为1，表示发送方的BFD实现不依赖于它的控制平面（即，BFD报文在转发平面传输，即使控制平面失效，BFD仍然能够起作用）；设置为0，表示BFD报文在控制平面传输。</li><li>Authentication Present（A）：如果设置为1，则表示控制报文包含认证字段，并且会话是被认证的。</li><li>Demand（D）：设置为1，表示发送方希望操作在<strong>查询模式</strong>；设置为0，表示发送方不区分是否操作在查询模式，或者表示发送方不能操作在查询模式。</li><li>Reserved（R）：在发送时设置为0，在接收时忽略。</li><li>Detect Mult：<strong>检测时间倍数</strong>。即接收方允许发送方发送报文的最大连续丢包数，用来检测链路是否正常。</li><li>Length：BFD控制报文的长度，单位字节。</li><li>My Discriminator：发送方产生的一个唯一的、非0鉴别值，用来区分两个协议之间的多个BFD会话。</li><li>Your Discriminator：接收方收到的鉴别值“My Discriminator”，如果没有收到这个值就返回0。</li><li>Desired Min Tx Interval：发送方发送BFD控制报文时想要采用的最小间隔，单位毫秒。</li><li>Required Min Rx Interval：发送方能够支持的接收两个BFD控制报文之间的间隔，单位毫秒。</li><li>Required Min Echo Rx Interval：发送方能够支持的接收两个BFD回声报文之间的间隔，单位毫秒。如果这个值设置为0，则发送不支持接收BFD回声报文。</li><li>Auth Type：BFD控制报文使用的认证类型。</li><li>Auth Len：认证字段的长度，包括认证类型与认证长度字段。</li></ul><h2 id="BFD支持的应用"><a href="#BFD支持的应用" class="headerlink" title="BFD支持的应用"></a>BFD支持的应用</h2><ul><li>OSPF与BFD联动</li><li>OSPFv3与BFD联动</li><li>IS-IS与BFD联动</li><li>IPv6 IS-IS与BFD联动</li><li>RIP与BFD联动</li><li>静态路由与BFD联动</li><li>BGP与BFD联动</li><li>IPv6 BGP与BFD联动</li><li>MPLS与BFD联动</li><li>Track与BFD联动</li><li>IP快速重路由</li></ul><h2 id="BFD与BGP联动"><a href="#BFD与BGP联动" class="headerlink" title="BFD与BGP联动"></a>BFD与BGP联动</h2><p>操作系统为 centos 7.6，内核为 3.10</p><h3 id="初始化环境"><a href="#初始化环境" class="headerlink" title="初始化环境"></a>初始化环境</h3><p>下载源码、安装依赖</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git clone https://github.com/hzchenyuefang/quagga_bfd.git</span><br><span class="line">yum install -y autoconf automake libtool readline-devel texinfo kernel-devel-$(uname -r) gcc gcc-c++</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd quagga_bfd/</span><br><span class="line">./bootstrap.sh</span><br><span class="line">./configure --enable-user=root --enable-group=root --exec-prefix=/usr/local/ ; make clean;make ;make install</span><br></pre></td></tr></table></figure><blockquote><p>enable-user、enable-group，允许程序以指定用户允许，默认只能quagga用户启动程序</p><p>exec-prefix，程序的执行目录，内部拼接的完整路径 为 $exec-prefix/sbin/</p></blockquote><blockquote><p>No package ‘libcares’ found</p><p>下载文件包：c-ares-1.12.0.tar：<a href="https://c-ares.haxx.se/download/">https://c-ares.haxx.se/download/</a></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">解压，</span><br><span class="line">./configure</span><br><span class="line">make</span><br><span class="line">make install </span><br><span class="line">cp libcares.pc /usr/local/lib/pkgconfig</span><br><span class="line">PKG_CONFIG_PATH=/usr/local/lib/pkgconfig</span><br><span class="line">export PKG_CONFIG_PATH </span><br></pre></td></tr></table></figure></blockquote><h3 id="程序迁移、验证"><a href="#程序迁移、验证" class="headerlink" title="程序迁移、验证"></a>程序迁移、验证</h3><p>将 <strong>bgpd、zebra、bfdd</strong>及<strong>libzebra.so.1</strong>移入相应目录。（/usr/local/sbin , /usr/local/lib/）（<strong>这几个文件一定要是同一个版本！！！</strong>）</p><p><strong>创建bfdd 配置文件</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">cat /usr/local/etc/bfdd.conf</span><br><span class="line">!</span><br><span class="line">! BFDd sample configuratin file</span><br><span class="line">!</span><br><span class="line">! bfdd.conf</span><br><span class="line">!</span><br><span class="line">hostname bfdd</span><br><span class="line">password zebra</span><br><span class="line">!</span><br><span class="line">!log file zapd.log</span><br><span class="line">!</span><br><span class="line">log file /var/log/quagga/bfdd.log</span><br><span class="line">!</span><br></pre></td></tr></table></figure><p><strong>修改 bgpd 配置，新增bfd neighbor信息，使能bfd</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">neighbor 100.66.122.1 fall-over bfd</span><br><span class="line"></span><br><span class="line">neighbor 100.66.123.1 fall-over bfd</span><br></pre></td></tr></table></figure><p><strong>启动进程</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> <span class="built_in">kill</span> `pidof bfdd`; <span class="built_in">kill</span> `pidof zebra`; <span class="built_in">kill</span> `pidof bgpd`</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> zebra -d -f /usr/<span class="built_in">local</span>/etc/zebra.conf; bfdd -d -f /usr/<span class="built_in">local</span>/etc/bfdd.conf ;bgpd -d -f /usr/<span class="built_in">local</span>/etc/bgpd.conf ;</span></span><br></pre></td></tr></table></figure><p><strong>查看进程状态</strong></p><ol><li><p>查看 /var/log/quagga/ 下3个日志文件，保证无报错；</p></li><li><p>查看bfd 邻居是否建立</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">telnet 127.0.0.1 2609 // 密码在bfdd配置中</span><br><span class="line"><span class="meta">&gt;</span><span class="bash"> show bfd neighbors</span></span><br></pre></td></tr></table></figure></li><li><p>查看bgp邻居是否建立</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">telnet 127.0.0.1 2605 // 密码在bgpd配置中</span><br><span class="line"><span class="meta">&gt;</span><span class="bash"> show ip bgp neighbors</span></span><br></pre></td></tr></table></figure></li></ol><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://www.jianshu.com/p/11ce9b787f65">BGP配置BFD链路检测feature</a></p><p><a href="http://www.h3c.com/cn/d_201006/676935_30003_0.htm">华三-BFD技术介绍</a></p><p><a href="https://www.bianchengquan.com/article/179317.html">双向链路检测（BFD）之静态路由篇</a></p><p><a href="https://blog.csdn.net/fuyuande/article/details/81253672">BFD (双向转发检测) 协议简介与开发</a></p><p><a href="https://wiki.gentoo.org/wiki/Frr">Quagga</a></p><p><a href="https://zhiliao.h3c.com/questions/dispcont/104109">bgp与bfd</a></p>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;BFD简介&quot;&gt;&lt;a href=&quot;#BFD简介&quot; class=&quot;headerlink&quot; title=&quot;BFD简介&quot;&gt;&lt;/a&gt;BFD简介&lt;/h2&gt;&lt;p&gt;为了减小设备故障对业务的影响、提高网络的可用性，设备需要能够尽快检测到与相邻设备间的通信故障，以便能够及时采取措施，从而保证业务继续进行。&lt;/p&gt;
&lt;p&gt;现有的故障检测方法主要包括以下几种：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;硬件检测：例如通过SDH（Synchronous Digital Hierarchy，同步数字体系）告警检测链路故障。硬件检测的优点是可以很快发现故障，但并不是所有介质都能提供硬件检测。&lt;/li&gt;
&lt;li&gt;慢Hello机制：通常采用路由协议中的Hello报文机制。这种机制检测到故障&lt;strong&gt;所需时间为秒级&lt;/strong&gt;。对于高速数据传输，例如吉比特速率级，超过1秒的检测时间将导致大量数据丢失；对于时延敏感的业务，例如语音业务，超过1秒的延迟也是不能接受的。并且，这种&lt;strong&gt;机制依赖于路由协议&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;其他检测机制：不同的协议有时会提供专用的检测机制，但在系统间互联互通时，这样的专用检测机制通常难以部署。&lt;/li&gt;
&lt;/ul&gt;</summary>
    
    
    
    
    <category term="tag" scheme="http://chengqian90.com/tags/tag/"/>
    
  </entry>
  
  <entry>
    <title>PXE装机简介</title>
    <link href="http://chengqian90.com/%E6%9D%82%E8%B0%88/PXE%E8%A3%85%E6%9C%BA%E7%AE%80%E4%BB%8B.html"/>
    <id>http://chengqian90.com/%E6%9D%82%E8%B0%88/PXE%E8%A3%85%E6%9C%BA%E7%AE%80%E4%BB%8B.html</id>
    <published>2022-01-15T07:22:33.000Z</published>
    <updated>2022-03-08T16:23:40.436Z</updated>
    
    <content type="html"><![CDATA[<h1 id="什么是PXE"><a href="#什么是PXE" class="headerlink" title="什么是PXE"></a>什么是PXE</h1><p>PXE（ <code>Preboot Execution Environment</code>，预启动执行环境）是由Intel设计的一种网络协议，可使计算机通过网络启动安装系统，同时也是一种使用网络接口启动计算机的机制，其不依赖本地数据存储设备或本地已安装的系统。协议分为<strong>client端和server端</strong>，PXE client在网卡的boot ROM中启动，当计算机开机引导时，BIOS把PXE client调入内存执行，并显示出命令菜单，经用户选择需要安装的系统后，PXE client将放置在远端的操作系统通过网络下载到本地运行。</p><span id="more"></span><ul><li>服务器，运行 DHCP服务器、TFTP 服务器从服务器提供引导文件，同时 HTTP、FTP 或者 NFS 服务器托管安装映射。</li><li>客户端，要安装系统的机器。安装开始时，客户端会查询 DHCP 服务器，从 TFTP 服务器中获取引导文件，并从 HTTP、FTP 或者 NFS 服务器下载安装映象。</li></ul><h1 id="PXE的模式"><a href="#PXE的模式" class="headerlink" title="PXE的模式"></a>PXE的模式</h1><p>PXE装机有legacy、UEFI两种模式，又细分为IPV4 legacy、IPV4 UEFI、IPV6 legacy、IPV6 UEFI。</p><h2 id="Legacy模式"><a href="#Legacy模式" class="headerlink" title="Legacy模式"></a>Legacy模式</h2><p>传统的引导模式，Legacy引导模式对系统的兼容性比较好，支持32位、64位系统。</p><p>Legacy模式使用MBR磁盘格式，它的特点：</p><ul><li><strong>系统只能安装在MBR格式磁盘上</strong>；</li><li>只支持最多4个主分区；</li><li>不支持2TB以上的硬盘；</li><li>在单一的MBR 中只能存储一个操作系统的引导记录。</li></ul><blockquote><p>Legacy BIOS 最早来自IBM，当时各个厂商都想用自己的标准，这也导致它封闭，神秘，充满各种坑爹预设和祖传代码，也就微软这样的大厂才能勉强统一接口，这也是Legacy将被取代的重要原因。 </p></blockquote><h2 id="UEFI模式"><a href="#UEFI模式" class="headerlink" title="UEFI模式"></a>UEFI模式</h2><p>目前主流的引导模式，相较于Legacy， UEFI的可编程性更好，可扩展性更好，性能更高，安全性更高。UEFI模式使用GPT磁盘格式（GUID分区表），它的特点：</p><ul><li><strong>系统只能安装在GPT格式磁盘上</strong>；</li><li>GPT支持最多128个分区；</li><li>GPT突破2TB限制，支持最高18EB；</li><li>UEFI提供安全引导功能，防止病毒在引导时加载；</li><li>UEFI BIOS图形界面更直观，交互性更强，支持鼠标操作和多国语言；</li><li>开机时没有自检环节，启动速度可以快一点。</li></ul><h1 id="启动过程"><a href="#启动过程" class="headerlink" title="启动过程"></a>启动过程</h1><p>以legacy引导模式为例，其启动过程需要几个文件：</p><ul><li><code>pxelinux.0</code>：计算机自展引导程序(bootstrap),负责系统引导和启动，作用类似于BIOS，会调用PXE相关配置文件</li><li><code>pxelinux.cfg</code>：文件夹，存放PXE配置文件</li><li> <code>vmlinuz</code>： linux的内核文件，可以被引导程序加载，从而启动Linux系统</li><li><code>initrd.img</code>：boot loader initialized RAM disk的缩写，作为根文件系统加载各种模块、驱动、服务等，网卡驱动就包含在该文件中。</li></ul><p>具体启动过程如下</p><ol><li>客户端(Client)的BIOS支持网卡启动，且网卡具有PXE <code>ROM</code>芯片</li><li>服务端(PXE Server)至少有 <code>dhcp</code>，<code>tftp</code>，<code>nfs</code>服务且为开启状态；</li><li>BIOS通过PXE Client调入内存执行</li><li>客户机向网络中请求DHCP服务器获取动态IP</li><li>DHCP服务器下发IP、引导文件位置、TFTP服务器地址</li><li>客户端向tftp.server请求<code>bootstrap</code>文件，tftp.server收到请求向客户端发送bootstrap文件 –&gt;<code>pxelinux.0</code></li><li>客户端收到pxelinux.0文件后执行文件</li><li>根据执行文件向tftp.server请求pxelinux.0的配置文件pxelinux.cfg（tftpboot/pxelinux.cfg/default，配置文件包含vmlinux、initrd.img、ks文件位置信息）</li><li>客户机读取<code>default</code>文件，等待用户选择安装系统后，客户端向tftp.server发出提供内核文件<code>vmlinuz</code>和根文件系统<code>initrd.img</code>请求</li><li>tftp.server收到客户端请求，提供vmlinuz和initrd.img</li><li>客户端收到文件，启动内核映像文件，内核挂载initrd.img，并执行挂载各种各样的模块。</li></ol><blockquote><p>题外话</p><p>由于PXE仅支持tftp协议，仅支持tftp传输数据，性能差，灵活性也差，于是有了gpxe这个项目。</p><p>gpxe是一种兼容pxe的实现，并且在pxe之上增加了许多特性，例如通过http/ftp等协议传输数据。</p><p>gpxe原先使用的域名的拥有者突然收回了该域名的使用权，于是这些人fork出去做了ipxe，gpxe现在已经不再开发，ipxe开发非常活跃。</p><p>具体可以参考 <a href="https://groups.google.com/g/ustc_lug/c/P2jOQ5F4EKY?pli=1">https://groups.google.com/g/ustc_lug/c/P2jOQ5F4EKY?pli=1</a></p></blockquote><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="https://www.jianshu.com/p/6a44b0a6b87b">PXE的部署过程</a></p><p><a href="https://www.bilibili.com/read/cv6107167">系统启动方式：Legacy、UEFI和Legacy and UEFI</a></p><p><a href="https://wiki.fogproject.org/wiki/index.php/BIOS_and_UEFI_Co-Existence">BIOS and UEFI Co-Existence</a></p><p><a href="https://stackoverflow.com/questions/58921055/pxe-boot-arch-field-dhcp-option-93">PXE Boot Arch Field DHCP Option 93</a></p><p><a href="https://help.univention.com/t/how-to-configure-a-dhcp-switch-for-uefi-and-non-uefi-boot/9931">How-to: Configure a DHCP switch for UEFI and non-UEFI boot</a></p><p><a href="https://www.redhat.com/sysadmin/pxe-boot-uefi">How to set up PXE boot for UEFI hardware</a></p><p><a href="https://gal.vin/posts/old/pxe-booting-for-uefi-bios/">PXE Booting with WDS for UEFI and BIOS Devices</a></p><p><a href="https://www.experts-exchange.com/articles/2978/PXEClient-dhcp-options-60-66-and-67-what-are-they-for-Can-I-use-PXE-without-it.html">PXEClient, dhcp options 60, 66 and 67, what are they for? Can I use PXE without it ?</a></p><p><a href="https://www.cxybb.com/article/Future_promise/108287038">PXE 网络安装 CentOS 7</a></p><p><a href="https://groups.google.com/g/ustc_lug/c/P2jOQ5F4EKY?pli=1">原先的 PXE 引导中，两阶段的 PXELINUX 的区别，以及 iPXE 的用途？</a></p>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;什么是PXE&quot;&gt;&lt;a href=&quot;#什么是PXE&quot; class=&quot;headerlink&quot; title=&quot;什么是PXE&quot;&gt;&lt;/a&gt;什么是PXE&lt;/h1&gt;&lt;p&gt;PXE（ &lt;code&gt;Preboot Execution Environment&lt;/code&gt;，预启动执行环境）是由Intel设计的一种网络协议，可使计算机通过网络启动安装系统，同时也是一种使用网络接口启动计算机的机制，其不依赖本地数据存储设备或本地已安装的系统。协议分为&lt;strong&gt;client端和server端&lt;/strong&gt;，PXE client在网卡的boot ROM中启动，当计算机开机引导时，BIOS把PXE client调入内存执行，并显示出命令菜单，经用户选择需要安装的系统后，PXE client将放置在远端的操作系统通过网络下载到本地运行。&lt;/p&gt;</summary>
    
    
    
    
    <category term="pxe" scheme="http://chengqian90.com/tags/pxe/"/>
    
    <category term="legacy" scheme="http://chengqian90.com/tags/legacy/"/>
    
    <category term="uefi" scheme="http://chengqian90.com/tags/uefi/"/>
    
  </entry>
  
  <entry>
    <title>Linux常用命令</title>
    <link href="http://chengqian90.com/Linux%E5%B7%A5%E5%85%B7/Linux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4.html"/>
    <id>http://chengqian90.com/Linux%E5%B7%A5%E5%85%B7/Linux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4.html</id>
    <published>2021-07-25T11:57:52.000Z</published>
    <updated>2022-03-08T16:51:56.506Z</updated>
    
    <content type="html"><![CDATA[<p>本文仅记录作者在工作中感觉比较好用或者没用过的Linux命令，并对其做简要说明。</p><p>TODO</p><span id="more"></span><p><a href="https://linuxtools-rst.readthedocs.io/zh_CN/latest/base/index.html">https://linuxtools-rst.readthedocs.io/zh_CN/latest/base/index.html</a></p><p><a href="https://github.com/me115/linuxtools_rst/blob/master/advance/01_program_build.rst">https://github.com/me115/linuxtools_rst/blob/master/advance/01_program_build.rst</a></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;本文仅记录作者在工作中感觉比较好用或者没用过的Linux命令，并对其做简要说明。&lt;/p&gt;
&lt;p&gt;TODO&lt;/p&gt;</summary>
    
    
    
    <category term="Linux工具" scheme="http://chengqian90.com/categories/Linux%E5%B7%A5%E5%85%B7/"/>
    
    
    <category term="Linux常用命令" scheme="http://chengqian90.com/tags/Linux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/"/>
    
  </entry>
  
  <entry>
    <title>网络性能测试方式</title>
    <link href="http://chengqian90.com/Linux%E5%B7%A5%E5%85%B7/%E7%BD%91%E7%BB%9C%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E6%96%B9%E5%BC%8F.html"/>
    <id>http://chengqian90.com/Linux%E5%B7%A5%E5%85%B7/%E7%BD%91%E7%BB%9C%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E6%96%B9%E5%BC%8F.html</id>
    <published>2021-07-14T01:57:52.000Z</published>
    <updated>2022-03-15T03:18:43.751Z</updated>
    
    <content type="html"><![CDATA[<p>测试设备物理性能的工具比较多，比较常用的有netperf、iperf3，以及qperf这三种，下面对这三种工具使用方式进行简要说明。</p><blockquote><p>被测机：需要做压力测试网络性能的服务器，可作为netperf测试中的client端（发送端）或server端（接收端）。</p><p>辅助机：用于netperf/iperf3测试中的client端（发送端）或server端（接收端），用于与被测机建立连接，传递测试数据。</p></blockquote><span id="more"></span><blockquote><p>网卡多队列：需分别在被测机和辅助云服务器上开启网卡多队列。</p><p><strong>ethtool -l eth0 | grep -i Pre -A 5 | grep Combined</strong>    -&gt; 检查服务器支持的队列个数</p><p><strong>ethtool -L eth0 combined X</strong>  -&gt; 设置队列数，开启网卡多队列功能，X表示上一个命令查询的队列数</p></blockquote><h2 id="netperf"><a href="#netperf" class="headerlink" title="netperf"></a>netperf</h2><p>netperf是一个基于client-server模式的网络测试工具，可以测量TCP和UDP传输的吞吐量、时延、CPU占用率等性能参数。它可以测试以下几种模式的TCP核UDP网络性能：</p><ul><li>TCP_STREAM:client端向server端发送批量TCP数据</li><li>UDP_STREAM：client端向server端发送批量UDP数据</li><li>TCP_RR和TCP_CRR：前者是在同一个连接中进行多次request和response请求，后者是每次请求新建一个连接（HTTP）</li><li>UDP_RR：使用UDP进行request和response请求</li></ul><blockquote><p>不同子网下的主机使用netperf时连接超时。netperf在设计时关闭了此功能，需要通过额外参数进行打开‘-R 1’。</p></blockquote><h3 id="安装方式"><a href="#安装方式" class="headerlink" title="安装方式"></a>安装方式</h3><p><strong>源码安装</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">yum -y install unzip gcc gcc-c++</span><br><span class="line">wget --no-check-certificate https://github.com/HewlettPackard/netperf/archive/refs/tags/netperf-2.7.0.zip</span><br><span class="line"></span><br><span class="line">unzip netperf-2.7.0.zip</span><br><span class="line"></span><br><span class="line">cd netperf-netperf-2.7.0/</span><br><span class="line">./configure &amp;&amp; make &amp;&amp; make install</span><br></pre></td></tr></table></figure><p><strong>rpm安装</strong></p><p>例如，对于centos7系统</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">wget http://repo.iotti.biz/CentOS/7/x86_64/netperf-2.7.0-1.el7.lux.x86_64.rpm</span><br><span class="line"></span><br><span class="line">rpm -i netperf-2.7.0-1.el7.lux.x86_64.rpm</span><br></pre></td></tr></table></figure><h3 id="常用参数"><a href="#常用参数" class="headerlink" title="常用参数"></a>常用参数</h3><table> <tr>    <td>工具名称</td>        <td>工具说明</td>    <td>主要参数</td>        <td>参数说明</td>  </tr>  <tr>        <td rowspan="4">netserver</td>         <td rowspan="4">接收端工具（Server 端）</td>         <td>-p</td>         <td>监听的端口号</td>  </tr>  <tr>    <td>-D</td>    <td>不在后台运行</td>  </tr>  <tr>    <td>-T</td>    <td>netserver/netperf绑定到cpu or lcpu</td>  </tr>  <tr>        <td>-4</td>    <td>IPv4协议栈</td>  </tr>  <tr>        <td rowspan="5">netperf</td>         <td rowspan="5">发送端工具（Client 端）</td>         <td>-H</td>         <td>指定netserver的hostname或者IP</td>  </tr>  <tr>         <td>-p</td>         <td>指定端口号</td>  </tr>  <tr>         <td>-l</td>         <td>指定运行时间</td>  </tr>  <tr>         <td>-t</td>         <td>指定发包协议类型：TCP_STREAM或UDP_STREAM。建议使用UDP_STREAM</td>  </tr>  <tr>         <td>-m</td>         <td>指定数据包大小。<br>测试PPS时，该值为 1。<br>测试BPS（bit per second）时，该值为1400。</td>  </tr></table><blockquote><p>关于Markdown表格单元格合并，可参考 <a href="https://blog.csdn.net/qq_42711815/article/details/89257489">https://blog.csdn.net/qq_42711815/article/details/89257489</a></p></blockquote><h3 id="使用场景"><a href="#使用场景" class="headerlink" title="使用场景"></a>使用场景</h3><h4 id="TCP带宽测试"><a href="#TCP带宽测试" class="headerlink" title="TCP带宽测试"></a>TCP带宽测试</h4><p>发包方向 ： netperf -&gt; netserver</p><p>在辅助机执行以下命令，启动netserver进程</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">netserver -p 12001</span><br></pre></td></tr></table></figure><p>在测试机中执行以下命令，启动netperf进程，指定到辅助机的netserver端口</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">netperf -H 192.168.2.11 -p 12001 -t TCP_STREAM -l 300 -- -m 1440 &amp;</span><br></pre></td></tr></table></figure><blockquote><p>对于需要测试收/发包带宽的，最好启动多个进程发包。（或者多机部署）</p></blockquote><p><img src="/images/Linux%E5%B7%A5%E5%85%B7/netperf-result.png" alt="netperf-result"></p><blockquote><p>如果有多个节点测试被测试机，可以被测试机上利用sar命令来统计 ，<strong>sar -n DEV 1 60</strong></p><p>安装方式为 <strong>yum -y install sysstat</strong></p></blockquote><h2 id="iperf3"><a href="#iperf3" class="headerlink" title="iperf3"></a>iperf3</h2><h3 id="安装方式-1"><a href="#安装方式-1" class="headerlink" title="安装方式"></a>安装方式</h3><p><strong>源码安装</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">yum -y install unzip gcc gcc-c++</span><br><span class="line">wget --no-check-certificate https://codeload.github.com/esnet/iperf/zip/master -O iperf3.zip</span><br><span class="line"></span><br><span class="line">unzip iperf3.zip</span><br><span class="line">cd iperf-master/</span><br><span class="line"></span><br><span class="line">./configure &amp;&amp; make &amp;&amp; make install</span><br></pre></td></tr></table></figure><p><strong>rpm安装</strong></p><p>例如，对于centos7系统</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">wget --inet4-only  http://mirror.centos.org/centos/7/os/x86_64/Packages/iperf3-3.1.7-2.el7.x86_64.rpm</span><br><span class="line"></span><br><span class="line">rpm -i iperf3-3.1.7-2.el7.x86_64.rpm</span><br></pre></td></tr></table></figure><h3 id="常用参数-1"><a href="#常用参数-1" class="headerlink" title="常用参数"></a>常用参数</h3><table> <tr>    <td>工具名称</td>        <td>工具说明</td>    <td>主要参数</td>        <td>参数说明</td>  </tr>  <tr>        <td rowspan="8">iperf3</td>         <td rowspan="8">收发一体</td>         <td>-s</td>         <td>表示作为server端接收包</td>  </tr>  <tr>    <td>-i</td>    <td>间隔多久输出信息流量信息，默认单位为秒</td>  </tr>  <tr>    <td>-p</td>    <td>指定服务的监听端口</td>  </tr>  <tr>        <td>-u</td>    <td>表示采用UDP协议发送报文，不带该参数表示采用TCP协议</td>  </tr>  <tr>                 <td>-i</td>         <td>表示包大小，默认单位为 Byte。通常测试 PPS 的时候该值为16，测试BPS时该值为1400</td>  </tr>  <tr>         <td>-b</td>         <td>设定流量带宽，可选单位包括：k/m/g</td>  </tr>  <tr>         <td>-t</td>         <td>流量的持续时间，默认单位为秒</td>  </tr>  <tr>         <td>-A</td>         <td>CPU亲和性，可以将具体的iperf3进程绑定对应编号的逻辑CPU，避免iperf进程在不同的CPU间调度</td>  </tr> </table><h3 id="使用场景-1"><a href="#使用场景-1" class="headerlink" title="使用场景"></a>使用场景</h3><h4 id="UDP-PPS测试"><a href="#UDP-PPS测试" class="headerlink" title="UDP PPS测试"></a>UDP PPS测试</h4><p>在辅助机执行以下命令，以启动server进程</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">iperf3 -s -p 12001 &amp;</span><br></pre></td></tr></table></figure><p>在测试机上中执行如下命令，启动client进程</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">iperf3 -c 192.168.2.11 -p 12001 -u -b 100M -t 300 -l 16 -A 0 &amp;</span><br></pre></td></tr></table></figure><p>或者 </p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">iperf3 -s -p 12001 -A 0 -i 60 &amp;     -&gt; server端绑定多个核，测试收包性能</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">iperf3 -c 192.168.2.10 -p 12001 -u -b 100M -t 300 -l 16 -A 0 &amp;</span><br></pre></td></tr></table></figure><p><img src="/images/Linux%E5%B7%A5%E5%85%B7/iperf3-result.png" alt="iperf3-result"></p><h2 id="qperf"><a href="#qperf" class="headerlink" title="qperf"></a>qperf</h2><p>qperf 可以用来测试两个节点之间的带宽（bandwidth）和延迟（latency），不仅仅可以用来测试 TCP/IP 协议的性能指标，还可以用来测试 RDMA 传输的指标。使用方法是：一个节点运行 qperf 作为服务端，另一个节点则运行 qperf 作为客户端，与服务端建立连接之后打流，获取带宽和延迟等数据。</p><h3 id="安装方式-2"><a href="#安装方式-2" class="headerlink" title="安装方式"></a>安装方式</h3><p><strong>YUM安装</strong></p><p>例如，对于centos7系统</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install qperf</span><br></pre></td></tr></table></figure><h3 id="使用场景-2"><a href="#使用场景-2" class="headerlink" title="使用场景"></a>使用场景</h3><p><strong>服务端</strong></p><p>典型的用法不带任何参数，直接运行 <code>qperf</code> 命令即启动服务端进程，等待客户端的连接，默认监听端口为 19765。如果想指定监听端口可以增加参数 <code>--listen_port xxx</code>，此时要保证客户端也要指定该端口号建立连接。</p><p><strong>客户端</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">qperf SERVERNODE [OPTIONS] TESTS</span><br></pre></td></tr></table></figure><p>其中，</p><ol><li><code>SERVERNODE</code> 为服务端的地址</li><li><code>TESTS</code> 为需要测试的指标，使用帮助命令 <code>qperf --help tests</code> 可以查看到 qperf 支持的所有测量指标，可以一条命令中带多个测试项，这里介绍常用的有：<ul><li><code>tcp_bw</code> —— TCP流带宽</li><li><code>tcp_lat</code> —— TCP流延迟</li><li><code>udp_bw</code> —— UDP流带宽</li><li><code>udp_lat</code> —— UDP流延迟</li><li><code>conf</code> —— 显示两端主机配置</li></ul></li><li><code>OPTIONS</code> 是可选字段，使用帮助命令 <code>qperf --help options</code> 可以查看所有支持的可选参数，这里介绍常用的参数：<ul><li><code>--time/-t</code> —— 测试持续的时间，默认为 2s</li><li><code>--msg_size/-m</code> —— 设置报文的大小，默认测带宽是为 64KB，测延迟是为 1B</li><li><code>--listen_port/-lp</code> —— 设置与服务端建立连接的端口号，默认为 19765</li><li><code>--verbose/-v</code> —— 提供更多输出的信息，可以更多尝试一下 <code>-vc</code>、<code>-vs</code>、<code>-vt</code>、<code>-vu</code> 等等</li></ul></li></ol><p>例如：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> qperf 192.168.0.8 -t 10 -vvu tcp_lat udp_lat conf</span></span><br><span class="line">tcp_lat:</span><br><span class="line">    latency   =  57.2 us</span><br><span class="line">    msg_size  =     1 bytes</span><br><span class="line">    time      =    10 sec</span><br><span class="line">    timeout   =     5 sec</span><br><span class="line">udp_lat:</span><br><span class="line">    latency   =  10 sec</span><br><span class="line">    msg_size  =   1 bytes</span><br><span class="line">    time      =  10 sec</span><br><span class="line">    timeout   =   5 sec</span><br><span class="line">conf:</span><br><span class="line">    loc_node   =  performance-north-south-000-0003</span><br><span class="line">    loc_cpu    =  8 Cores: Intel Xeon Gold 6161 @ 2.20GHz</span><br><span class="line">    loc_os     =  Linux 3.10.0-514.10.2.el7.x86_64</span><br><span class="line">    loc_qperf  =  0.4.9</span><br><span class="line">    rem_node   =  performance-north-south-000-0001.novalocal</span><br><span class="line">    rem_cpu    =  8 Cores: Intel Xeon Gold 6161 @ 2.20GHz</span><br><span class="line">    rem_os     =  Linux 3.10.0-514.10.2.el7.x86_64</span><br><span class="line">    rem_qperf  =  0.4.9</span><br></pre></td></tr></table></figure><h2 id="进阶使用方法"><a href="#进阶使用方法" class="headerlink" title="进阶使用方法"></a>进阶使用方法</h2><p>qperf 有个比较酷的功能可以循环 loop 遍历测试，这对于摸底网络性能找到最优参数非常有帮助，利用的是其中一个 OPTIONS 参数，使用说明可以参数帮助文档：</p><blockquote><p>–loop Var:Init:Last:Incr (-oo) Run a test multiple times sequencing through a series of values. Var is the loop variable; Init is the initial value; Last is the value it must not exceed and Incr is the increment. It is useful to set the –verbose_used (-vu) option in conjunction with this option.</p></blockquote><p>通常可以调优的 <code>Var</code> 设为 <code>msg_size</code>，看下下面的命令输出结果就一目了然了：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> qperf 192.168.0.8 -oo msg_size:1:64K:*2 -vu tcp_bw tcp_lat</span></span><br><span class="line">tcp_bw:</span><br><span class="line">    bw        =  2.17 MB/sec</span><br><span class="line">    msg_size  =     1 bytes</span><br><span class="line">tcp_bw:</span><br><span class="line">    bw        =  4.13 MB/sec</span><br><span class="line">    msg_size  =     2 bytes</span><br><span class="line">tcp_bw:</span><br><span class="line">    bw        =  7.82 MB/sec</span><br><span class="line">    msg_size  =     4 bytes</span><br><span class="line">tcp_bw:</span><br><span class="line">    bw        =  14.3 MB/sec</span><br><span class="line">    msg_size  =     8 bytes</span><br><span class="line">tcp_bw:</span><br><span class="line">    bw        =  25.8 MB/sec</span><br><span class="line">    msg_size  =    16 bytes</span><br><span class="line">tcp_bw:</span><br><span class="line">    bw        =  42.4 MB/sec</span><br><span class="line">    msg_size  =    32 bytes</span><br><span class="line">tcp_bw:</span><br><span class="line">    bw        =  63.4 MB/sec</span><br><span class="line">    msg_size  =    64 bytes</span><br><span class="line">tcp_bw:</span><br><span class="line">    bw        =  83.3 MB/sec</span><br><span class="line">    msg_size  =   128 bytes</span><br><span class="line">tcp_bw:</span><br><span class="line">    bw        =  388 MB/sec</span><br><span class="line">    msg_size  =  256 bytes</span><br><span class="line">tcp_bw:</span><br><span class="line">    bw        =  816 MB/sec</span><br><span class="line">    msg_size  =  512 bytes</span><br><span class="line">tcp_bw:</span><br><span class="line">    bw        =  941 MB/sec</span><br><span class="line">    msg_size  =    1 KiB (1,024)</span><br><span class="line">tcp_bw:</span><br><span class="line">    bw        =  967 MB/sec</span><br><span class="line">    msg_size  =    2 KiB (2,048)</span><br><span class="line">tcp_bw:</span><br><span class="line">    bw        =  980 MB/sec</span><br><span class="line">    msg_size  =    4 KiB (4,096)</span><br><span class="line">tcp_bw:</span><br><span class="line">    bw        =  1.01 GB/sec</span><br><span class="line">    msg_size  =     8 KiB (8,192)</span><br><span class="line">tcp_bw:</span><br><span class="line">    bw        =  950 MB/sec</span><br><span class="line">    msg_size  =   16 KiB (16,384)</span><br><span class="line">tcp_bw:</span><br><span class="line">    bw        =  1.01 GB/sec</span><br><span class="line">    msg_size  =    32 KiB (32,768)</span><br><span class="line">tcp_bw:</span><br><span class="line">    bw        =  986 MB/sec</span><br><span class="line">    msg_size  =   64 KiB (65,536)</span><br><span class="line">tcp_lat:</span><br><span class="line">    latency   =  61.5 us</span><br><span class="line">    msg_size  =     1 bytes</span><br><span class="line">tcp_lat:</span><br><span class="line">    latency   =  58.2 us</span><br><span class="line">    msg_size  =     2 bytes</span><br><span class="line">tcp_lat:</span><br><span class="line">    latency   =  57.5 us</span><br><span class="line">    msg_size  =     4 bytes</span><br><span class="line">tcp_lat:</span><br><span class="line">    latency   =  57.6 us</span><br><span class="line">    msg_size  =     8 bytes</span><br><span class="line">tcp_lat:</span><br><span class="line">    latency   =  57.9 us</span><br><span class="line">    msg_size  =    16 bytes</span><br><span class="line">tcp_lat:</span><br><span class="line">    latency   =  61.7 us</span><br><span class="line">    msg_size  =    32 bytes</span><br><span class="line">tcp_lat:</span><br><span class="line">    latency   =  58.6 us</span><br><span class="line">    msg_size  =    64 bytes</span><br><span class="line">tcp_lat:</span><br><span class="line">    latency   =  58.3 us</span><br><span class="line">    msg_size  =   128 bytes</span><br><span class="line">tcp_lat:</span><br><span class="line">    latency   =  58.8 us</span><br><span class="line">    msg_size  =   256 bytes</span><br><span class="line">tcp_lat:</span><br><span class="line">    latency   =   60 us</span><br><span class="line">    msg_size  =  512 bytes</span><br><span class="line">tcp_lat:</span><br><span class="line">    latency   =  61.8 us</span><br><span class="line">    msg_size  =     1 KiB (1,024)</span><br><span class="line">tcp_lat:</span><br><span class="line">    latency   =  72.8 us</span><br><span class="line">    msg_size  =     2 KiB (2,048)</span><br><span class="line">tcp_lat:</span><br><span class="line">    latency   =  75.6 us</span><br><span class="line">    msg_size  =     4 KiB (4,096)</span><br><span class="line">tcp_lat:</span><br><span class="line">    latency   =  103 us</span><br><span class="line">    msg_size  =    8 KiB (8,192)</span><br><span class="line">tcp_lat:</span><br><span class="line">    latency   =  132 us</span><br><span class="line">    msg_size  =   16 KiB (16,384)</span><br><span class="line">tcp_lat:</span><br><span class="line">    latency   =  163 us</span><br><span class="line">    msg_size  =   32 KiB (32,768)</span><br><span class="line">tcp_lat:</span><br><span class="line">    latency   =  313 us</span><br><span class="line">    msg_size  =   64 KiB (65,536)</span><br></pre></td></tr></table></figure><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://support.huaweicloud.com/ecs_faq/zh-cn_topic_0115820205.html#ZH-CN_TOPIC_0115820205__li162918018139">网络性能测试方法</a></p><p><a href="https://www.alibabacloud.com/help/zh/doc-detail/55757.htm#test">网络性能测试方法</a></p><p><a href="http://hazirguo.github.io/articles/2018/network_performace_tool_qperf.html">网络性能测试工具 qperf 简介</a></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;测试设备物理性能的工具比较多，比较常用的有netperf、iperf3，以及qperf这三种，下面对这三种工具使用方式进行简要说明。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;被测机：需要做压力测试网络性能的服务器，可作为netperf测试中的client端（发送端）或server端（接收端）。&lt;/p&gt;
&lt;p&gt;辅助机：用于netperf/iperf3测试中的client端（发送端）或server端（接收端），用于与被测机建立连接，传递测试数据。&lt;/p&gt;
&lt;/blockquote&gt;</summary>
    
    
    
    <category term="Linux工具" scheme="http://chengqian90.com/categories/Linux%E5%B7%A5%E5%85%B7/"/>
    
    
    <category term="netperf" scheme="http://chengqian90.com/tags/netperf/"/>
    
    <category term="iperf3" scheme="http://chengqian90.com/tags/iperf3/"/>
    
    <category term="qperf" scheme="http://chengqian90.com/tags/qperf/"/>
    
  </entry>
  
  <entry>
    <title>学习Kubernetes系列5——服务、负载均衡、联网</title>
    <link href="http://chengqian90.com/%E5%AE%B9%E5%99%A8/%E5%AD%A6%E4%B9%A0Kubernetes%E7%B3%BB%E5%88%975%E2%80%94%E2%80%94%E6%9C%8D%E5%8A%A1%E3%80%81%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E3%80%81%E8%81%94%E7%BD%91.html"/>
    <id>http://chengqian90.com/%E5%AE%B9%E5%99%A8/%E5%AD%A6%E4%B9%A0Kubernetes%E7%B3%BB%E5%88%975%E2%80%94%E2%80%94%E6%9C%8D%E5%8A%A1%E3%80%81%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E3%80%81%E8%81%94%E7%BD%91.html</id>
    <published>2021-06-22T07:22:33.000Z</published>
    <updated>2022-03-08T16:51:56.507Z</updated>
    
    <content type="html"><![CDATA[<h1 id="服务、负载均衡和联网"><a href="#服务、负载均衡和联网" class="headerlink" title="服务、负载均衡和联网"></a>服务、负载均衡和联网</h1><h2 id="Kubernetes-网络模型"><a href="#Kubernetes-网络模型" class="headerlink" title="Kubernetes 网络模型"></a>Kubernetes 网络模型</h2><p>每一个 Pod 都有它自己的IP地址， 这就意味着你不需要显式地在 Pod 之间创建链接， 你几乎不需要处理容器端口到主机端口之间的映射。 这将形成一个干净的、向后兼容的模型；在这个模型里，从端口分配、命名、服务发现、 负载均衡、应用配置和迁移的角度来看， Pod 可以被视作虚拟机或者物理主机。</p><span id="more"></span><p>Kubernetes 强制要求所有网络设施都满足以下基本要求（从而排除了有意隔离网络的策略）：</p><ul><li><p>节点上的 Pod 可以不通过 NAT 和其他任何节点上的 Pod 通信</p></li><li><p>节点上的代理（比如：系统守护进程、kubelet）可以和节点上的所有 Pod 通信</p></li></ul><p>备注：对于支持在主机网络中运行 Pod 的平台（比如：Linux）：</p><ul><li>运行在节点主机网络里的 Pod 可以不通过 NAT 和所有节点上的 Pod 通信</li></ul><p>这个模型不仅不复杂，而且还和 Kubernetes 的实现从虚拟机向容器平滑迁移的初衷相符， 如果你的任务开始是在虚拟机中运行的，你的虚拟机有一个 IP， 可以和项目中其他虚拟机通信。这里的模型是基本相同的。</p><p>Kubernetes 的 IP 地址存在于 Pod 范围内 - 容器共享它们的网络命名空间 - 包括它们的 IP 地址和 MAC 地址。 这就意味着 Pod 内的容器都可以通过 localhost 到达对方端口。 这也意味着 Pod 内的容器需要相互协调端口的使用，但是这和虚拟机中的进程似乎没有什么不同， 这也被称为“一个 Pod 一个 IP”模型。</p><p><strong>如何实现以上需求是所使用的特定容器运行时的细节。</strong></p><p>也可以在 Node 本身请求端口，并用这类端口<strong>转发</strong>到你的 Pod（称之为主机端口）， 但这是一个很特殊的操作。转发方式如何实现也是容器运行时的细节。 Pod 自己并不知道这些主机端口的存在。</p><p>Kubernetes 网络解决四方面的问题：</p><ol><li>一个 Pod 中的容器之间通过本地回路（loopback）通信。</li><li>集群网络在不同 pod 之间提供通信。</li><li>Service 资源允许你 对外暴露 Pods 中运行的应用程序， 以支持来自于集群外部的访问。</li><li>可以使用 Services 来发布仅供集群内部使用的服务。</li></ol><h1 id="服务"><a href="#服务" class="headerlink" title="服务"></a>服务</h1><p>将运行在一组 <a href="https://kubernetes.io/docs/concepts/workloads/pods/pod-overview/">Pods</a> 上的应用程序公开为网络服务的抽象方法。</p><p>使用 Kubernetes，你无需修改应用程序即可使用不熟悉的服务发现机制。 Kubernetes 为 Pods 提供自己的 IP 地址，并为一组 Pod 提供相同的 DNS 名， 并且可以在它们之间进行负载均衡。</p><h2 id="动机"><a href="#动机" class="headerlink" title="动机"></a>动机</h2><p>创建和销毁 Kubernetes <a href="https://kubernetes.io/docs/concepts/workloads/pods/pod-overview/">Pod</a> 以匹配集群状态。 Pod 是非永久性资源。 如果你使用 <a href="https://kubernetes.io/zh/docs/concepts/workloads/controllers/deployment/">Deployment</a> 来运行你的应用程序，则它可以动态创建和销毁 Pod。</p><p>每个 Pod 都有自己的 IP 地址，但是在 Deployment 中，在同一时刻运行的 Pod 集合可能与稍后运行该应用程序的 Pod 集合不同。</p><p>这导致了一个问题： 如果一组 Pod（称为“后端”）为集群内的其他 Pod（称为“前端”）提供功能， 那么<strong>前端如何找出并跟踪要连接的 IP 地址，以便前端可以使用提供工作负载的后端部分</strong>？</p><p>进入 <em>Services</em>。</p><h2 id="Service-资源"><a href="#Service-资源" class="headerlink" title="Service 资源"></a>Service 资源</h2><p>Kubernetes Service 定义了这样一种抽象：<strong>逻辑上的一组 Pod，一种可以访问它们的策略 —— 通常称为微服务</strong>。 Service 所针对的 Pods 集合通常是通过<a href="https://kubernetes.io/zh/docs/concepts/overview/working-with-objects/labels/">选择算符</a>来确定的。 要了解定义服务端点的其他方法，请参阅<a href="https://kubernetes.io/zh/docs/concepts/services-networking/service/#services-without-selectors">不带选择算符的服务</a>。</p><p>举个例子，考虑一个图片处理后端，它运行了 3 个副本。这些副本是可互换的 —— 前端不需要关心它们调用了哪个后端副本。 然而组成这一组后端程序的 Pod 实际上可能会发生变化， 前端客户端不应该也没必要知道，而且也不需要跟踪这一组后端的状态。</p><p><strong>Service 定义的抽象能够解耦这种关联。</strong></p><h3 id="云原生服务发现"><a href="#云原生服务发现" class="headerlink" title="云原生服务发现"></a>云原生服务发现</h3><p>如果你想要在应用程序中使用 Kubernetes API 进行服务发现，则可以查询 <a href="https://kubernetes.io/zh/docs/reference/command-line-tools-reference/kube-apiserver/">API 服务器</a> 的 Endpoints 资源，只要服务中的 Pod 集合发生更改，Endpoints 就会被更新。</p><p>对于非本机应用程序，Kubernetes 提供了在应用程序和后端 Pod 之间放置网络端口或负载均衡器的方法。</p><h2 id="定义-Service"><a href="#定义-Service" class="headerlink" title="定义 Service"></a>定义 Service</h2><p>Service 在 Kubernetes 中是一个 REST 对象，和 Pod 类似。 像所有的 REST 对象一样，Service 定义可以基于 <code>POST</code> 方式，请求 API server 创建新的实例。 </p><p>例如，假定有一组 Pod，它们对外暴露了 9376 端口，同时还被打上 <code>app=MyApp</code> 标签：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">my-service</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">MyApp</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line">      <span class="attr">port:</span> <span class="number">80</span></span><br><span class="line">      <span class="attr">targetPort:</span> <span class="number">9376</span></span><br></pre></td></tr></table></figure><p>上述配置创建一个名称为 “my-service” 的 Service 对象，它会将请求代理到使用 TCP 端口 9376，并且具有标签 <code>&quot;app=MyApp&quot;</code> 的 Pod 上。</p><p><strong>Kubernetes 为该服务分配一个 IP 地址（有时称为 “集群IP”），该 IP 地址由服务代理使用。</strong></p><p>服务选择算符的控制器不断扫描与其选择器匹配的 Pod，然后将所有更新发布到也称为 “my-service” 的 Endpoint 对象。</p><blockquote><p>需要注意的是，Service 能够将一个接收 <code>port</code> 映射到任意的 <code>targetPort</code>。 默认情况下，<code>targetPort</code> 将被设置为与 <code>port</code> 字段相同的值。</p></blockquote><p>Pod 中的端口定义是有名字的，你可以在服务的 <code>targetPort</code> 属性中引用这些名称。 即使服务中使用单个配置的名称混合使用 Pod，并且通过不同的端口号提供相同的网络协议，此功能也可以使用。 这为部署和发展服务提供了很大的灵活性。 例如，你可以更改 Pods 在新版本的后端软件中公开的端口号，而不会破坏客户端。</p><p>服务的默认协议是 TCP；你还可以使用任何其他<a href="https://kubernetes.io/zh/docs/concepts/services-networking/service/#protocol-support">受支持的协议</a>。</p><p>由于许多服务需要公开多个端口，因此 Kubernetes 在服务对象上支持多个端口定义。 每个端口定义可以具有相同的 <code>protocol</code>，也可以具有不同的协议。</p><h3 id="没有选择算符的-Service"><a href="#没有选择算符的-Service" class="headerlink" title="没有选择算符的 Service"></a>没有选择算符的 Service</h3><p>服务最常见的是抽象化对 Kubernetes Pod 的访问，但是它们也可以抽象化其他种类的后端。 实例:</p><ul><li>希望在生产环境中使用外部的数据库集群，但测试环境使用自己的数据库。</li><li>希望服务指向另一个 名字空间（Namespace）中或其它集群中的服务。</li><li>你正在将工作负载迁移到 Kubernetes。 在评估该方法时，你仅在 Kubernetes 中运行一部分后端。</li></ul><p>在任何这些场景中，都能够定义没有选择算符的 Service。 实例:</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">my-service</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line">      <span class="attr">port:</span> <span class="number">80</span></span><br><span class="line">      <span class="attr">targetPort:</span> <span class="number">9376</span></span><br></pre></td></tr></table></figure><p>由于此服务没有选择算符，因此不会自动创建相应的 Endpoint 对象。 你可以通过手动添加 Endpoint 对象，将服务手动映射到运行该服务的网络地址和端口：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Endpoints</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">my-service</span></span><br><span class="line"><span class="attr">subsets:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">addresses:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">ip:</span> <span class="number">192.0</span><span class="number">.2</span><span class="number">.42</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">port:</span> <span class="number">9376</span></span><br></pre></td></tr></table></figure><p>Endpoints 对象的名称必须是合法的 <a href="https://kubernetes.io/zh/docs/concepts/overview/working-with-objects/names#dns-subdomain-names">DNS 子域名</a>。</p><blockquote><p>端点 IPs <em>必须不可以</em> 是：本地回路（IPv4 的 127.0.0.0/8, IPv6 的 ::1/128）或 本地链接（IPv4 的 169.254.0.0/16 和 224.0.0.0/24，IPv6 的 fe80::/64)。</p><p>端点 IP 地址不能是其他 Kubernetes 服务的集群 IP，因为 kube-proxy不支持将虚拟 IP 作为目标。</p></blockquote><p>访问没有选择算符的 Service，与有选择算符的 Service 的原理相同。 请求将被路由到用户定义的 Endpoint，YAML 中为：<code>192.0.2.42:9376</code>（TCP）。</p><p>ExternalName Service 是 Service 的特例，它没有选择算符，但是使用 DNS 名称。 有关更多信息，请参阅本文档后面的<a href="https://kubernetes.io/zh/docs/concepts/services-networking/service/#externalname">ExternalName</a>。</p><h2 id="虚拟-IP-和-Service-代理"><a href="#虚拟-IP-和-Service-代理" class="headerlink" title="虚拟 IP 和 Service 代理"></a>虚拟 IP 和 Service 代理</h2><p>在 Kubernetes 集群中，每个 Node 运行一个 <code>kube-proxy</code> 进程。 <code>kube-proxy</code> 负责为 Service 实现了一种 <strong>VIP（虚拟 IP）的形式</strong>，而不是 <a href="https://kubernetes.io/zh/docs/concepts/services-networking/service/#externalname"><code>ExternalName</code></a> 的形式。</p><h3 id="userspace-代理模式"><a href="#userspace-代理模式" class="headerlink" title="userspace 代理模式"></a>userspace 代理模式</h3><p>这种模式，kube-proxy 会监视 Kubernetes 控制平面对 Service 对象和 Endpoints 对象的添加和移除操作。 对每个 Service，它会<strong>在本地 Node 上打开一个端口（随机选择）</strong>。 任何连接到“代理端口”的请求，都会被代理到 Service 的后端 <code>Pods</code> 中的某个上面（如 <code>Endpoints</code> 所报告的一样）。 使用哪个后端 Pod，是 kube-proxy 基于 <code>SessionAffinity</code> 来确定的。</p><p>最后，它配置 <strong>iptables 规则</strong>，捕获到达该 Service 的 <code>clusterIP</code>（是虚拟 IP） 和 <code>Port</code> 的请求，并<strong>重定向到代理端口</strong>，代理端口再代理请求到后端Pod。</p><p><strong>默认情况下，用户空间模式下的 kube-proxy 通过轮转算法选择后端</strong>。</p><p><img src="/images/%E5%AD%A6%E4%B9%A0Kubernetes%E7%B3%BB%E5%88%97%E4%B9%8B%E6%A6%82%E5%BF%B5/services-userspace-overview.svg" alt="services-userspace-overview"></p><h3 id="iptables-代理模式"><a href="#iptables-代理模式" class="headerlink" title="iptables 代理模式"></a>iptables 代理模式</h3><p>这种模式，<code>kube-proxy</code> 会监视 Kubernetes 控制节点对 Service 对象和 Endpoints 对象的添加和移除。 对每个 Service，它会<strong>配置 iptables 规则，从而捕获到达该 Service 的 <code>clusterIP</code> 和端口的请求，进而将请求重定向到 Service 的一组后端中的某个 Pod 上面</strong>。 对于每个 Endpoints 对象，它也会配置 iptables 规则，这个规则会选择一个后端组合。</p><p><strong>默认的策略是，kube-proxy 在 iptables 模式下随机选择一个后端。</strong></p><p>使用 iptables 处理流量具有较低的系统开销，因为流量由 Linux netfilter 处理， 而无需在用户空间和内核空间之间切换。 这种方法也可能更可靠。</p><p>如果 kube-proxy 在 iptables 模式下运行，并且所选的第一个 Pod 没有响应， 则连接失败。 这与用户空间模式不同：在这种情况下，kube-proxy 将检测到与第一个 Pod 的连接已失败， 并会自动使用其他后端 Pod 重试。</p><p>你可以使用 Pod <a href="https://kubernetes.io/zh/docs/concepts/workloads/pods/pod-lifecycle/#container-probes">就绪探测器</a> 验证后端 Pod 可以正常工作，以便 iptables 模式下的 kube-proxy 仅看到测试正常的后端。 这样做意味着你避免将流量通过 kube-proxy 发送到已知已失败的 Pod。</p><p><img src="/images/%E5%AD%A6%E4%B9%A0Kubernetes%E7%B3%BB%E5%88%97%E4%B9%8B%E6%A6%82%E5%BF%B5/services-iptables-overview.svg" alt="services-iptables-overview"></p><h3 id="IPVS-代理模式"><a href="#IPVS-代理模式" class="headerlink" title="IPVS 代理模式"></a>IPVS 代理模式</h3><p><strong>FEATURE STATE:</strong> <code>Kubernetes v1.11 [stable]</code></p><p>在 <code>ipvs</code> 模式下，kube-proxy 监视 Kubernetes 服务和端点，<strong>调用 <code>netlink</code> 接口相应地创建 IPVS 规则， 并定期将 IPVS 规则与 Kubernetes 服务和端点同步</strong>。 该控制循环可确保IPVS 状态与所需状态匹配。访问服务时，IPVS 将流量定向到后端Pod之一。</p><p>IPVS代理模式基于类似于 iptables 模式的 netfilter 挂钩函数， 但是使用哈希表作为基础数据结构，并且在内核空间中工作。 这意味着，与 iptables 模式下的 kube-proxy 相比，IPVS 模式下的 kube-proxy 重定向通信的延迟要短，并且在同步代理规则时具有更好的性能。 与其他代理模式相比，IPVS 模式还支持更高的网络流量吞吐量。</p><p>IPVS 提供了更多选项来平衡后端 Pod 的流量。 这些是：</p><ul><li><code>rr</code>：轮替（Round-Robin）</li><li><code>lc</code>：最少链接（Least Connection），即打开链接数量最少者优先</li><li><code>dh</code>：目标地址哈希（Destination Hashing）</li><li><code>sh</code>：源地址哈希（Source Hashing）</li><li><code>sed</code>：最短预期延迟（Shortest Expected Delay）</li><li><code>nq</code>：从不排队（Never Queue）</li></ul><blockquote><p>要在 IPVS 模式下运行 kube-proxy，必须在启动 kube-proxy 之前使 IPVS 在节点上可用。</p><p>当 kube-proxy 以 IPVS 代理模式启动时，它将验证 IPVS 内核模块是否可用。 如果未检测到 IPVS 内核模块，则 kube-proxy 将退回到以 iptables 代理模式运行。</p></blockquote><p><img src="/images/%E5%AD%A6%E4%B9%A0Kubernetes%E7%B3%BB%E5%88%97%E4%B9%8B%E6%A6%82%E5%BF%B5/services-ipvs-overview.svg" alt="services-ipvs-overview"></p><p>如果要确保每次都将来自特定客户端的连接传递到同一 Pod， 则可以通过将 <code>service.spec.sessionAffinity</code> 设置为 “ClientIP” （默认值是 “None”），来基于客户端的 IP 地址选择会话关联。 你还可以通过适当设置 <code>service.spec.sessionAffinityConfig.clientIP.timeoutSeconds</code> 来设置最大会话停留时间。 （默认值为 10800 秒，即 3 小时）。</p><h2 id="多端口-Service"><a href="#多端口-Service" class="headerlink" title="多端口 Service"></a>多端口 Service</h2><p>对于某些服务，你需要公开多个端口。 Kubernetes 允许你在 Service 对象上配置多个端口定义。 为服务使用多个端口时，必须提供所有端口名称，以使它们无歧义。 例如：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">my-service</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">MyApp</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">http</span></span><br><span class="line">      <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line">      <span class="attr">port:</span> <span class="number">80</span></span><br><span class="line">      <span class="attr">targetPort:</span> <span class="number">9376</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">https</span></span><br><span class="line">      <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line">      <span class="attr">port:</span> <span class="number">443</span></span><br><span class="line">      <span class="attr">targetPort:</span> <span class="number">9377</span></span><br></pre></td></tr></table></figure><blockquote><p>与一般的Kubernetes名称一样，端口名称只能包含小写字母数字字符 和 <code>-</code>。 端口名称还必须以字母数字字符开头和结尾。</p><p>例如，名称 <code>123-abc</code> 和 <code>web</code> 有效，但是 <code>123_abc</code> 和 <code>-web</code> 无效。</p></blockquote><h2 id="选择自己的-IP-地址"><a href="#选择自己的-IP-地址" class="headerlink" title="选择自己的 IP 地址"></a>选择自己的 IP 地址</h2><p>在 <code>Service</code> 创建的请求中，可以通过设置 <code>spec.clusterIP</code> 字段来指定自己的集群 IP 地址。 比如，希望替换一个已经已存在的 DNS 条目，或者遗留系统已经配置了一个固定的 IP 且很难重新配置。</p><p>用户选择的 IP 地址必须合法，并且这个 IP 地址在 <code>service-cluster-ip-range</code> CIDR 范围内， 这对 API 服务器来说是通过一个标识来指定的。 如果 IP 地址不合法，API 服务器会返回 HTTP 状态码 422，表示值不合法。</p><h2 id="流量策略"><a href="#流量策略" class="headerlink" title="流量策略"></a>流量策略</h2><h3 id="外部流量策略"><a href="#外部流量策略" class="headerlink" title="外部流量策略"></a>外部流量策略</h3><p>你可以通过设置 <code>spec.externalTrafficPolicy</code> 字段来控制来自于外部的流量是如何路由的。 可选值有 <code>Cluster</code> 和 <code>Local</code>。字段设为 <code>Cluster</code> 会将外部流量路由到所有就绪的端点， 设为 <code>Local</code> 会只路由到当前节点上就绪的端点。 如果流量策略设置为 <code>Local</code>，而且当前节点上没有就绪的端点，kube-proxy 不会转发请求相关服务的任何流量。</p><h3 id="内部流量策略"><a href="#内部流量策略" class="headerlink" title="内部流量策略"></a>内部流量策略</h3><p><strong>FEATURE STATE:</strong> <code>Kubernetes v1.22 [beta]</code></p><p>你可以设置 <code>spec.internalTrafficPolicy</code> 字段来控制内部来源的流量是如何转发的。可设置的值有 <code>Cluster</code> 和 <code>Local</code>。 将字段设置为 <code>Cluster</code> 会将内部流量路由到所有就绪端点，设置为 <code>Local</code> 只会路由到当前节点上就绪的端点。 如果流量策略是 <code>Local</code>，而且当前节点上没有就绪的端点，那么 kube-proxy 会丢弃流量。</p><h2 id="服务发现"><a href="#服务发现" class="headerlink" title="服务发现"></a>服务发现</h2><p>Kubernetes 支持两种基本的服务发现模式 —— <strong>环境变量和 DNS</strong>。</p><h3 id="环境变量"><a href="#环境变量" class="headerlink" title="环境变量"></a>环境变量</h3><p>当 Pod 运行在 <code>Node</code> 上，kubelet 会为每个活跃的 Service 添加一组环境变量。 它同时支持 <a href="https://docs.docker.com/userguide/dockerlinks/">Docker links兼容</a> 变量 、 简单的 <code>&#123;SVCNAME&#125;_SERVICE_HOST</code> 和 <code>&#123;SVCNAME&#125;_SERVICE_PORT</code> 变量。 这里 Service 的名称需大写，横线被转换成下划线。</p><p>举个例子，一个名称为 <code>redis-master</code> 的 Service 暴露了 TCP 端口 6379， 同时给它分配了 Cluster IP 地址 10.0.0.11，这个 Service 生成了如下环境变量：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">REDIS_MASTER_SERVICE_HOST=10.0.0.11</span><br><span class="line">REDIS_MASTER_SERVICE_PORT=6379</span><br><span class="line">REDIS_MASTER_PORT=tcp://10.0.0.11:6379</span><br><span class="line">REDIS_MASTER_PORT_6379_TCP=tcp://10.0.0.11:6379</span><br><span class="line">REDIS_MASTER_PORT_6379_TCP_PROTO=tcp</span><br><span class="line">REDIS_MASTER_PORT_6379_TCP_PORT=6379</span><br><span class="line">REDIS_MASTER_PORT_6379_TCP_ADDR=10.0.0.11</span><br></pre></td></tr></table></figure><blockquote><p>当你具有需要访问服务的 Pod 时，并且你正在使用环境变量方法将端口和集群 IP 发布到客户端 Pod 时，必须在客户端 Pod 出现 <em>之前</em> 创建服务。 否则，这些客户端 Pod 将不会设定其环境变量。</p><p>如果仅使用 DNS 查找服务的集群 IP，则无需担心此设定问题。</p></blockquote><h3 id="DNS"><a href="#DNS" class="headerlink" title="DNS"></a>DNS</h3><p>你可以（几乎总是应该）使用<a href="https://kubernetes.io/zh/docs/concepts/cluster-administration/addons/">附加组件</a> 为 Kubernetes 集群设置 DNS 服务。</p><p>支持集群的 DNS 服务器（例如 CoreDNS）监视 Kubernetes API 中的新服务，并为每个服务创建一组 DNS 记录。 如果在整个集群中都启用了 DNS，则所有 Pod 都应该能够通过其 DNS 名称自动解析服务。</p><p>例如，如果你在 Kubernetes 命名空间 <code>my-ns</code> 中有一个名为 <code>my-service</code> 的服务， 则控制平面和 DNS 服务共同为 <code>my-service.my-ns</code> 创建 DNS 记录。 <code>my-ns</code> 命名空间中的 Pod 应该能够通过按名检索 <code>my-service</code> 来找到服务 （<code>my-service.my-ns</code> 也可以工作）。</p><p>其他命名空间中的 Pod 必须将名称限定为 <code>my-service.my-ns</code>。 这些名称将解析为为服务分配的集群 IP。</p><p>Kubernetes 还支持命名端口的 DNS SRV（服务）记录。 如果 <code>my-service.my-ns</code> 服务具有名为 <code>http</code>　的端口，且协议设置为 TCP， 则可以对 <code>_http._tcp.my-service.my-ns</code> 执行 DNS SRV 查询查询以发现该端口号, <code>&quot;http&quot;</code> 以及 IP 地址。</p><p><strong>Kubernetes DNS 服务器是唯一的一种能够访问 <code>ExternalName</code> 类型的 Service 的方式</strong>。 更多关于 <code>ExternalName</code> 信息可以查看 <a href="https://kubernetes.io/zh/docs/concepts/services-networking/dns-pod-service/">DNS Pod 和 Service</a>。</p><h2 id="无头服务（Headless-Services）"><a href="#无头服务（Headless-Services）" class="headerlink" title="无头服务（Headless Services）"></a>无头服务（Headless Services）</h2><p>有时不需要或不想要负载均衡，以及单独的 Service IP。 遇到这种情况，可以通过指定 Cluster IP（<code>spec.clusterIP</code>）的值为 <code>&quot;None&quot;</code> 来创建 <code>Headless</code> Service。</p><p>你可以使用无头 Service 与其他服务发现机制进行接口，而不必与 Kubernetes 的实现捆绑在一起。</p><p>对这无头 Service 并不会分配 Cluster IP，kube-proxy 不会处理它们， 而且平台也不会为它们进行负载均衡和路由。 DNS 如何实现自动配置，依赖于 Service 是否定义了选择算符。</p><h3 id="带选择算符的服务"><a href="#带选择算符的服务" class="headerlink" title="带选择算符的服务"></a>带选择算符的服务</h3><p>对定义了选择算符的无头服务，Endpoint 控制器在 API 中创建了 Endpoints 记录， 并且修改 DNS 配置返回 A 记录（IP 地址），通过这个地址直接到达 <code>Service</code> 的后端 Pod 上。</p><h3 id="无选择算符的服务"><a href="#无选择算符的服务" class="headerlink" title="无选择算符的服务"></a>无选择算符的服务</h3><p>对没有定义选择算符的无头服务，Endpoint 控制器不会创建 <code>Endpoints</code> 记录。 然而 DNS 系统会查找和配置，无论是：</p><ul><li>对于 <a href="https://kubernetes.io/zh/docs/concepts/services-networking/service/#external-name"><code>ExternalName</code></a> 类型的服务，查找其 CNAME 记录</li><li>对所有其他类型的服务，查找与 Service 名称相同的任何 <code>Endpoints</code> 的记录</li></ul><h2 id="发布服务（服务类型"><a href="#发布服务（服务类型" class="headerlink" title="发布服务（服务类型)"></a>发布服务（服务类型)</h2><p>对一些应用的某些部分（如前端），可能希望将其暴露给 Kubernetes 集群外部 的 IP 地址。</p><p>Kubernetes <code>ServiceTypes</code> 允许指定你所需要的 Service 类型，默认是 <code>ClusterIP</code>。</p><p><code>Type</code> 的取值以及行为如下：</p><ul><li><code>ClusterIP</code>：通过集群的内部 IP 暴露服务，选择该值时服务只能够在集群内部访问。 这也是默认的 <code>ServiceType</code>。</li><li><a href="https://kubernetes.io/zh/docs/concepts/services-networking/service/#type-nodeport"><code>NodePort</code></a>：通过每个节点上的 IP 和静态端口（<code>NodePort</code>）暴露服务。 <code>NodePort</code> 服务会路由到自动创建的 <code>ClusterIP</code> 服务。 通过请求 <code>&lt;节点 IP&gt;:&lt;节点端口&gt;</code>，你可以从集群的外部访问一个 <code>NodePort</code> 服务。</li><li><a href="https://kubernetes.io/zh/docs/concepts/services-networking/service/#loadbalancer"><code>LoadBalancer</code></a>：使用<strong>云提供商的负载均衡器</strong>向外部暴露服务。 外部负载均衡器可以将流量路由到自动创建的 <code>NodePort</code> 服务和 <code>ClusterIP</code> 服务上。</li><li><a href="https://kubernetes.io/zh/docs/concepts/services-networking/service/#externalname"><code>ExternalName</code></a>：通过返回 <code>CNAME</code> 和对应值，可以将服务映射到 <code>externalName</code> 字段的内容（例如，<code>foo.bar.example.com</code>）。 无需创建任何类型代理。</li></ul><p>也可以使用 <a href="https://kubernetes.io/zh/docs/concepts/services-networking/ingress/">Ingress</a> 来暴露自己的服务。 Ingress 不是一种服务类型，但它充当集群的入口点。 它可以将路由规则整合到一个资源中，因为它可以在同一IP地址下公开多个服务。</p><h3 id="NodePort-类型"><a href="#NodePort-类型" class="headerlink" title="NodePort 类型"></a>NodePort 类型</h3><p>如果你将 <code>type</code> 字段设置为 <code>NodePort</code>，则 Kubernetes 控制平面将在 <code>--service-node-port-range</code> 标志指定的范围内分配端口（默认值：30000-32767）。 每个节点将那个端口（每个节点上的相同端口号）代理到你的服务中。 你的服务在其 <code>.spec.ports[*].nodePort</code> 字段中要求分配的端口。</p><p>如果你想指定特定的 IP 代理端口，则可以设置 kube-proxy 中的 <code>--nodeport-addresses</code> 参数 或者将<a href="https://kubernetes.io/docs/reference/config-api/kube-proxy-config.v1alpha1/">kube-proxy 配置文件</a> 中的等效 <code>nodePortAddresses</code> 字段设置为特定的 IP 块。 该标志采用逗号分隔的 IP 块列表（例如，<code>10.0.0.0/8</code>、<code>192.0.2.0/25</code>）来指定 kube-proxy 应该认为是此节点本地的 IP 地址范围。</p><p>例如，如果你使用 <code>--nodeport-addresses=127.0.0.0/8</code> 标志启动 kube-proxy， 则 kube-proxy 仅选择 NodePort Services 的本地回路接口。 <code>--nodeport-addresses</code> 的默认值是一个空列表。 这意味着 kube-proxy 应该考虑 NodePort 的所有可用网络接口。 （这也与早期的 Kubernetes 版本兼容）。</p><p>如果需要特定的端口号，你可以在 <code>nodePort</code> 字段中指定一个值。 控制平面将为你分配该端口或报告 API 事务失败。 这意味着你需要自己注意可能发生的端口冲突。 你还必须使用有效的端口号，该端口号在配置用于 NodePort 的范围内。</p><p>使用 NodePort 可以让你自由设置自己的负载均衡解决方案， 配置 Kubernetes 不完全支持的环境， 甚至直接暴露一个或多个节点的 IP。</p><p>需要注意的是，Service 能够通过 <code>&lt;NodeIP&gt;:spec.ports[*].nodePort</code> 和 <code>spec.clusterIp:spec.ports[*].port</code> 而对外可见。 如果设置了 kube-proxy 的 <code>--nodeport-addresses</code> 参数或 kube-proxy 配置文件中的等效字段， <code>&lt;NodeIP&gt;</code> 将被过滤 NodeIP。</p><p>例如：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">my-service</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">NodePort</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">MyApp</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">      <span class="comment"># 默认情况下，为了方便起见，`targetPort` 被设置为与 `port` 字段相同的值。</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">port:</span> <span class="number">80</span></span><br><span class="line">      <span class="attr">targetPort:</span> <span class="number">80</span></span><br><span class="line">      <span class="comment"># 可选字段</span></span><br><span class="line">      <span class="comment"># 默认情况下，为了方便起见，Kubernetes 控制平面会从某个范围内分配一个端口号（默认：30000-32767）</span></span><br><span class="line">      <span class="attr">nodePort:</span> <span class="number">30007</span></span><br></pre></td></tr></table></figure><h3 id="LoadBalancer-类型"><a href="#LoadBalancer-类型" class="headerlink" title="LoadBalancer 类型"></a>LoadBalancer 类型</h3><p>在使用支持外部负载均衡器的云提供商的服务时，设置 <code>type</code> 的值为 <code>&quot;LoadBalancer&quot;</code>， 将为 Service 提供负载均衡器。 负载均衡器是异步创建的，关于被提供的负载均衡器的信息将会通过 Service 的 <code>status.loadBalancer</code> 字段发布出去。</p><p>实例：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">my-service</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">MyApp</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line">      <span class="attr">port:</span> <span class="number">80</span></span><br><span class="line">      <span class="attr">targetPort:</span> <span class="number">9376</span></span><br><span class="line">  <span class="attr">clusterIP:</span> <span class="number">10.0</span><span class="number">.171</span><span class="number">.239</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">LoadBalancer</span></span><br><span class="line"><span class="attr">status:</span></span><br><span class="line">  <span class="attr">loadBalancer:</span></span><br><span class="line">    <span class="attr">ingress:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">ip:</span> <span class="number">192.0</span><span class="number">.2</span><span class="number">.127</span></span><br></pre></td></tr></table></figure><p>来自外部负载均衡器的流量将直接重定向到后端 Pod 上，不过实际它们是如何工作的，这要依赖于云提供商。</p><p>某些云提供商允许设置 <code>loadBalancerIP</code>。 在这些情况下，将根据用户设置的 <code>loadBalancerIP</code> 来创建负载均衡器。 如果没有设置 <code>loadBalancerIP</code> 字段，将会给负载均衡器指派一个临时 IP。 如果设置了 <code>loadBalancerIP</code>，但云提供商并不支持这种特性，那么设置的 <code>loadBalancerIP</code> 值将会被忽略掉。</p><h3 id="ExternalName-类型"><a href="#ExternalName-类型" class="headerlink" title="ExternalName 类型"></a>ExternalName 类型</h3><p>类型为 ExternalName 的服务将服务映射到 DNS 名称，而不是典型的选择器，例如 <code>my-service</code> 或者 <code>cassandra</code>。 你可以使用 <code>spec.externalName</code> 参数指定这些服务。</p><p>例如，以下 Service 定义将 <code>prod</code> 名称空间中的 <code>my-service</code> 服务映射到 <code>my.database.example.com</code>：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">my-service</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">prod</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">ExternalName</span></span><br><span class="line">  <span class="attr">externalName:</span> <span class="string">my.database.example.com</span></span><br></pre></td></tr></table></figure><p>当查找主机 <code>my-service.prod.svc.cluster.local</code> 时，集群 DNS 服务返回 <code>CNAME</code> 记录， 其值为 <code>my.database.example.com</code>。 访问 <code>my-service</code> 的方式与其他服务的方式相同，但主要区别在于重定向发生在 DNS 级别，而不是通过代理或转发。 如果以后你决定将数据库移到集群中，则可以启动其 Pod，添加适当的选择器或端点以及更改服务的 <code>type</code>。</p><h3 id="外部-IP"><a href="#外部-IP" class="headerlink" title="外部 IP"></a>外部 IP</h3><p>如果外部的 IP 路由到集群中一个或多个 Node 上，Kubernetes Service 会被暴露给这些 externalIPs。 通过外部 IP（作为目的 IP 地址）进入到集群，打到 Service 的端口上的流量， 将会被路由到 Service 的 Endpoint 上。 <code>externalIPs</code> 不会被 Kubernetes 管理，它属于集群管理员的职责范畴。</p><p>根据 Service 的规定，<code>externalIPs</code> 可以同任意的 <code>ServiceType</code> 来一起指定。 在上面的例子中，<code>my-service</code> 可以在 “<code>80.11.12.10:80</code>“(<code>externalIP:port</code>) 上被客户端访问。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">my-service</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">MyApp</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">http</span></span><br><span class="line">      <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line">      <span class="attr">port:</span> <span class="number">80</span></span><br><span class="line">      <span class="attr">targetPort:</span> <span class="number">9376</span></span><br><span class="line">  <span class="attr">externalIPs:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="number">80.11</span><span class="number">.12</span><span class="number">.10</span></span><br></pre></td></tr></table></figure><h2 id="虚拟IP实施"><a href="#虚拟IP实施" class="headerlink" title="虚拟IP实施"></a>虚拟IP实施</h2><h3 id="避免冲突"><a href="#避免冲突" class="headerlink" title="避免冲突"></a>避免冲突</h3><p>Kubernetes 最主要的哲学之一，是用户不应该暴露那些能够导致他们操作失败、但又不是他们的过错的场景。 对于 Service 资源的设计，这意味着如果用户的选择有可能与他人冲突，那就不要让用户自行选择端口号。 这是一个隔离性的失败。</p><p>为了使用户能够为他们的 Service 选择一个端口号，我们必须确保不能有2个 Service 发生冲突。 Kubernetes 通过为每个 Service 分配它们自己的 IP 地址来实现。</p><p>为了保证每个 Service 被分配到一个唯一的 IP，需要一个内部的分配器能够原子地更新 <a href="https://kubernetes.io/zh/docs/tasks/administer-cluster/configure-upgrade-etcd/">etcd</a> 中的一个全局分配映射表， 这个更新操作要先于创建每一个 Service。 为了使 Service 能够获取到 IP，这个映射表对象必须在注册中心存在， 否则创建 Service 将会失败，指示一个 IP 不能被分配。</p><p>在控制平面中，一个后台 Controller 的职责是创建映射表 （需要支持从使用了内存锁的 Kubernetes 的旧版本迁移过来）。 同时 Kubernetes 会通过控制器检查不合理的分配（如管理员干预导致的） 以及清理已被分配但不再被任何 Service 使用的 IP 地址。</p><h3 id="Service-IP-地址"><a href="#Service-IP-地址" class="headerlink" title="Service IP 地址"></a>Service IP 地址</h3><p><strong>不像 Pod 的 IP 地址，它实际路由到一个固定的目的地，Service 的 IP 实际上 不能通过单个主机来进行应答</strong>。 相反，我们使用 <code>iptables</code>（Linux 中的数据包处理逻辑）来定义一个 虚拟 IP 地址（VIP），它可以根据需要透明地进行重定向。 当客户端连接到 VIP 时，它们的流量会自动地传输到一个合适的 Endpoint。 环境变量和 DNS，实际上会根据 Service 的 VIP 和端口来进行填充。</p><p>kube-proxy支持三种代理模式: 用户空间，iptables和IPVS；它们各自的操作略有不同。</p><h4 id="Userspace"><a href="#Userspace" class="headerlink" title="Userspace"></a>Userspace</h4><p>作为一个例子，考虑前面提到的图片处理应用程序。 当创建后端 Service 时，Kubernetes master 会给它指派一个虚拟 IP 地址，比如 10.0.0.1。 假设 Service 的端口是 1234，该 Service 会被集群中所有的 <code>kube-proxy</code> 实例观察到。 当代理看到一个新的 Service， 它会打开一个新的端口，建立一个从该 VIP 重定向到 新端口的 iptables，并开始接收请求连接。</p><p>当一个客户端连接到一个 VIP，iptables 规则开始起作用，它会重定向该数据包到 “服务代理” 的端口。 “服务代理” 选择一个后端，并将客户端的流量代理到后端上。</p><p>这意味着 Service 的所有者能够选择任何他们想使用的端口，而不存在冲突的风险。 客户端可以连接到一个 IP 和端口，而不需要知道实际访问了哪些 Pod。</p><h4 id="iptables"><a href="#iptables" class="headerlink" title="iptables"></a>iptables</h4><p>再次考虑前面提到的图片处理应用程序。 当创建后端 Service 时，Kubernetes 控制面板会给它指派一个虚拟 IP 地址，比如 10.0.0.1。 假设 Service 的端口是 1234，该 Service 会被集群中所有的 <code>kube-proxy</code> 实例观察到。 当代理看到一个新的 Service， 它会配置一系列的 iptables 规则，从 VIP 重定向到每个 Service 规则。 该特定于服务的规则连接到特定于 Endpoint 的规则，而后者会重定向（目标地址转译）到后端。</p><p>当客户端连接到一个 VIP，iptables 规则开始起作用。一个后端会被选择（或者根据会话亲和性，或者随机）， 数据包被重定向到这个后端。 不像用户空间代理，数据包从来不拷贝到用户空间，kube-proxy 不是必须为该 VIP 工作而运行， 并且客户端 IP 是不可更改的。</p><p>当流量打到 Node 的端口上，或通过负载均衡器，会执行相同的基本流程， 但是在那些案例中客户端 IP 是可以更改的。</p><h4 id="IPVS"><a href="#IPVS" class="headerlink" title="IPVS"></a>IPVS</h4><p>在大规模集群（例如 10000 个服务）中，iptables 操作会显着降低速度。 IPVS 专为负载平衡而设计，并基于内核内哈希表。 因此，你可以通过基于 IPVS 的 kube-proxy 在大量服务中实现性能一致性。 同时，基于 IPVS 的 kube-proxy 具有更复杂的负载均衡算法（最小连接、局部性、 加权、持久性）。</p><h1 id="使用-Service-连接到应用"><a href="#使用-Service-连接到应用" class="headerlink" title="使用 Service 连接到应用"></a>使用 Service 连接到应用</h1><h2 id="Kubernetes-连接容器模型"><a href="#Kubernetes-连接容器模型" class="headerlink" title="Kubernetes 连接容器模型"></a>Kubernetes 连接容器模型</h2><p>既然有了一个持续运行、可复制的应用，我们就能够将它暴露到网络上。 在讨论 Kubernetes 网络连接的方式之前，非常值得与 Docker 中 “正常” 方式的网络进行对比。</p><p>默认情况下，Docker 使用私有主机网络连接，只能与同在一台机器上的容器进行通信。 为了实现容器的跨节点通信，必须在机器自己的 IP 上为这些容器分配端口，为容器进行端口转发或者代理。</p><p>多个开发人员或是提供容器的团队之间协调端口的分配很难做到规模化，那些难以控制的集群级别的问题，都会交由用户自己去处理。 Kubernetes 假设 Pod 可与其它 Pod 通信，不管它们在哪个主机上。 <strong>Kubernetes 给 Pod 分配属于自己的集群私有 IP 地址</strong>，所以没必要在 Pod 或映射到的容器的端口和主机端口之间显式地创建连接。 这表明了在 Pod 内的容器都能够连接到本地的每个端口，集群中的所有 Pod 不需要通过 NAT 转换就能够互相看到。 文档的剩余部分详述如何在一个网络模型之上运行可靠的服务。</p><p>该指南使用一个简单的 Nginx server 来演示并证明谈到的概念。</p><h2 id="在集群中暴露-Pod"><a href="#在集群中暴露-Pod" class="headerlink" title="在集群中暴露 Pod"></a>在集群中暴露 Pod</h2><p>我们在之前的示例中已经做过，然而让我们以网络连接的视角再重做一遍。 创建一个 Nginx Pod，并且注意，它有一个容器端口的规范（service/networking/run-my-nginx.yaml）：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">my-nginx</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">run:</span> <span class="string">my-nginx</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">2</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">run:</span> <span class="string">my-nginx</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">my-nginx</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">nginx</span></span><br><span class="line">        <span class="attr">ports:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span></span><br></pre></td></tr></table></figure><p>这使得可以从集群中任何一个节点来访问它。检查节点，该 Pod 正在运行：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f ./run-my-nginx.yaml</span><br><span class="line">kubectl get pods -l run=my-nginx -o wide</span><br><span class="line">NAME                        READY     STATUS    RESTARTS   AGE       IP            NODE</span><br><span class="line">my-nginx-3800858182-jr4a2   1/1       Running   0          13s       10.244.3.4    kubernetes-minion-905m</span><br><span class="line">my-nginx-3800858182-kna2y   1/1       Running   0          13s       10.244.2.5    kubernetes-minion-ljyd</span><br></pre></td></tr></table></figure><p>检查 Pod 的 IP 地址：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kubectl get pods -l run=my-nginx -o yaml | grep podIP</span><br><span class="line">    podIP: 10.244.3.4</span><br><span class="line">    podIP: 10.244.2.5</span><br></pre></td></tr></table></figure><p>应该能够通过 ssh 登录到集群中的任何一个节点上，使用 curl 也能调通所有 IP 地址。 需要注意的是，容器不会使用该节点上的 80 端口，也不会使用任何特定的 NAT 规则去路由流量到 Pod 上。 这意味着可以在同一个节点上运行多个 Pod，使用相同的容器端口，并且可以从集群中任何其他的 Pod 或节点上使用 IP 的方式访问到它们。 像 Docker 一样，端口能够被发布到主机节点的接口上，但是出于网络模型的原因应该从根本上减少这种用法。</p><h2 id="创建-Service"><a href="#创建-Service" class="headerlink" title="创建 Service"></a>创建 Service</h2><p>我们有 Pod 在一个扁平的、集群范围的地址空间中运行 Nginx 服务，可以直接连接到这些 Pod，但如果某个节点死掉了会发生什么呢？ Pod 会终止，<strong>Deployment 将创建新的 Pod，且使用不同的 IP</strong>。这正是 Service 要解决的问题。</p><p>Kubernetes Service 从逻辑上定义了运行在集群中的一组 Pod，这些 Pod 提供了相同的功能。 <strong>当每个 Service 创建时，会被分配一个唯一的 IP 地址（也称为 clusterIP）</strong>。 这个 IP 地址与一个 Service 的生命周期绑定在一起，当 Service 存在的时候它也不会改变。 可以配置 Pod 使它与 Service 进行通信，Pod 知道与 Service 通信将被自动地负载均衡到该 Service 中的某些 Pod 上。</p><p>可以使用 <code>kubectl expose</code> 命令为 2个 Nginx 副本创建一个 Service：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kubectl expose deployment/my-nginx</span><br><span class="line">service/my-nginx exposed</span><br></pre></td></tr></table></figure><p>这等价于使用 <code>kubectl create -f</code> 命令创建，对应如下的 yaml 文件（service/networking/nginx-svc.yaml）：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">my-nginx</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">run:</span> <span class="string">my-nginx</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">port:</span> <span class="number">80</span></span><br><span class="line">    <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">run:</span> <span class="string">my-nginx</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>上述规约将创建一个 Service，对应具有标签 <code>run: my-nginx</code> 的 Pod，目标 TCP 端口 80， 并且在一个抽象的 Service 端口（<code>targetPort</code>：容器接收流量的端口；<code>port</code>：抽象的 Service 端口，可以使任何其它 Pod 访问该 Service 的端口）上暴露。</p><p>查看你的 Service 资源:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kubectl get svc my-nginx</span><br><span class="line">NAME       TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)   AGE</span><br><span class="line">my-nginx   ClusterIP   10.0.162.149   &lt;none&gt;        80/TCP    21s</span><br></pre></td></tr></table></figure><p>正如前面所提到的，一个 Service 由一组 backend Pod 组成。这些 Pod 通过 <code>endpoints</code> 暴露出来。 Service Selector 将持续评估，结果被 POST 到一个名称为 <code>my-nginx</code> 的 Endpoint 对象上。 当 Pod 终止后，它会自动从 Endpoint 中移除，新的能够匹配上 Service Selector 的 Pod 将自动地被添加到 Endpoint 中。 检查该 Endpoint，注意到 IP 地址与在第一步创建的 Pod 是相同的。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">kubectl describe svc my-nginx</span><br><span class="line">Name:                my-nginx</span><br><span class="line">Namespace:           default</span><br><span class="line">Labels:              run=my-nginx</span><br><span class="line">Annotations:         &lt;none&gt;</span><br><span class="line">Selector:            run=my-nginx</span><br><span class="line">Type:                ClusterIP</span><br><span class="line">IP:                  10.0.162.149</span><br><span class="line">Port:                &lt;unset&gt; 80/TCP</span><br><span class="line">Endpoints:           10.244.2.5:80,10.244.3.4:80</span><br><span class="line">Session Affinity:    None</span><br><span class="line">Events:              &lt;none&gt;</span><br><span class="line">kubectl get ep my-nginx</span><br><span class="line">NAME       ENDPOINTS                     AGE</span><br><span class="line">my-nginx   10.244.2.5:80,10.244.3.4:80   1m</span><br></pre></td></tr></table></figure><p>现在，能够从集群中任意节点上使用 curl 命令请求 Nginx Service <code>&lt;CLUSTER-IP&gt;:&lt;PORT&gt;</code> 。 </p><h2 id="访问-Service"><a href="#访问-Service" class="headerlink" title="访问 Service"></a>访问 Service</h2><p>Kubernetes支持两种查找服务的主要模式: 环境变量和DNS。 前者开箱即用，而后者则需要[CoreDNS集群插件] <a href="https://releases.k8s.io/main/cluster/addons/dns/coredns">CoreDNS 集群插件</a>.</p><p><strong>说明：</strong> 如果不需要服务环境变量（因为可能与预期的程序冲突，可能要处理的变量太多，或者仅使用DNS等），则可以通过在 <a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.23/#pod-v1-core">pod spec</a> 上将 <code>enableServiceLinks</code> 标志设置为 <code>false</code> 来禁用此模式。</p><h3 id="环境变量-1"><a href="#环境变量-1" class="headerlink" title="环境变量"></a>环境变量</h3><p>当 Pod 在 Node 上运行时，kubelet 会为每个活跃的 Service 添加一组环境变量。 这会有一个顺序的问题。想了解为何，检查正在运行的 Nginx Pod 的环境变量（Pod 名称将不会相同）：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">kubectl exec my-nginx-3800858182-jr4a2 -- printenv | grep SERVICE</span><br><span class="line">KUBERNETES_SERVICE_HOST=10.0.0.1</span><br><span class="line">KUBERNETES_SERVICE_PORT=443</span><br><span class="line">KUBERNETES_SERVICE_PORT_HTTPS=443</span><br></pre></td></tr></table></figure><p>注意，还没有谈及到 Service。这是因为创建副本先于 Service。 这样做的另一个缺点是，调度器可能在同一个机器上放置所有 Pod，如果该机器宕机则所有的 Service 都会挂掉。 正确的做法是，我们杀掉 2 个 Pod，等待 Deployment 去创建它们。 这次 Service 会 <em>先于</em> 副本存在。这将实现调度器级别的 Service，能够使 Pod 分散创建（假定所有的 Node 都具有同样的容量），以及正确的环境变量：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">kubectl scale deployment my-nginx --replicas=0; kubectl scale deployment my-nginx --replicas=2;</span><br><span class="line"></span><br><span class="line">kubectl get pods -l run=my-nginx -o wide</span><br><span class="line">NAME                        READY     STATUS    RESTARTS   AGE     IP            NODE</span><br><span class="line">my-nginx-3800858182-e9ihh   1/1       Running   0          5s      10.244.2.7    kubernetes-minion-ljyd</span><br><span class="line">my-nginx-3800858182-j4rm4   1/1       Running   0          5s      10.244.3.8    kubernetes-minion-905m</span><br></pre></td></tr></table></figure><p>可能注意到，Pod 具有不同的名称，因为它们被杀掉后并被重新创建。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">kubectl exec my-nginx-3800858182-e9ihh -- printenv | grep SERVICE</span><br><span class="line">KUBERNETES_SERVICE_PORT=443</span><br><span class="line">MY_NGINX_SERVICE_HOST=10.0.162.149</span><br><span class="line">KUBERNETES_SERVICE_HOST=10.0.0.1</span><br><span class="line">MY_NGINX_SERVICE_PORT=80</span><br><span class="line">KUBERNETES_SERVICE_PORT_HTTPS=443</span><br></pre></td></tr></table></figure><h3 id="DNS-1"><a href="#DNS-1" class="headerlink" title="DNS"></a>DNS</h3><p><strong>Kubernetes 提供了一个 DNS 插件 Service，它使用 skydns 自动为其它 Service 指派 DNS 名字</strong>。 如果它在集群中处于运行状态，可以通过如下命令来检查：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kubectl get services kube-dns --namespace=kube-system</span><br><span class="line">NAME       TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)         AGE</span><br><span class="line">kube-dns   ClusterIP   10.0.0.10    &lt;none&gt;        53/UDP,53/TCP   8m</span><br></pre></td></tr></table></figure><p>如果没有在运行，可以<a href="https://releases.k8s.io/main/cluster/addons/dns/kube-dns/README.md#how-do-i-configure-it">启用它</a>。 本段剩余的内容，将假设已经有一个 Service，它具有一个长久存在的 IP（my-nginx）， 一个为该 IP 指派名称的 DNS 服务器。 这里我们使用 CoreDNS 集群插件（应用名为 <code>kube-dns</code>）， 所以可以通过标准做法，使在集群中的任何 Pod 都能与该 Service 通信（例如：<code>gethostbyname()</code>）。 如果 CoreDNS 没有在运行，你可以参照 <a href="https://github.com/coredns/deployment/tree/master/kubernetes">CoreDNS README</a> 或者 <a href="https://kubernetes.io/zh/docs/tasks/administer-cluster/coredns/#installing-coredns">安装 CoreDNS</a> 来启用它。 让我们运行另一个 curl 应用来进行测试：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kubectl run curl --image=radial/busyboxplus:curl -i --tty</span><br><span class="line">Waiting for pod default/curl-131556218-9fnch to be running, status is Pending, pod ready: false</span><br><span class="line">Hit enter for command prompt</span><br></pre></td></tr></table></figure><p>然后，按回车并执行命令 <code>nslookup my-nginx</code>：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[ root@curl-131556218-9fnch:/ ]$ nslookup my-nginx</span><br><span class="line">Server:    10.0.0.10</span><br><span class="line">Address 1: 10.0.0.10</span><br><span class="line"></span><br><span class="line">Name:      my-nginx</span><br><span class="line">Address 1: 10.0.162.149</span><br></pre></td></tr></table></figure><h2 id="暴露-Service"><a href="#暴露-Service" class="headerlink" title="暴露 Service"></a>暴露 Service</h2><p>对我们应用的某些部分，可能希望将 Service 暴露在一个外部 IP 地址上。 Kubernetes 支持两种实现方式：NodePort 和 LoadBalancer。 在上一段创建的 Service 使用了 <code>NodePort</code>，因此 Nginx https 副本已经就绪， 如果使用一个公网 IP，能够处理 Internet 上的流量。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">kubectl get svc my-nginx -o yaml | grep nodePort -C 5</span><br><span class="line">  uid: 07191fb3-f61a-11e5-8ae5-42010af00002</span><br><span class="line">spec:</span><br><span class="line">  clusterIP: 10.0.162.149</span><br><span class="line">  ports:</span><br><span class="line">  - name: http</span><br><span class="line">    nodePort: 31704</span><br><span class="line">    port: 8080</span><br><span class="line">    protocol: TCP</span><br><span class="line">    targetPort: 80</span><br><span class="line">  - name: https</span><br><span class="line">    nodePort: 32453</span><br><span class="line">    port: 443</span><br><span class="line">    protocol: TCP</span><br><span class="line">    targetPort: 443</span><br><span class="line">  selector:</span><br><span class="line">    run: my-nginx</span><br><span class="line">kubectl get nodes -o yaml | grep ExternalIP -C 1</span><br><span class="line">    - address: 104.197.41.11</span><br><span class="line">      type: ExternalIP</span><br><span class="line">    allocatable:</span><br><span class="line">--</span><br><span class="line">    - address: 23.251.152.56</span><br><span class="line">      type: ExternalIP</span><br><span class="line">    allocatable:</span><br><span class="line">...</span><br><span class="line"><span class="meta">$</span><span class="bash"> curl https://&lt;EXTERNAL-IP&gt;:&lt;NODE-PORT&gt; -k</span></span><br><span class="line"></span><br><span class="line">...</span><br><span class="line">&lt;h1&gt;Welcome to nginx!&lt;/h1&gt;</span><br></pre></td></tr></table></figure><p>让我们重新创建一个 Service，使用一个云负载均衡器，只需要将 <code>my-nginx</code> Service 的 <code>Type</code> 由 <code>NodePort</code> 改成 <code>LoadBalancer</code>。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">kubectl edit svc my-nginx</span><br><span class="line">kubectl get svc my-nginx</span><br><span class="line">NAME       TYPE           CLUSTER-IP     EXTERNAL-IP        PORT(S)               AGE</span><br><span class="line">my-nginx   LoadBalancer   10.0.162.149   xx.xxx.xxx.xxx     8080:30163/TCP        21s</span><br><span class="line">curl https://&lt;EXTERNAL-IP&gt; -k</span><br><span class="line">...</span><br><span class="line">&lt;title&gt;Welcome to nginx!&lt;/title&gt;</span><br></pre></td></tr></table></figure><p>在 <code>EXTERNAL-IP</code> 列指定的 IP 地址是在公网上可用的。<code>CLUSTER-IP</code> 只在集群/私有云网络中可用。</p><p>注意，在 AWS 上类型 <code>LoadBalancer</code> 创建一个 ELB，它使用主机名（比较长），而不是 IP。 它太长以至于不能适配标准 <code>kubectl get svc</code> 的输出，事实上需要通过执行 <code>kubectl describe service my-nginx</code> 命令来查看它。 可以看到类似如下内容：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">kubectl describe service my-nginx</span><br><span class="line">...</span><br><span class="line">LoadBalancer Ingress:   a320587ffd19711e5a37606cf4a74574-1142138393.us-east-1.elb.amazonaws.com</span><br><span class="line">...</span><br></pre></td></tr></table></figure><h1 id="Ingress"><a href="#Ingress" class="headerlink" title="Ingress"></a>Ingress</h1><p><strong>FEATURE STATE:</strong> <code>Kubernetes v1.19 [stable]</code></p><p>Ingress 是对集群中服务的外部访问进行管理的 API 对象，典型的访问方式是 HTTP。</p><p>Ingress 可以提供负载均衡、SSL 终结和基于名称的虚拟托管。</p><h2 id="Ingress-是什么？"><a href="#Ingress-是什么？" class="headerlink" title="Ingress 是什么？"></a>Ingress 是什么？</h2><p><a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.23/#ingress-v1beta1-networking-k8s-io">Ingress</a> 公开了从集群外部到集群内<a href="https://kubernetes.io/zh/docs/concepts/services-networking/service/">服务</a>的 HTTP 和 HTTPS 路由。 流量路由由 Ingress 资源上定义的规则控制。</p><p>下面是一个将所有流量都发送到同一 Service 的简单 Ingress 示例：</p><p><img src="/images/%E5%AD%A6%E4%B9%A0Kubernetes%E7%B3%BB%E5%88%97%E4%B9%8B%E6%A6%82%E5%BF%B5/ingress.png" alt="ingress"></p><p>可以将 Ingress 配置为服务提供外部可访问的 URL、负载均衡流量、终止 SSL/TLS，以及提供基于名称的虚拟主机等能力。 <a href="https://kubernetes.io/zh/docs/concepts/services-networking/ingress-controllers">Ingress 控制器</a> 通常负责通过负载均衡器来实现 Ingress，尽管它也可以配置边缘路由器或其他前端来帮助处理流量。</p><p>Ingress 不会公开任意端口或协议。 将 HTTP 和 HTTPS 以外的服务公开到 Internet 时，通常使用 <a href="https://kubernetes.io/zh/docs/concepts/services-networking/service/#nodeport">Service.Type=NodePort</a> 或 <a href="https://kubernetes.io/zh/docs/concepts/services-networking/service/#loadbalancer">Service.Type=LoadBalancer</a> 类型的服务。</p><h2 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h2><p>你必须具有 <a href="https://kubernetes.io/zh/docs/concepts/services-networking/ingress-controllers">Ingress 控制器</a> 才能满足 Ingress 的要求。 仅创建 Ingress 资源本身没有任何效果。</p><p>你可能需要部署 Ingress 控制器，例如 <a href="https://kubernetes.github.io/ingress-nginx/deploy/">ingress-nginx</a>。 你可以从许多 <a href="https://kubernetes.io/zh/docs/concepts/services-networking/ingress-controllers">Ingress 控制器</a> 中进行选择。</p><p>理想情况下，所有 Ingress 控制器都应符合参考规范。但实际上，不同的 Ingress 控制器操作略有不同。</p><h2 id="Ingress-资源"><a href="#Ingress-资源" class="headerlink" title="Ingress 资源"></a>Ingress 资源</h2><p>一个最小的 Ingress 资源示例（service/networking/minimal-ingress.yaml）：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.k8s.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Ingress</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">minimal-ingress</span></span><br><span class="line">  <span class="attr">annotations:</span></span><br><span class="line">    <span class="attr">nginx.ingress.kubernetes.io/rewrite-target:</span> <span class="string">/</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">rules:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">http:</span></span><br><span class="line">      <span class="attr">paths:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">path:</span> <span class="string">/testpath</span></span><br><span class="line">        <span class="attr">pathType:</span> <span class="string">Prefix</span></span><br><span class="line">        <span class="attr">backend:</span></span><br><span class="line">          <span class="attr">service:</span></span><br><span class="line">            <span class="attr">name:</span> <span class="string">test</span></span><br><span class="line">            <span class="attr">port:</span></span><br><span class="line">              <span class="attr">number:</span> <span class="number">80</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="Ingress-规则"><a href="#Ingress-规则" class="headerlink" title="Ingress 规则"></a>Ingress 规则</h3><p>每个 HTTP 规则都包含以下信息：</p><ul><li>可选的 <code>host</code>。在此示例中，未指定 <code>host</code>，因此该规则适用于通过指定 IP 地址的所有入站 HTTP 通信。 如果提供了 <code>host</code>（例如 foo.bar.com），则 <code>rules</code> 适用于该 <code>host</code>。</li><li>路径列表 paths（例如，<code>/testpath</code>）,每个路径都有一个由 <code>serviceName</code> 和 <code>servicePort</code> 定义的关联后端。 在负载均衡器将流量定向到引用的服务之前，主机和路径都必须匹配传入请求的内容。</li><li><code>backend</code>（后端）是 <a href="https://kubernetes.io/zh/docs/concepts/services-networking/service/">Service 文档</a>中所述的服务和端口名称的组合。 与规则的 <code>host</code> 和 <code>path</code> 匹配的对 Ingress 的 HTTP（和 HTTPS ）请求将发送到列出的 <code>backend</code>。</li></ul><p>通常在 Ingress 控制器中会配置 <code>defaultBackend</code>（默认后端），以服务于任何不符合规约中 <code>path</code> 的请求。</p><h3 id="DefaultBackend"><a href="#DefaultBackend" class="headerlink" title="DefaultBackend"></a>DefaultBackend</h3><p>没有 <code>rules</code> 的 Ingress 将所有流量发送到同一个默认后端。 <code>defaultBackend</code> 通常是 <a href="https://kubernetes.io/zh/docs/concepts/services-networking/ingress-controllers">Ingress 控制器</a> 的配置选项，而非在 Ingress 资源中指定。</p><p>如果 <code>hosts</code> 或 <code>paths</code> 都没有与 Ingress 对象中的 HTTP 请求匹配，则流量将路由到默认后端。</p><h3 id="资源后端"><a href="#资源后端" class="headerlink" title="资源后端"></a>资源后端</h3><p><code>Resource</code> 后端是一个 <code>ObjectRef</code>，指向同一名字空间中的另一个 Kubernetes，将其作为 Ingress 对象。<code>Resource</code> 与 <code>Service</code> 配置是互斥的，在 二者均被设置时会无法通过合法性检查。 <code>Resource</code> 后端的一种常见用法是将所有入站数据导向带有静态资产的对象存储后端。</p><p>(service/networking/ingress-resource-backend.yaml)</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.k8s.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Ingress</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">ingress-resource-backend</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">defaultBackend:</span></span><br><span class="line">    <span class="attr">resource:</span></span><br><span class="line">      <span class="attr">apiGroup:</span> <span class="string">k8s.example.com</span></span><br><span class="line">      <span class="attr">kind:</span> <span class="string">StorageBucket</span></span><br><span class="line">      <span class="attr">name:</span> <span class="string">static-assets</span></span><br><span class="line">  <span class="attr">rules:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">http:</span></span><br><span class="line">        <span class="attr">paths:</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">path:</span> <span class="string">/icons</span></span><br><span class="line">            <span class="attr">pathType:</span> <span class="string">ImplementationSpecific</span></span><br><span class="line">            <span class="attr">backend:</span></span><br><span class="line">              <span class="attr">resource:</span></span><br><span class="line">                <span class="attr">apiGroup:</span> <span class="string">k8s.example.com</span></span><br><span class="line">                <span class="attr">kind:</span> <span class="string">StorageBucket</span></span><br><span class="line">                <span class="attr">name:</span> <span class="string">icon-assets</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>创建了如上的 Ingress 之后，你可以使用下面的命令查看它：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">kubectl describe ingress ingress-resource-backend</span><br><span class="line">Name:             ingress-resource-backend</span><br><span class="line">Namespace:        default</span><br><span class="line">Address:</span><br><span class="line">Default backend:  APIGroup: k8s.example.com, Kind: StorageBucket, Name: static-assets</span><br><span class="line">Rules:</span><br><span class="line">  Host        Path  Backends</span><br><span class="line">  ----        ----  --------</span><br><span class="line">  *</span><br><span class="line">              /icons   APIGroup: k8s.example.com, Kind: StorageBucket, Name: icon-assets</span><br><span class="line">Annotations:  &lt;none&gt;</span><br><span class="line">Events:       &lt;none&gt;</span><br></pre></td></tr></table></figure><h3 id="路径类型"><a href="#路径类型" class="headerlink" title="路径类型"></a>路径类型</h3><p>Ingress 中的每个路径都需要有对应的路径类型（Path Type）。未明确设置 <code>pathType</code> 的路径无法通过合法性检查。当前支持的路径类型有三种：</p><ul><li><code>ImplementationSpecific</code>：对于这种路径类型，匹配方法取决于 IngressClass。 具体实现可以将其作为单独的 <code>pathType</code> 处理或者与 <code>Prefix</code> 或 <code>Exact</code> 类型作相同处理。</li><li><code>Exact</code>：精确匹配 URL 路径，且区分大小写。</li><li><code>Prefix</code>：基于以 <code>/</code> 分隔的 URL 路径前缀匹配。匹配区分大小写，并且对路径中的元素逐个完成。 路径元素指的是由 <code>/</code> 分隔符分隔的路径中的标签列表。 如果每个 <em>p</em> 都是请求路径 <em>p</em> 的元素前缀，则请求与路径 <em>p</em> 匹配。</li></ul><h3 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h3><table><thead><tr><th>类型</th><th>路径</th><th>请求路径</th><th>匹配与否？</th></tr></thead><tbody><tr><td>Prefix</td><td><code>/</code></td><td>（所有路径）</td><td>是</td></tr><tr><td>Exact</td><td><code>/foo</code></td><td><code>/foo</code></td><td>是</td></tr><tr><td>Exact</td><td><code>/foo</code></td><td><code>/bar</code></td><td>否</td></tr><tr><td>Exact</td><td><code>/foo</code></td><td><code>/foo/</code></td><td>否</td></tr><tr><td>Exact</td><td><code>/foo/</code></td><td><code>/foo</code></td><td>否</td></tr><tr><td>Prefix</td><td><code>/foo</code></td><td><code>/foo</code>, <code>/foo/</code></td><td>是</td></tr><tr><td>Prefix</td><td><code>/foo/</code></td><td><code>/foo</code>, <code>/foo/</code></td><td>是</td></tr><tr><td>Prefix</td><td><code>/aaa/bb</code></td><td><code>/aaa/bbb</code></td><td>否</td></tr><tr><td>Prefix</td><td><code>/aaa/bbb</code></td><td><code>/aaa/bbb</code></td><td>是</td></tr><tr><td>Prefix</td><td><code>/aaa/bbb/</code></td><td><code>/aaa/bbb</code></td><td>是，忽略尾部斜线</td></tr><tr><td>Prefix</td><td><code>/aaa/bbb</code></td><td><code>/aaa/bbb/</code></td><td>是，匹配尾部斜线</td></tr><tr><td>Prefix</td><td><code>/aaa/bbb</code></td><td><code>/aaa/bbb/ccc</code></td><td>是，匹配子路径</td></tr><tr><td>Prefix</td><td><code>/aaa/bbb</code></td><td><code>/aaa/bbbxyz</code></td><td>否，字符串前缀不匹配</td></tr><tr><td>Prefix</td><td><code>/</code>, <code>/aaa</code></td><td><code>/aaa/ccc</code></td><td>是，匹配 <code>/aaa</code> 前缀</td></tr><tr><td>Prefix</td><td><code>/</code>, <code>/aaa</code>, <code>/aaa/bbb</code></td><td><code>/aaa/bbb</code></td><td>是，匹配 <code>/aaa/bbb</code> 前缀</td></tr><tr><td>Prefix</td><td><code>/</code>, <code>/aaa</code>, <code>/aaa/bbb</code></td><td><code>/ccc</code></td><td>是，匹配 <code>/</code> 前缀</td></tr><tr><td>Prefix</td><td><code>/aaa</code></td><td><code>/ccc</code></td><td>否，使用默认后端</td></tr><tr><td>混合</td><td><code>/foo</code> (Prefix), <code>/foo</code> (Exact)</td><td><code>/foo</code></td><td>是，优选 Exact 类型</td></tr></tbody></table><h4 id="多重匹配"><a href="#多重匹配" class="headerlink" title="多重匹配"></a>多重匹配</h4><p>在某些情况下，Ingress 中的多条路径会匹配同一个请求。 这种情况下最长的匹配路径优先。 如果仍然有两条同等的匹配路径，则精确路径类型优先于前缀路径类型。</p><h2 id="主机名通配符"><a href="#主机名通配符" class="headerlink" title="主机名通配符"></a>主机名通配符</h2><p>主机名可以是精确匹配（例如“<code>foo.bar.com</code>”）或者使用通配符来匹配 （例如“<code>*.foo.com</code>”）。 精确匹配要求 HTTP <code>host</code> 头部字段与 <code>host</code> 字段值完全匹配。 通配符匹配则要求 HTTP <code>host</code> 头部字段与通配符规则中的后缀部分相同。</p><table><thead><tr><th>主机</th><th>host 头部</th><th>匹配与否？</th></tr></thead><tbody><tr><td><code>*.foo.com</code></td><td><code>bar.foo.com</code></td><td>基于相同的后缀匹配</td></tr><tr><td><code>*.foo.com</code></td><td><code>baz.bar.foo.com</code></td><td>不匹配，通配符仅覆盖了一个 DNS 标签</td></tr><tr><td><code>*.foo.com</code></td><td><code>foo.com</code></td><td>不匹配，通配符仅覆盖了一个 DNS 标签</td></tr></tbody></table><p>service/networking/ingress-wildcard-host.yaml</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.k8s.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Ingress</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">ingress-wildcard-host</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">rules:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">host:</span> <span class="string">&quot;foo.bar.com&quot;</span></span><br><span class="line">    <span class="attr">http:</span></span><br><span class="line">      <span class="attr">paths:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">pathType:</span> <span class="string">Prefix</span></span><br><span class="line">        <span class="attr">path:</span> <span class="string">&quot;/bar&quot;</span></span><br><span class="line">        <span class="attr">backend:</span></span><br><span class="line">          <span class="attr">service:</span></span><br><span class="line">            <span class="attr">name:</span> <span class="string">service1</span></span><br><span class="line">            <span class="attr">port:</span></span><br><span class="line">              <span class="attr">number:</span> <span class="number">80</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">host:</span> <span class="string">&quot;*.foo.com&quot;</span></span><br><span class="line">    <span class="attr">http:</span></span><br><span class="line">      <span class="attr">paths:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">pathType:</span> <span class="string">Prefix</span></span><br><span class="line">        <span class="attr">path:</span> <span class="string">&quot;/foo&quot;</span></span><br><span class="line">        <span class="attr">backend:</span></span><br><span class="line">          <span class="attr">service:</span></span><br><span class="line">            <span class="attr">name:</span> <span class="string">service2</span></span><br><span class="line">            <span class="attr">port:</span></span><br><span class="line">              <span class="attr">number:</span> <span class="number">80</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="Ingress-类"><a href="#Ingress-类" class="headerlink" title="Ingress 类"></a>Ingress 类</h2><p>Ingress 可以由不同的控制器实现，通常使用不同的配置。 每个 Ingress 应当指定一个类，也就是一个对 IngressClass 资源的引用。 IngressClass 资源包含额外的配置，其中包括应当实现该类的控制器名称。</p><p>service/networking/external-lb.yaml</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.k8s.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">IngressClass</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">external-lb</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">controller:</span> <span class="string">example.com/ingress-controller</span></span><br><span class="line">  <span class="attr">parameters:</span></span><br><span class="line">    <span class="attr">apiGroup:</span> <span class="string">k8s.example.com</span></span><br><span class="line">    <span class="attr">kind:</span> <span class="string">IngressParameters</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">external-lb</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>ngressClass 资源包含一个可选的 <code>parameters</code> 字段，可用于为该类引用额外的、 特定于具体实现的配置。</p><h4 id="名字空间域的参数"><a href="#名字空间域的参数" class="headerlink" title="名字空间域的参数"></a>名字空间域的参数</h4><p><strong>FEATURE STATE:</strong> <code>Kubernetes v1.22 [beta]</code></p><p><code>parameters</code> 字段有一个 <code>scope</code> 和 <code>namespace</code> 字段，可用来引用特定 于名字空间的资源，对 Ingress 类进行配置。 <code>scope</code> 字段默认为 <code>Cluster</code>，表示默认是集群作用域的资源。 将 <code>scope</code> 设置为 <code>Namespace</code> 并设置 <code>namespace</code> 字段就可以引用某特定 名字空间中的参数资源。</p><p>有了名字空间域的参数，就不再需要为一个参数资源配置集群范围的 CustomResourceDefinition。 除此之外，之前对访问集群范围的资源进行授权，需要用到 RBAC 相关的资源，现在也不再需要了。</p><p>service/networking/namespaced-params.yaml </p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.k8s.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">IngressClass</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">external-lb</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">controller:</span> <span class="string">example.com/ingress-controller</span></span><br><span class="line">  <span class="attr">parameters:</span></span><br><span class="line">    <span class="attr">apiGroup:</span> <span class="string">k8s.example.com</span></span><br><span class="line">    <span class="attr">kind:</span> <span class="string">IngressParameters</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">external-lb</span></span><br><span class="line">    <span class="attr">namespace:</span> <span class="string">external-configuration</span></span><br><span class="line">    <span class="attr">scope:</span> <span class="string">Namespace</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="废弃的注解"><a href="#废弃的注解" class="headerlink" title="废弃的注解"></a>废弃的注解</h3><p>在 Kubernetes 1.18 版本引入 IngressClass 资源和 <code>ingressClassName</code> 字段之前， Ingress 类是通过 Ingress 中的一个 <code>kubernetes.io/ingress.class</code> 注解来指定的。 这个注解从未被正式定义过，但是得到了 Ingress 控制器的广泛支持。</p><p>Ingress 中新的 <code>ingressClassName</code> 字段是该注解的替代品，但并非完全等价。 该注解通常用于引用实现该 Ingress 的控制器的名称， 而这个新的字段则是对一个包含额外 Ingress 配置的 IngressClass 资源的引用， 包括 Ingress 控制器的名称。</p><h3 id="默认-Ingress-类"><a href="#默认-Ingress-类" class="headerlink" title="默认 Ingress 类"></a>默认 Ingress 类</h3><p>你可以将一个特定的 IngressClass 标记为集群默认 Ingress 类。 将一个 IngressClass 资源的 <code>ingressclass.kubernetes.io/is-default-class</code> 注解设置为 <code>true</code> 将确保新的未指定 <code>ingressClassName</code> 字段的 Ingress 能够分配为这个默认的 IngressClass.</p><p><strong>注意：</strong> 如果集群中有多个 IngressClass 被标记为默认，准入控制器将阻止创建新的未指定 <code>ingressClassName</code> 的 Ingress 对象。 解决这个问题只需确保集群中最多只能有一个 IngressClass 被标记为默认。</p><h2 id="Ingress-类型"><a href="#Ingress-类型" class="headerlink" title="Ingress 类型"></a>Ingress 类型</h2><h3 id="由单个-Service-来完成的-Ingress"><a href="#由单个-Service-来完成的-Ingress" class="headerlink" title="由单个 Service 来完成的 Ingress"></a>由单个 Service 来完成的 Ingress</h3><p>现有的 Kubernetes 概念允许你暴露单个 Service (参见<a href="https://kubernetes.io/zh/docs/concepts/services-networking/ingress/#alternatives">替代方案</a>)。 你也可以通过指定无规则的 <em>默认后端</em> 来对 Ingress 进行此操作。</p><p>service/networking/test-ingress.yaml </p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.k8s.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Ingress</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">test-ingress</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">defaultBackend:</span></span><br><span class="line">    <span class="attr">service:</span></span><br><span class="line">      <span class="attr">name:</span> <span class="string">test</span></span><br><span class="line">      <span class="attr">port:</span></span><br><span class="line">        <span class="attr">number:</span> <span class="number">80</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>如果使用 <code>kubectl apply -f</code> 创建此 Ingress，则应该能够查看刚刚添加的 Ingress 的状态：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kubectl get ingress test-ingress</span><br><span class="line">NAME           CLASS         HOSTS   ADDRESS         PORTS   AGE</span><br><span class="line">test-ingress   external-lb   *       203.0.113.123   80      59s</span><br></pre></td></tr></table></figure><p>其中 <code>203.0.113.123</code> 是由 Ingress 控制器分配以满足该 Ingress 的 IP。</p><h3 id="简单扇出"><a href="#简单扇出" class="headerlink" title="简单扇出"></a>简单扇出</h3><p>一个扇出（fanout）配置根据请求的 HTTP URI 将来自同一 IP 地址的流量路由到多个 Service。 Ingress 允许你将负载均衡器的数量降至最低。例如，这样的设置：<img src="/images/%E5%AD%A6%E4%B9%A0Kubernetes%E7%B3%BB%E5%88%97%E4%B9%8B%E6%A6%82%E5%BF%B5/ingress-fanout.png" alt="ingress-fanout"></p><p>将需要一个如下所示的 Ingress(service/networking/simple-fanout-example.yaml)：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.k8s.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Ingress</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">simple-fanout-example</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">rules:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">host:</span> <span class="string">foo.bar.com</span></span><br><span class="line">    <span class="attr">http:</span></span><br><span class="line">      <span class="attr">paths:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">path:</span> <span class="string">/foo</span></span><br><span class="line">        <span class="attr">pathType:</span> <span class="string">Prefix</span></span><br><span class="line">        <span class="attr">backend:</span></span><br><span class="line">          <span class="attr">service:</span></span><br><span class="line">            <span class="attr">name:</span> <span class="string">service1</span></span><br><span class="line">            <span class="attr">port:</span></span><br><span class="line">              <span class="attr">number:</span> <span class="number">4200</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">path:</span> <span class="string">/bar</span></span><br><span class="line">        <span class="attr">pathType:</span> <span class="string">Prefix</span></span><br><span class="line">        <span class="attr">backend:</span></span><br><span class="line">          <span class="attr">service:</span></span><br><span class="line">            <span class="attr">name:</span> <span class="string">service2</span></span><br><span class="line">            <span class="attr">port:</span></span><br><span class="line">              <span class="attr">number:</span> <span class="number">8080</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>当你使用 <code>kubectl apply -f</code> 创建 Ingress 时：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">kubectl describe ingress simple-fanout-example</span><br><span class="line">Name:             simple-fanout-example</span><br><span class="line">Namespace:        default</span><br><span class="line">Address:          178.91.123.132</span><br><span class="line">Default backend:  default-http-backend:80 (10.8.2.3:8080)</span><br><span class="line">Rules:</span><br><span class="line">  Host         Path  Backends</span><br><span class="line">  ----         ----  --------</span><br><span class="line">  foo.bar.com</span><br><span class="line">               /foo   service1:4200 (10.8.0.90:4200)</span><br><span class="line">               /bar   service2:8080 (10.8.0.91:8080)</span><br><span class="line">Annotations:</span><br><span class="line">  nginx.ingress.kubernetes.io/rewrite-target:  /</span><br><span class="line">Events:</span><br><span class="line">  Type     Reason  Age                From                     Message</span><br><span class="line">  ----     ------  ----               ----                     -------</span><br><span class="line">  Normal   ADD     22s                loadbalancer-controller  default/test</span><br></pre></td></tr></table></figure><p>Ingress 控制器将提供实现特定的负载均衡器来满足 Ingress， 只要 Service (<code>service1</code>，<code>service2</code>) 存在。 当它这样做时，你会在 Address 字段看到负载均衡器的地址。</p><h3 id="基于名称的虚拟托管"><a href="#基于名称的虚拟托管" class="headerlink" title="基于名称的虚拟托管"></a>基于名称的虚拟托管</h3><p>基于名称的虚拟主机支持将针对多个主机名的 HTTP 流量路由到同一 IP 地址上。</p><p><img src="/images/%E5%AD%A6%E4%B9%A0Kubernetes%E7%B3%BB%E5%88%97%E4%B9%8B%E6%A6%82%E5%BF%B5/ingress-name.png" alt="ingress-name"></p><p>以下 Ingress 让后台负载均衡器基于<a href="https://tools.ietf.org/html/rfc7230#section-5.4">host 头部字段</a> 来路由请求。</p><p>service/networking/name-virtual-host-ingress.yaml</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.k8s.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Ingress</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">name-virtual-host-ingress</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">rules:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">host:</span> <span class="string">foo.bar.com</span></span><br><span class="line">    <span class="attr">http:</span></span><br><span class="line">      <span class="attr">paths:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">pathType:</span> <span class="string">Prefix</span></span><br><span class="line">        <span class="attr">path:</span> <span class="string">&quot;/&quot;</span></span><br><span class="line">        <span class="attr">backend:</span></span><br><span class="line">          <span class="attr">service:</span></span><br><span class="line">            <span class="attr">name:</span> <span class="string">service1</span></span><br><span class="line">            <span class="attr">port:</span></span><br><span class="line">              <span class="attr">number:</span> <span class="number">80</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">host:</span> <span class="string">bar.foo.com</span></span><br><span class="line">    <span class="attr">http:</span></span><br><span class="line">      <span class="attr">paths:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">pathType:</span> <span class="string">Prefix</span></span><br><span class="line">        <span class="attr">path:</span> <span class="string">&quot;/&quot;</span></span><br><span class="line">        <span class="attr">backend:</span></span><br><span class="line">          <span class="attr">service:</span></span><br><span class="line">            <span class="attr">name:</span> <span class="string">service2</span></span><br><span class="line">            <span class="attr">port:</span></span><br><span class="line">              <span class="attr">number:</span> <span class="number">80</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>如果你创建的 Ingress 资源没有在 <code>rules</code> 中定义的任何 <code>hosts</code>，则可以匹配指向 Ingress 控制器 IP 地址的任何网络流量，而无需基于名称的虚拟主机。</p><p>例如，以下 Ingress 会将针对 <code>first.bar.com</code> 的请求流量路由到 <code>service1</code>， 将针对 <code>second.bar.com</code> 的请求流量路由到 <code>service2</code>， 而针对该 IP 地址的、没有在请求中定义主机名的请求流量会被路由（即，不提供请求标头） 到 <code>service3</code>。</p><p>service/networking/name-virtual-host-ingress-no-third-host.yaml</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.k8s.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Ingress</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">name-virtual-host-ingress-no-third-host</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">rules:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">host:</span> <span class="string">first.bar.com</span></span><br><span class="line">    <span class="attr">http:</span></span><br><span class="line">      <span class="attr">paths:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">pathType:</span> <span class="string">Prefix</span></span><br><span class="line">        <span class="attr">path:</span> <span class="string">&quot;/&quot;</span></span><br><span class="line">        <span class="attr">backend:</span></span><br><span class="line">          <span class="attr">service:</span></span><br><span class="line">            <span class="attr">name:</span> <span class="string">service1</span></span><br><span class="line">            <span class="attr">port:</span></span><br><span class="line">              <span class="attr">number:</span> <span class="number">80</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">host:</span> <span class="string">second.bar.com</span></span><br><span class="line">    <span class="attr">http:</span></span><br><span class="line">      <span class="attr">paths:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">pathType:</span> <span class="string">Prefix</span></span><br><span class="line">        <span class="attr">path:</span> <span class="string">&quot;/&quot;</span></span><br><span class="line">        <span class="attr">backend:</span></span><br><span class="line">          <span class="attr">service:</span></span><br><span class="line">            <span class="attr">name:</span> <span class="string">service2</span></span><br><span class="line">            <span class="attr">port:</span></span><br><span class="line">              <span class="attr">number:</span> <span class="number">80</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">http:</span></span><br><span class="line">      <span class="attr">paths:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">pathType:</span> <span class="string">Prefix</span></span><br><span class="line">        <span class="attr">path:</span> <span class="string">&quot;/&quot;</span></span><br><span class="line">        <span class="attr">backend:</span></span><br><span class="line">          <span class="attr">service:</span></span><br><span class="line">            <span class="attr">name:</span> <span class="string">service3</span></span><br><span class="line">            <span class="attr">port:</span></span><br><span class="line">              <span class="attr">number:</span> <span class="number">80</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="TLS"><a href="#TLS" class="headerlink" title="TLS"></a>TLS</h3><p>你可以通过设定包含 TLS 私钥和证书的<a href="https://kubernetes.io/zh/docs/concepts/configuration/secret/">Secret</a> 来保护 Ingress。 Ingress 只支持单个 TLS 端口 443，并假定 TLS 连接终止于 Ingress 节点 （与 Service 及其 Pod 之间的流量都以明文传输）。 如果 Ingress 中的 TLS 配置部分指定了不同的主机，那么它们将根据通过 SNI TLS 扩展指定的主机名 （如果 Ingress 控制器支持 SNI）在同一端口上进行复用。 TLS Secret 必须包含名为 <code>tls.crt</code> 和 <code>tls.key</code> 的键名。 这些数据包含用于 TLS 的证书和私钥。例如：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Secret</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">testsecret-tls</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">default</span></span><br><span class="line"><span class="attr">data:</span></span><br><span class="line">  <span class="attr">tls.crt:</span> <span class="string">base64</span> <span class="string">编码的</span> <span class="string">cert</span></span><br><span class="line">  <span class="attr">tls.key:</span> <span class="string">base64</span> <span class="string">编码的</span> <span class="string">key</span></span><br><span class="line"><span class="attr">type:</span> <span class="string">kubernetes.io/tls</span></span><br></pre></td></tr></table></figure><p>在 Ingress 中引用此 Secret 将会告诉 Ingress 控制器使用 TLS 加密从客户端到负载均衡器的通道。 你需要确保创建的 TLS Secret 创建自包含 <code>https-example.foo.com</code> 的公用名称（CN）的证书。 这里的公共名称也被称为全限定域名（FQDN）。</p><h3 id="负载均衡"><a href="#负载均衡" class="headerlink" title="负载均衡"></a>负载均衡</h3><p>Ingress 控制器启动引导时使用一些适用于所有 Ingress 的负载均衡策略设置， 例如负载均衡算法、后端权重方案和其他等。 更高级的负载均衡概念（例如持久会话、动态权重）尚未通过 Ingress 公开。 你可以通过用于服务的负载均衡器来获取这些功能。</p><p>值得注意的是，尽管健康检查不是通过 Ingress 直接暴露的，在 Kubernetes 中存在并行的概念，比如 <a href="https://kubernetes.io/zh/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/">就绪检查</a>， 允许你实现相同的目的。 请检查特定控制器的说明文档（ <a href="https://git.k8s.io/ingress-nginx/README.md">nginx</a>， <a href="https://git.k8s.io/ingress-gce/README.md#health-checks">GCE</a>） 以了解它们是怎样处理健康检查的。</p><h2 id="更新-Ingress"><a href="#更新-Ingress" class="headerlink" title="更新 Ingress"></a>更新 Ingress</h2><p>要更新现有的 Ingress 以添加新的 Host，可以通过编辑资源来对其进行更新：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">kubectl describe ingress test</span><br><span class="line">Name:             test</span><br><span class="line">Namespace:        default</span><br><span class="line">Address:          178.91.123.132</span><br><span class="line">Default backend:  default-http-backend:80 (10.8.2.3:8080)</span><br><span class="line">Rules:</span><br><span class="line">  Host         Path  Backends</span><br><span class="line">  ----         ----  --------</span><br><span class="line">  foo.bar.com</span><br><span class="line">               /foo   service1:80 (10.8.0.90:80)</span><br><span class="line">Annotations:</span><br><span class="line">  nginx.ingress.kubernetes.io/rewrite-target:  /</span><br><span class="line">Events:</span><br><span class="line">  Type     Reason  Age                From                     Message</span><br><span class="line">  ----     ------  ----               ----                     -------</span><br><span class="line">  Normal   ADD     35s                loadbalancer-controller  default/test</span><br><span class="line">kubectl edit ingress test</span><br></pre></td></tr></table></figure><p>这一命令将打开编辑器，允许你以 YAML 格式编辑现有配置。 修改它来增加新的主机：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">rules:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">host:</span> <span class="string">foo.bar.com</span></span><br><span class="line">    <span class="attr">http:</span></span><br><span class="line">      <span class="attr">paths:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">backend:</span></span><br><span class="line">          <span class="attr">serviceName:</span> <span class="string">service1</span></span><br><span class="line">          <span class="attr">servicePort:</span> <span class="number">80</span></span><br><span class="line">        <span class="attr">path:</span> <span class="string">/foo</span></span><br><span class="line">        <span class="attr">pathType:</span> <span class="string">Prefix</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">host:</span> <span class="string">bar.baz.com</span></span><br><span class="line">    <span class="attr">http:</span></span><br><span class="line">      <span class="attr">paths:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">backend:</span></span><br><span class="line">          <span class="attr">serviceName:</span> <span class="string">service2</span></span><br><span class="line">          <span class="attr">servicePort:</span> <span class="number">80</span></span><br><span class="line">        <span class="attr">path:</span> <span class="string">/foo</span></span><br><span class="line">        <span class="attr">pathType:</span> <span class="string">Prefix</span></span><br><span class="line"><span class="string">..</span></span><br></pre></td></tr></table></figure><p>保存更改后，kubectl 将更新 API 服务器中的资源，该资源将告诉 Ingress 控制器重新配置负载均衡器。</p><p>验证：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">kubectl describe ingress test</span><br><span class="line">Name:             test</span><br><span class="line">Namespace:        default</span><br><span class="line">Address:          178.91.123.132</span><br><span class="line">Default backend:  default-http-backend:80 (10.8.2.3:8080)</span><br><span class="line">Rules:</span><br><span class="line">  Host         Path  Backends</span><br><span class="line">  ----         ----  --------</span><br><span class="line">  foo.bar.com</span><br><span class="line">               /foo   service1:80 (10.8.0.90:80)</span><br><span class="line">  bar.baz.com</span><br><span class="line">               /foo   service2:80 (10.8.0.91:80)</span><br><span class="line">Annotations:</span><br><span class="line">  nginx.ingress.kubernetes.io/rewrite-target:  /</span><br><span class="line">Events:</span><br><span class="line">  Type     Reason  Age                From                     Message</span><br><span class="line">  ----     ------  ----               ----                     -------</span><br><span class="line">  Normal   ADD     45s                loadbalancer-controller  default/test</span><br></pre></td></tr></table></figure><p>你也可以通过 <code>kubectl replace -f</code> 命令调用修改后的 Ingress yaml 文件来获得同样的结果。</p><h2 id="跨可用区失败"><a href="#跨可用区失败" class="headerlink" title="跨可用区失败"></a>跨可用区失败</h2><p>不同的云厂商使用不同的技术来实现跨故障域的流量分布。详情请查阅相关 Ingress 控制器的文档。 </p><h1 id="Ingress-控制器"><a href="#Ingress-控制器" class="headerlink" title="Ingress 控制器"></a>Ingress 控制器</h1><p>为了让 Ingress 资源工作，集群必须有一个正在运行的 Ingress 控制器。</p><p>与作为 <code>kube-controller-manager</code> 可执行文件的一部分运行的其他类型的控制器不同， Ingress 控制器不是随集群自动启动的。 基于此页面，你可选择最适合你的集群的 ingress 控制器实现。</p><p>Kubernetes 作为一个项目，目前支持和维护 <a href="https://github.com/kubernetes-sigs/aws-load-balancer-controller#readme">AWS</a>， <a href="https://git.k8s.io/ingress-gce/README.md">GCE</a> 和 <a href="https://git.k8s.io/ingress-nginx/README.md#readme">nginx</a> Ingress 控制器。</p><h2 id="其他控制器"><a href="#其他控制器" class="headerlink" title="其他控制器"></a>其他控制器</h2><p><strong>说明：</strong> 本部分链接到提供 Kubernetes 所需功能的第三方项目。Kubernetes 项目作者不负责这些项目。此页面遵循<a href="https://github.com/cncf/foundation/blob/master/website-guidelines.md">CNCF 网站指南</a>，按字母顺序列出项目。要将项目添加到此列表中，请在提交更改之前阅读<a href="https://kubernetes.io/docs/contribute/style/content-guide/#third-party-content">内容指南</a>。</p><ul><li><p><a href="https://azure.github.io/application-gateway-kubernetes-ingress/">AKS 应用程序网关 Ingress 控制器</a> 是一个配置 <a href="https://docs.microsoft.com/azure/application-gateway/overview">Azure 应用程序网关</a> 的 Ingress 控制器。</p></li><li><p><a href="https://www.getambassador.io/">Ambassador</a> API 网关是一个基于 <a href="https://www.envoyproxy.io/">Envoy</a> 的 Ingress 控制器。</p></li><li><p><a href="https://github.com/apache/apisix-ingress-controller">Apache APISIX Ingress 控制器</a> 是一个基于 <a href="https://github.com/apache/apisix">Apache APISIX 网关</a> 的 Ingress 控制器。</p></li><li><p><a href="https://github.com/vmware/load-balancer-and-ingress-services-for-kubernetes">Avi Kubernetes Operator</a> 使用 <a href="https://avinetworks.com/">VMware NSX Advanced Load Balancer</a> 提供第 4 到第 7 层的负载均衡。</p></li><li><p><a href="https://github.com/bfenetworks/ingress-bfe">BFE Ingress 控制器</a> 是一个基于 <a href="https://www.bfe-networks.net/">BFE</a> 的 Ingress 控制器。</p></li><li><p><a href="https://github.com/citrix/citrix-k8s-ingress-controller#readme">Citrix Ingress 控制器</a> 可以用来与 Citrix Application Delivery Controller 一起使用。</p></li><li><p><a href="https://projectcontour.io/">Contour</a> 是一个基于 <a href="https://www.envoyproxy.io/">Envoy</a> 的 Ingress 控制器。</p></li><li><p><a href="https://getenroute.io/">EnRoute</a> 是一个基于 <a href="https://www.envoyproxy.io/">Envoy</a> API 网关， 可以作为 Ingress 控制器来执行。</p></li><li><p><a href="https://github.com/megaease/easegress/blob/main/doc/ingresscontroller.md">Easegress IngressController</a> 是一个基于 <a href="https://megaease.com/easegress/">Easegress</a> API 网关，可以作为 Ingress 控制器来执行。</p></li><li><p>F5 BIG-IP 的 <a href="https://clouddocs.f5.com/products/connectors/k8s-bigip-ctlr/latest">用于 Kubernetes 的容器 Ingress 服务</a> 让你能够使用 Ingress 来配置 F5 BIG-IP 虚拟服务器。</p></li><li><p><a href="https://gloo.solo.io/">Gloo</a> 是一个开源的、基于 <a href="https://www.envoyproxy.io/">Envoy</a> 的 Ingress 控制器，能够提供 API 网关功能，</p></li><li><p><a href="https://haproxy-ingress.github.io/">HAProxy Ingress</a> 针对 <a href="https://www.haproxy.org/#desc">HAProxy</a> 的 Ingress 控制器。</p></li><li><p><a href="https://github.com/haproxytech/kubernetes-ingress#readme">用于 Kubernetes 的 HAProxy Ingress 控制器</a> 也是一个针对 <a href="https://www.haproxy.org/#desc">HAProxy</a> 的 Ingress 控制器。</p></li><li><p><a href="https://istio.io/latest/docs/tasks/traffic-management/ingress/kubernetes-ingress/">Istio Ingress</a> 是一个基于 <a href="https://istio.io/">Istio</a> 的 Ingress 控制器。</p></li><li><p><a href="https://github.com/Kong/kubernetes-ingress-controller#readme">用于 Kubernetes 的 Kong Ingress 控制器</a> 是一个用来驱动 <a href="https://konghq.com/kong/">Kong Gateway</a> 的 Ingress 控制器。</p></li><li><p><a href="https://www.nginx.com/products/nginx-ingress-controller/">用于 Kubernetes 的 NGINX Ingress 控制器</a> 能够与 <a href="https://www.nginx.com/resources/glossary/nginx/">NGINX</a> Web 服务器（作为代理） 一起使用。</p></li><li><p><a href="https://opensource.zalando.com/skipper/kubernetes/ingress-controller/">Skipper</a> HTTP 路由器和反向代理可用于服务组装，支持包括 Kubernetes Ingress 这类使用场景， 设计用来作为构造你自己的定制代理的库。</p></li><li><p><a href="https://doc.traefik.io/traefik/providers/kubernetes-ingress/">Traefik Kubernetes Ingress 提供程序</a> 是一个用于 <a href="https://traefik.io/traefik/">Traefik</a> 代理的 Ingress 控制器。</p></li><li><p><a href="https://github.com/TykTechnologies/tyk-operator">Tyk Operator</a> 使用自定义资源扩展 Ingress，为之带来 API 管理能力。Tyk Operator 使用开源的 Tyk Gateway &amp; Tyk Cloud 控制面。</p></li><li><p><a href="https://appscode.com/products/voyager">Voyager</a> 是一个针对 <a href="https://www.haproxy.org/#desc">HAProxy</a> 的 Ingress 控制器。</p></li></ul><h2 id="使用多个-Ingress-控制器"><a href="#使用多个-Ingress-控制器" class="headerlink" title="使用多个 Ingress 控制器"></a>使用多个 Ingress 控制器</h2><p>你可以在集群中部署<a href="https://git.k8s.io/ingress-nginx/docs/user-guide/multiple-ingress.md#multiple-ingress-controllers">任意数量的 ingress 控制器</a>。 创建 ingress 时，应该使用适当的 <a href="https://git.k8s.io/ingress-gce/docs/faq/README.md#how-do-i-run-multiple-ingress-controllers-in-the-same-cluster"><code>ingress.class</code></a> 注解每个 Ingress 以表明在集群中如果有多个 Ingress 控制器时，应该使用哪个 Ingress 控制器。</p><p>如果不定义 <code>ingress.class</code>，云提供商可能使用默认的 Ingress 控制器。</p><p>理想情况下，所有 Ingress 控制器都应满足此规范，但各种 Ingress 控制器的操作略有不同。</p><h1 id="网络策略"><a href="#网络策略" class="headerlink" title="网络策略"></a>网络策略</h1><p><a href="https://kubernetes.io/zh/docs/concepts/services-networking/network-policies/">https://kubernetes.io/zh/docs/concepts/services-networking/network-policies/</a></p><h1 id="IPv4-IPv6-双协议栈"><a href="#IPv4-IPv6-双协议栈" class="headerlink" title="IPv4/IPv6 双协议栈"></a>IPv4/IPv6 双协议栈</h1><p><a href="https://kubernetes.io/zh/docs/concepts/services-networking/dual-stack/">https://kubernetes.io/zh/docs/concepts/services-networking/dual-stack/</a></p>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;服务、负载均衡和联网&quot;&gt;&lt;a href=&quot;#服务、负载均衡和联网&quot; class=&quot;headerlink&quot; title=&quot;服务、负载均衡和联网&quot;&gt;&lt;/a&gt;服务、负载均衡和联网&lt;/h1&gt;&lt;h2 id=&quot;Kubernetes-网络模型&quot;&gt;&lt;a href=&quot;#Kubernetes-网络模型&quot; class=&quot;headerlink&quot; title=&quot;Kubernetes 网络模型&quot;&gt;&lt;/a&gt;Kubernetes 网络模型&lt;/h2&gt;&lt;p&gt;每一个 Pod 都有它自己的IP地址， 这就意味着你不需要显式地在 Pod 之间创建链接， 你几乎不需要处理容器端口到主机端口之间的映射。 这将形成一个干净的、向后兼容的模型；在这个模型里，从端口分配、命名、服务发现、 负载均衡、应用配置和迁移的角度来看， Pod 可以被视作虚拟机或者物理主机。&lt;/p&gt;</summary>
    
    
    
    
    <category term="Kubernetes" scheme="http://chengqian90.com/tags/Kubernetes/"/>
    
    <category term="k8s" scheme="http://chengqian90.com/tags/k8s/"/>
    
  </entry>
  
  <entry>
    <title>学习Kubernetes系列4——工作负载</title>
    <link href="http://chengqian90.com/%E5%AE%B9%E5%99%A8/%E5%AD%A6%E4%B9%A0Kubernetes%E7%B3%BB%E5%88%974%E2%80%94%E2%80%94%E5%B7%A5%E4%BD%9C%E8%B4%9F%E8%BD%BD.html"/>
    <id>http://chengqian90.com/%E5%AE%B9%E5%99%A8/%E5%AD%A6%E4%B9%A0Kubernetes%E7%B3%BB%E5%88%974%E2%80%94%E2%80%94%E5%B7%A5%E4%BD%9C%E8%B4%9F%E8%BD%BD.html</id>
    <published>2021-06-22T07:22:33.000Z</published>
    <updated>2022-03-08T16:23:40.435Z</updated>
    
    <content type="html"><![CDATA[<h1 id="工作负载"><a href="#工作负载" class="headerlink" title="工作负载"></a>工作负载</h1><p>工作负载是在 Kubernetes 上运行的应用程序。</p><p>无论你的负载是单一组件还是由多个一同工作的组件构成，在 Kubernetes 中你 可以在一组 <a href="https://kubernetes.io/zh/docs/concepts/workloads/pods">Pods</a> 中运行它。 在 Kubernetes 中，Pod 代表的是集群上处于运行状态的一组 <a href="https://kubernetes.io/zh/docs/concepts/overview/what-is-kubernetes/#why-containers">容器</a>。</p><span id="more"></span><p>Kubernetes Pods 有确定的生命周期。 例如，当某 Pod 在你的集群中运行时，Pod 运行所在的 节点 出现致命错误时， 所有该节点上的 Pods 都会失败。Kubernetes 将这类失败视为最终状态： 即使该节点后来恢复正常运行，你也需要创建新的 Pod 来恢复应用。</p><p>为了解耦人力，并不需要直接管理每个 Pod。 相反，可以使用 <em>负载资源</em> 来替你管理一组 Pods。 这些资源配置 控制器 来确保合适类型的、处于运行状态的 Pod 个数是正确的，与你所指定的状态相一致。</p><p>Kubernetes 提供若干种内置的工作负载资源：</p><ul><li><strong>Deployment 和 ReplicaSet</strong> （替换原来的资源 ReplicationController）。 Deployment 很适合用来管理你的集群上的无状态应用，Deployment 中的所有 Pod 都是相互等价的，并且在需要的时候被换掉。</li><li><strong>StatefulSet</strong> 让你能够运行一个或者多个以某种方式跟踪应用状态的 Pods。 例如，如果你的负载会将数据作持久存储，你可以运行一个 StatefulSet，将每个 Pod 与某个 PersistentVolume 对应起来。你在 StatefulSet 中各个 Pod 内运行的代码可以将数据复制到同一 StatefulSet 中的其它 Pod 中以提高整体的服务可靠性。</li><li><strong>DaemonSet</strong> 定义提供节点本地支撑设施的 Pods。这些 Pods 可能对于你的<strong>集群的运维</strong>是 非常重要的，例如作为网络链接的辅助工具或者作为网络 插件 的一部分等等。每次你向集群中添加一个新节点时，如果该节点与某 DaemonSet 的规约匹配，则控制面会为该 DaemonSet 调度一个 Pod 到该新节点上运行。</li><li><strong>Job 和 CronJob</strong>。 定义一些一直运行到结束并停止的任务。Job 用来表达的是一次性的任务，而 CronJob 会根据其时间规划反复运行。</li></ul><p>在庞大的 Kubernetes 生态系统中，你还可以找到一些提供额外操作的第三方 工作负载资源。通过使用 <a href="https://kubernetes.io/zh/docs/concepts/extend-kubernetes/api-extension/custom-resources/">定制资源定义（CRD）</a>， 你可以添加第三方工作负载资源，以完成原本不是 Kubernetes 核心功能的工作。 例如，如果你希望运行一组 <code>Pods</code>，但要求所有 Pods 都可用时才执行操作 （比如针对某种高吞吐量的分布式任务），你可以实现一个能够满足这一需求 的扩展，并将其安装到集群中运行。</p><h1 id="Pods"><a href="#Pods" class="headerlink" title="Pods"></a>Pods</h1><p>Pod 是可以在 Kubernetes 中创建和管理的、最小的可部署的计算单元。</p><p>Pod 是一组（一个或多个） 容器； 这些容器共享存储、网络、以及怎样运行这些容器的声明。 Pod 中的内容总是并置（colocated）的并且一同调度，在共享的上下文中运行。 Pod 所建模的是<strong>特定于应用的“逻辑主机”，其中包含一个或多个应用容器</strong>， 这些容器是相对紧密的耦合在一起的。 在非云环境中，在相同的物理机或虚拟机上运行的应用类似于在同一逻辑主机上运行的云应用。</p><p>除了应用容器，Pod 还可以包含在 Pod 启动期间运行的 <strong>Init 容器</strong>。 你也可以在集群中支持<strong>临时性容器</strong> 的情况下，为调试的目的注入临时性容器。</p><p>Pod 的共享上下文包括一组 Linux 名字空间、控制组（cgroup）和可能一些其他的隔离 方面，即用来隔离 Docker 容器的技术。 在 Pod 的上下文中，每个独立的应用可能会进一步实施隔离。</p><p>就 Docker 概念的术语而言，Pod 类似于共享名字空间和文件系统卷的<strong>一组</strong> Docker 容器。</p><h2 id="使用-Pod"><a href="#使用-Pod" class="headerlink" title="使用 Pod"></a>使用 Pod</h2><p>通常你不需要直接创建 Pod，甚至单实例 Pod。 相反，你会使用诸如 <strong>Deployment 或 Job</strong> 这类工作负载资源 来创建 Pod。如果 Pod 需要跟踪状态， 可以考虑 <strong>StatefulSet</strong> 资源。</p><p>Kubernetes 集群中的 Pod 主要有两种用法：</p><ul><li><strong>运行单个容器的 Pod</strong>。”每个 Pod 一个容器”模型是最常见的 Kubernetes 用例； 在这种情况下，可以将 Pod 看作单个容器的包装器，并且 Kubernetes 直接管理 Pod，而不是容器。</li><li><strong>运行多个协同工作的容器的 Pod</strong>。 Pod 可能封装由多个紧密耦合且需要共享资源的共处容器组成的应用程序。 这些位于同一位置的容器可能形成单个内聚的服务单元 —— 一个容器将文件从共享卷提供给公众， 而另一个单独的“边车”（sidecar）容器则刷新或更新这些文件。 Pod 将这些容器和存储资源打包为一个可管理的实体。</li></ul><blockquote><p>将多个并置、同管的容器组织到一个 Pod 中是一种相对高级的使用场景。 只有在一些场景中，容器之间紧密关联时你才应该使用这种模式。</p></blockquote><p>每个 Pod 都旨在运行给定应用程序的单个实例。如果希望横向扩展应用程序（例如，运行多个实例 以提供更多的资源），则应该使用多个 Pod，每个实例使用一个 Pod。 在 Kubernetes 中，这通常被称为 <em>副本（Replication）</em>。 通常使用一种工作负载资源及其控制器来创建和管理一组 Pod 副本。</p><h3 id="Pod-怎样管理多个容器"><a href="#Pod-怎样管理多个容器" class="headerlink" title="Pod 怎样管理多个容器"></a>Pod 怎样管理多个容器</h3><p>Pod 被设计成支持形成内聚服务单元的多个协作过程（形式为容器）。 Pod 中的容器被自动安排到集群中的同一物理机或虚拟机上，并可以一起进行调度。 容器之间可以共享资源和依赖、彼此通信、协调何时以及何种方式终止自身。</p><p><img src="/images/%E5%AD%A6%E4%B9%A0Kubernetes%E7%B3%BB%E5%88%97%E4%B9%8B%E6%A6%82%E5%BF%B5/work-pod.svg" alt="work-pod"></p><p>有些 Pod 具有 <strong>Init 容器 和 应用容器</strong>。 Init 容器会在启动应用容器之前运行并完成。</p><p>Pod 天生地为其成员容器提供了两种共享资源：<strong>网络和 存储</strong>。</p><h2 id="使用-Pod-1"><a href="#使用-Pod-1" class="headerlink" title="使用 Pod"></a>使用 Pod</h2><p>你很少在 Kubernetes 中直接创建一个个的 Pod，甚至是单实例（Singleton）的 Pod。 这是因为 Pod 被设计成了相对临时性的、用后即抛的一次性实体。 当 Pod 由你或者间接地由 <a href="https://kubernetes.io/zh/docs/concepts/architecture/controller/">控制器</a> 创建时，它被调度在集群中的<a href="https://kubernetes.io/zh/docs/concepts/architecture/nodes/">节点</a>上运行。 Pod 会保持在该节点上运行，直到 Pod 结束执行、Pod 对象被删除、Pod 因资源不足而被 <em>驱逐</em> 或者节点失效为止。</p><p>重启 Pod 中的容器不应与重启 Pod 混淆。 Pod 不是进程，而是容器运行的环境。 在被删除之前，Pod 会一直存在。</p><blockquote><p>当你为 Pod 对象创建清单时，要确保所指定的 Pod 名称是合法的 <a href="https://kubernetes.io/zh/docs/concepts/overview/working-with-objects/names#dns-subdomain-names">DNS 子域名</a>。</p></blockquote><h3 id="Pod-和控制器"><a href="#Pod-和控制器" class="headerlink" title="Pod 和控制器"></a>Pod 和控制器</h3><p>你可以使用工作负载资源来创建和管理多个 Pod。 资源的控制器能够处理副本的管理、上线，并在 Pod 失效时提供自愈能力。</p><p>下面是一些管理一个或者多个 Pod 的工作负载资源的示例：</p><ul><li><a href="https://kubernetes.io/zh/docs/concepts/workloads/controllers/deployment/">Deployment</a></li><li><a href="https://kubernetes.io/zh/docs/concepts/workloads/controllers/statefulset/">StatefulSet</a></li><li><a href="https://kubernetes.io/zh/docs/concepts/workloads/controllers/daemonset/">DaemonSet</a></li></ul><h3 id="Pod-模版"><a href="#Pod-模版" class="headerlink" title="Pod 模版"></a>Pod 模版</h3><p><a href="https://kubernetes.io/zh/docs/concepts/workloads/">负载</a>资源的控制器通常使用 <em>Pod 模板（Pod Template）</em> 来替你创建 Pod 并管理它们。</p><p>Pod 模板是包含在工作负载对象中的规范，用来创建 Pod。</p><p>工作负载的控制器会使用负载对象中的 <code>PodTemplate</code> 来生成实际的 Pod。 <code>PodTemplate</code> 是你用来运行应用时指定的负载资源的目标状态的一部分。</p><p>下面的示例是一个简单的 Job 的清单，其中的 <code>template</code> 指示启动一个容器。 该 Pod 中的容器会打印一条消息之后暂停。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">batch/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Job</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">hello</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="comment"># 这里是 Pod 模版</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">hello</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">busybox</span></span><br><span class="line">        <span class="attr">command:</span> [<span class="string">&#x27;sh&#x27;</span>, <span class="string">&#x27;-c&#x27;</span>, <span class="string">&#x27;echo &quot;Hello, Kubernetes!&quot; &amp;&amp; sleep 3600&#x27;</span>]</span><br><span class="line">      <span class="attr">restartPolicy:</span> <span class="string">OnFailure</span></span><br><span class="line">    <span class="comment"># 以上为 Pod 模版</span></span><br></pre></td></tr></table></figure><p>修改 Pod 模版或者切换到新的 Pod 模版都不会对已经存在的 Pod 起作用。 Pod 不会直接收到模版的更新。相反， 新的 Pod 会被创建出来，与更改后的 Pod 模版匹配。</p><p>例如，Deployment 控制器针对每个 Deployment 对象确保运行中的 Pod 与当前的 Pod 模版匹配。如果模版被更新，则 Deployment 必须删除现有的 Pod，基于更新后的模版 创建新的 Pod。每个工作负载资源都实现了自己的规则，用来处理对 Pod 模版的更新。</p><h3 id="资源共享和通信"><a href="#资源共享和通信" class="headerlink" title="资源共享和通信"></a>资源共享和通信</h3><p>Pod 使它的成员容器间能够进行数据共享和通信。</p><h3 id="Pod-中的存储"><a href="#Pod-中的存储" class="headerlink" title="Pod 中的存储"></a>Pod 中的存储</h3><p>一个 Pod 可以设置一组共享的存储<a href="https://kubernetes.io/zh/docs/concepts/storage/volumes/">卷</a>。 Pod 中的所有容器都可以访问该共享卷，从而允许这些容器共享数据。 卷还允许 Pod 中的持久数据保留下来，即使其中的容器需要重新启动。 有关 Kubernetes 如何在 Pod 中实现共享存储并将其提供给 Pod 的更多信息， 请参考<a href="https://kubernetes.io/zh/docs/concepts/storage/">卷</a>。</p><h3 id="Pod-联网"><a href="#Pod-联网" class="headerlink" title="Pod 联网"></a>Pod 联网</h3><p>每个 Pod 都在每个地址族中获得一个唯一的 IP 地址。 Pod 中的每个容器共享网络名字空间，包括 IP 地址和网络端口。 <em>Pod 内</em> 的容器可以使用 <code>localhost</code> 互相通信。 当 Pod 中的容器与 <em>Pod 之外</em> 的实体通信时，它们必须协调如何使用共享的网络资源 （例如端口）。</p><p>在同一个 Pod 内，所有容器共享一个 IP 地址和端口空间，并且可以通过 <code>localhost</code> 发现对方。 他们也能通过如 SystemV 信号量或 POSIX 共享内存这类标准的进程间通信方式互相通信。 不同 Pod 中的容器的 IP 地址互不相同，没有 <a href="https://kubernetes.io/zh/docs/concepts/policy/pod-security-policy/">特殊配置</a> 就不能使用 IPC 进行通信。 如果某容器希望与运行于其他 Pod 中的容器通信，可以通过 IP 联网的方式实现。</p><p>Pod 中的容器所看到的系统主机名与为 Pod 配置的 <code>name</code> 属性值相同。 <a href="https://kubernetes.io/zh/docs/concepts/cluster-administration/networking/">网络</a>部分提供了更多有关此内容的信息。</p><h2 id="容器的特权模式"><a href="#容器的特权模式" class="headerlink" title="容器的特权模式"></a>容器的特权模式</h2><p>在 Linux 中，Pod 中的任何容器都可以使用容器规约中的 <a href="https://kubernetes.io/zh/docs/tasks/configure-pod-container/security-context/">安全性上下文</a>中的 <code>privileged</code>（Linux）参数启用特权模式。 这对于想要使用操作系统管理权能（Capabilities，如操纵网络堆栈和访问设备） 的容器很有用。</p><blockquote><p><a href="https://kubernetes.io/zh/docs/setup/production-environment/container-runtimes">容器运行时</a>必须支持 特权容器的概念才能使用这一配置。</p></blockquote><h2 id="静态-Pod"><a href="#静态-Pod" class="headerlink" title="静态 Pod"></a>静态 Pod</h2><p><em>静态 Pod（Static Pod）</em> 直接由特定节点上的 <code>kubelet</code> 守护进程管理， 不需要<a href="https://kubernetes.io/zh/docs/reference/command-line-tools-reference/kube-apiserver/">API 服务器</a>看到它们。 尽管大多数 Pod 都是通过控制面（例如，<a href="https://kubernetes.io/zh/docs/concepts/workloads/controllers/deployment/">Deployment</a>） 来管理的，对于静态 Pod 而言，<code>kubelet</code> 直接监控每个 Pod，并在其失效时重启之。</p><p>静态 Pod 通常绑定到某个节点上的 <a href="https://kubernetes.io/docs/reference/generated/kubelet">kubelet</a>。 其主要用途是运行自托管的控制面。 在自托管场景中，使用 <code>kubelet</code> 来管理各个独立的 <a href="https://kubernetes.io/zh/docs/concepts/overview/components/#control-plane-components">控制面组件</a>。</p><p><code>kubelet</code> 自动尝试为每个静态 Pod 在 Kubernetes API 服务器上创建一个 <a href="https://kubernetes.io/zh/docs/reference/glossary/?all=true#term-mirror-pod">镜像 Pod</a>。 这意味着在节点上运行的 Pod 在 API 服务器上是可见的，但不可以通过 API 服务器来控制。</p><p><strong>说明：</strong></p><p>静态 Pod 的 <code>spec</code> 不能引用其他的 API 对象（例如：<a href="https://kubernetes.io/zh/docs/tasks/configure-pod-container/configure-service-account/">ServiceAccount</a>、<a href="https://kubernetes.io/zh/docs/tasks/configure-pod-container/configure-pod-configmap/">ConfigMap</a>、<a href="https://kubernetes.io/zh/docs/concepts/configuration/secret/">Secret</a>等）。</p><h2 id="容器探针"><a href="#容器探针" class="headerlink" title="容器探针"></a>容器探针</h2><p><em>Probe</em> 是由 kubelet 对容器执行的定期诊断。要执行诊断，kubelet 可以执行三种动作：</p><ul><li><code>ExecAction</code>（借助容器运行时执行）</li><li><code>TCPSocketAction</code>（由 kubelet 直接检测）</li><li><code>HTTPGetAction</code>（由 kubelet 直接检测）</li></ul><p>你可以参阅 Pod 的生命周期文档中的<a href="https://kubernetes.io/zh/docs/concepts/workloads/pods/pod-lifecycle/#container-probes">探针</a>部分。</p><h1 id="Deployments"><a href="#Deployments" class="headerlink" title="Deployments"></a>Deployments</h1><p>一个 <em>Deployment</em> 为 Pods 和 ReplicaSets（下一代副本控制器）提供声明式的更新能力。</p><p>你负责描述 Deployment 中的 <em>目标状态</em>，而 Deployment <a href="https://kubernetes.io/zh/docs/concepts/architecture/controller/">控制器（Controller）</a> 以受控速率更改实际状态， 使其变为期望状态。你可以定义 Deployment 以创建新的 ReplicaSet，或删除现有 Deployment， 并通过新的 Deployment 收养其资源。</p><blockquote><p>不要管理 Deployment 所拥有的 ReplicaSet 。 如果存在下面未覆盖的使用场景，请考虑在 Kubernetes 仓库中提出 Issue。</p></blockquote><h2 id="用例"><a href="#用例" class="headerlink" title="用例"></a>用例</h2><p>以下是 Deployments 的典型用例：</p><ul><li><strong>创建 Deployment 以将 ReplicaSet 上线</strong>。 ReplicaSet 在后台创建 Pods。 检查 ReplicaSet 的上线状态，查看其是否成功。</li><li><strong>通过更新 Deployment 的 PodTemplateSpec，声明 Pod 的新状态</strong>。 新的 ReplicaSet 会被创建，Deployment 以受控速率将 Pod 从旧 ReplicaSet 迁移到新 ReplicaSet。 每个新的 ReplicaSet 都会更新 Deployment 的修订版本。</li><li>如果 Deployment 的当前状态不稳定，<strong>回滚到较早的 Deployment 版本</strong>。 每次回滚都会更新 Deployment 的修订版本。</li><li><strong>扩大 Deployment 规模以承担更多负载</strong>。</li><li><strong>暂停 Deployment</strong>以应用对 PodTemplateSpec 所作的多项修改， 然后恢复其执行以启动新的上线版本。</li><li><strong>使用 Deployment 状态</strong>来判定上线过程是否出现停滞。</li><li><strong>清理较旧的不再需要的 ReplicaSet</strong> 。</li></ul><h2 id="创建-Deployment"><a href="#创建-Deployment" class="headerlink" title="创建 Deployment"></a>创建 Deployment</h2><p>下面是 Deployment 示例。其中创建了一个 ReplicaSet，负责启动三个 <code>nginx</code> Pods：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">nginx-deployment</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">nginx</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">3</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">nginx</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">nginx</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">nginx:1.14.2</span></span><br><span class="line">        <span class="attr">ports:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span></span><br></pre></td></tr></table></figure><p>在该例中：</p><ul><li><p>创建名为 <code>nginx-deployment</code>（由 <code>.metadata.name</code> 字段标明）的 Deployment。</p></li><li><p>该 Deployment 创建三个（由 <code>replicas</code> 字段标明）Pod 副本。</p></li><li><p><code>selector</code> 字段定义 Deployment 如何查找要管理的 Pods。 在这里，你选择在 Pod 模板中定义的标签（<code>app: nginx</code>）。 不过，更复杂的选择规则是也可能的，只要 Pod 模板本身满足所给规则即可。</p><blockquote><p><code>spec.selector.matchLabels</code> 字段是 <code>&#123;key,value&#125;</code> 键值对映射。 在 <code>matchLabels</code> 映射中的每个 <code>&#123;key,value&#125;</code> 映射等效于 <code>matchExpressions</code> 中的一个元素， 即其 <code>key</code> 字段是 “key”，<code>operator</code> 为 “In”，<code>values</code> 数组仅包含 “value”。 在 <code>matchLabels</code> 和 <code>matchExpressions</code> 中给出的所有条件都必须满足才能匹配。</p></blockquote></li><li><p><code>template</code> 字段包含以下子字段：</p><ul><li>Pod 被使用 <code>labels</code> 字段打上 <code>app: nginx</code> 标签。</li></ul></li><li><ul><li>Pod 模板规约（即 <code>.template.spec</code> 字段）指示 Pods 运行一个 <code>nginx</code> 容器， 该容器运行版本为 1.14.2 的 <code>nginx</code> <a href="https://hub.docker.com/">Docker Hub</a>镜像。</li><li>创建一个容器并使用 <code>name</code> 字段将其命名为 <code>nginx</code>。</li></ul></li></ul><p>开始之前，请确保的 Kubernetes 集群已启动并运行。 按照以下步骤创建上述 Deployment ：</p><ol><li><p>通过运行以下命令创建 Deployment ：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f https://k8s.io/examples/controllers/nginx-deployment.yaml</span><br></pre></td></tr></table></figure><p><strong>说明：</strong> 你可以设置 <code>--record</code> 标志将所执行的命令写入资源注解 <code>kubernetes.io/change-cause</code> 中。 这对于以后的检查是有用的。例如，要查看针对每个 Deployment 修订版本所执行过的命令。</p></li><li><p>运行 <code>kubectl get deployments</code> 检查 Deployment 是否已创建。如果仍在创建 Deployment， 则输出类似于：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">NAME               DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE</span><br><span class="line">nginx-deployment   3         0         0            0           1s</span><br></pre></td></tr></table></figure><p>在检查集群中的 Deployment 时，所显示的字段有：</p><ul><li><code>NAME</code> 列出了集群中 Deployment 的名称。</li><li><code>READY</code> 显示应用程序的可用的 <em>副本</em> 数。显示的模式是“就绪个数/期望个数”。</li><li><code>UP-TO-DATE</code> 显示为了达到期望状态已经更新的副本数。</li><li><code>AVAILABLE</code> 显示应用可供用户使用的副本数。</li><li><code>AGE</code> 显示应用程序运行的时间。</li></ul><p>请注意期望副本数是根据 <code>.spec.replicas</code> 字段设置 3。</p></li><li><p>要查看 Deployment 上线状态，运行 <code>kubectl rollout status deployment/nginx-deployment</code>。</p><p>输出类似于：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Waiting for rollout to finish: 2 out of 3 new replicas have been updated...</span><br><span class="line">deployment &quot;nginx-deployment&quot; successfully rolled out</span><br></pre></td></tr></table></figure></li><li><p>几秒钟后再次运行 <code>kubectl get deployments</code>。输出类似于：</p><p>注意 Deployment 已创建全部三个副本，并且所有副本都是最新的（它们包含最新的 Pod 模板） 并且可用。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">NAME               DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE</span><br><span class="line">nginx-deployment   3         3         3            3           18s</span><br></pre></td></tr></table></figure></li><li><p>要查看 Deployment 创建的 ReplicaSet（<code>rs</code>），运行 <code>kubectl get rs</code>。 输出类似于：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">NAME                          DESIRED   CURRENT   READY   AGE</span><br><span class="line">nginx-deployment-75675f5897   3         3         3       18s</span><br></pre></td></tr></table></figure><p>ReplicaSet 输出中包含以下字段：</p><ul><li><code>NAME</code> 列出名字空间中 ReplicaSet 的名称；</li><li><code>DESIRED</code> 显示应用的期望副本个数，即在创建 Deployment 时所定义的值。 此为期望状态；</li><li><code>CURRENT</code> 显示当前运行状态中的副本个数；</li><li><code>READY</code> 显示应用中有多少副本可以为用户提供服务；</li><li><code>AGE</code> 显示应用已经运行的时间长度。</li></ul><p>注意 ReplicaSet 的名称始终被格式化为<code>[Deployment名称]-[随机字符串]</code>。 其中的随机字符串是使用 pod-template-hash 作为种子随机生成的。</p></li><li><p>要查看每个 Pod 自动生成的标签，运行 <code>kubectl get pods --show-labels</code>。返回以下输出：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">NAME                                READY     STATUS    RESTARTS   AGE       LABELS</span><br><span class="line">nginx-deployment-75675f5897-7ci7o   1/1       Running   0          18s       app=nginx,pod-template-hash=3123191453</span><br><span class="line">nginx-deployment-75675f5897-kzszj   1/1       Running   0          18s       app=nginx,pod-template-hash=3123191453</span><br><span class="line">nginx-deployment-75675f5897-qqcnn   1/1       Running   0          18s       app=nginx,pod-template-hash=3123191453</span><br></pre></td></tr></table></figure><p>所创建的 ReplicaSet 确保总是存在三个 <code>nginx</code> Pod。</p></li></ol><h3 id="Pod-template-hash-标签"><a href="#Pod-template-hash-标签" class="headerlink" title="Pod-template-hash 标签"></a>Pod-template-hash 标签</h3><blockquote><p>不要更改此标签。</p></blockquote><p>Deployment 控制器将 <code>pod-template-hash</code> 标签添加到 Deployment 所创建或收留的 每个 ReplicaSet 。</p><p>此标签可确保 Deployment 的子 ReplicaSets 不重叠。 标签是通过对 ReplicaSet 的 <code>PodTemplate</code> 进行哈希处理。 所生成的哈希值被添加到 ReplicaSet 选择算符、Pod 模板标签，并存在于在 ReplicaSet 可能拥有的任何现有 Pod 中。</p><h2 id="更新-Deployment"><a href="#更新-Deployment" class="headerlink" title="更新 Deployment"></a>更新 Deployment</h2><blockquote><p>仅当 Deployment Pod 模板（即 <code>.spec.template</code>）发生改变时，例如模板的标签或容器镜像被更新， 才会触发 Deployment 上线。 其他更新（如对 Deployment 执行扩缩容的操作）不会触发上线动作。</p></blockquote><p>按照以下步骤更新 Deployment：</p><ol><li><p>先来更新 nginx Pod 以使用 <code>nginx:1.16.1</code> 镜像，而不是 <code>nginx:1.14.2</code> 镜像。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kubectl --record deployment.apps/nginx-deployment set image \</span><br><span class="line">   deployment.v1.apps/nginx-deployment nginx=nginx:1.16.1</span><br></pre></td></tr></table></figure><p>或者使用下面的命令：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl set image deployment/nginx-deployment nginx=nginx:1.16.1 --record</span><br></pre></td></tr></table></figure><p>输出类似于：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">deployment.apps/nginx-deployment image updated</span><br></pre></td></tr></table></figure><p>或者，可以 <code>edit</code> Deployment 并将 <code>.spec.template.spec.containers[0].image</code> 从 <code>nginx:1.14.2</code> 更改至 <code>nginx:1.16.1</code>。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl edit deployment.v1.apps/nginx-deployment</span><br></pre></td></tr></table></figure><p>输出类似于：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">deployment.apps/nginx-deployment edited</span><br></pre></td></tr></table></figure></li><li><p>要查看上线状态，运行：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl rollout status deployment/nginx-deployment</span><br></pre></td></tr></table></figure><p> 输出类似于：</p> <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Waiting for rollout to finish: 2 out of 3 new replicas have been updated...</span><br></pre></td></tr></table></figure><p> 或者</p> <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">deployment &quot;nginx-deployment&quot; successfully rolled out</span><br></pre></td></tr></table></figure></li></ol><h3 id="翻转（多-Deployment-动态更新）"><a href="#翻转（多-Deployment-动态更新）" class="headerlink" title="翻转（多 Deployment 动态更新）"></a>翻转（多 Deployment 动态更新）</h3><p>Deployment 控制器每次注意到新的 Deployment 时，都会创建一个 ReplicaSet 以启动所需的 Pods。 如果更新了 Deployment，则控制标签匹配 <code>.spec.selector</code> 但模板不匹配 <code>.spec.template</code> 的 Pods 的现有 ReplicaSet 被缩容。最终，新的 ReplicaSet 缩放为 <code>.spec.replicas</code> 个副本， 所有旧 ReplicaSets 缩放为 0 个副本。</p><p>当 Deployment 正在<strong>上线时被更新</strong>，Deployment 会针对更新创建一个新的 ReplicaSet 并开始对其扩容，之前正在被扩容的 ReplicaSet 会被<strong>翻转</strong>，添加到旧 ReplicaSets 列表 并开始<strong>缩容</strong>。</p><p>例如，假定你在创建一个 Deployment 以生成 <code>nginx:1.14.2</code> 的 5 个副本，但接下来 更新 Deployment 以创建 5 个 <code>nginx:1.16.1</code> 的副本，而此时只有 3 个<code>nginx:1.14.2</code> 副本已创建。在这种情况下，Deployment 会<strong>立即开始</strong>杀死 3 个 <code>nginx:1.14.2</code> Pods， 并开始创建 <code>nginx:1.16.1</code> Pods。它不会等待 <code>nginx:1.14.2</code> 的 5 个副本都创建完成 后才开始执行变更动作。</p><h3 id="更改标签选择算符"><a href="#更改标签选择算符" class="headerlink" title="更改标签选择算符"></a>更改标签选择算符</h3><p>通常不鼓励更新标签选择算符。建议你提前规划选择算符。 在任何情况下，如果需要更新标签选择算符，请格外小心，并确保自己了解 这背后可能发生的所有事情。</p><blockquote><p>在 API 版本 <code>apps/v1</code> 中，Deployment 标签选择算符在创建后是不可变的。</p></blockquote><ul><li>添加选择算符时要求使用新标签更新 Deployment 规约中的 Pod 模板标签，否则将返回验证错误。 此更改是非重叠的，也就是说新的选择算符不会选择使用旧选择算符所创建的 ReplicaSet 和 Pod， 这会导致创建新的 ReplicaSet 时所有旧 ReplicaSet 都会被孤立。</li><li>选择算符的更新如果更改了某个算符的键名，这会导致与添加算符时相同的行为。</li><li>删除选择算符的操作会删除从 Deployment 选择算符中删除现有算符。 此操作不需要更改 Pod 模板标签。现有 ReplicaSet 不会被孤立，也不会因此创建新的 ReplicaSet， 但请注意已删除的标签仍然存在于现有的 Pod 和 ReplicaSet 中。</li></ul><h2 id="回滚-Deployment"><a href="#回滚-Deployment" class="headerlink" title="回滚 Deployment"></a>回滚 Deployment</h2><p>有时，你可能想要回滚 Deployment；例如，当 Deployment 不稳定时（例如进入反复崩溃状态）。 默认情况下，Deployment 的所有上线记录都保留在系统中，以便可以随时回滚 （你可以通过修改修订历史记录限制来更改这一约束）。</p><blockquote><p><strong>说明：</strong> Deployment 被触发上线时，系统就会创建 Deployment 的新的修订版本。 这意味着仅当 Deployment 的 Pod 模板（<code>.spec.template</code>）发生更改时，才会创建新修订版本 – 例如，模板的标签或容器镜像发生变化。 其他更新，如 Deployment 的扩缩容操作不会创建 Deployment 修订版本。 这是为了方便同时执行手动缩放或自动缩放。 换言之，当你回滚到较早的修订版本时，只有 Deployment 的 Pod 模板部分会被回滚。</p></blockquote><ul><li><p>假设你在更新 Deployment 时犯了一个拼写错误，将镜像名称命名设置为 <code>nginx:1.161</code> 而不是 <code>nginx:1.16.1</code>：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl set image deployment.v1.apps/nginx-deployment nginx=nginx:1.161 --record=true</span><br></pre></td></tr></table></figure><p>输出类似于：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">deployment.apps/nginx-deployment image updated</span><br></pre></td></tr></table></figure></li><li><p>此上线进程会出现停滞。你可以通过检查上线状态来验证：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl rollout status deployment/nginx-deployment</span><br></pre></td></tr></table></figure><p>输出类似于：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Waiting for rollout to finish: 1 out of 3 new replicas have been updated...</span><br></pre></td></tr></table></figure></li><li><p>按 Ctrl-C 停止上述上线状态观测。有关上线停滞的详细信息，<a href="https://kubernetes.io/zh/docs/concepts/workloads/controllers/deployment/#deployment-status">参考这里</a>。</p></li><li><p>你可以看到旧的副本有两个（<code>nginx-deployment-1564180365</code> 和 <code>nginx-deployment-2035384211</code>）， 新的副本有 1 个（<code>nginx-deployment-3066724191</code>）：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl get rs</span><br></pre></td></tr></table></figure><p>输出类似于：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">NAME                          DESIRED   CURRENT   READY   AGE</span><br><span class="line">nginx-deployment-1564180365   3         3         3       25s</span><br><span class="line">nginx-deployment-2035384211   0         0         0       36s</span><br><span class="line">nginx-deployment-3066724191   1         1         0       6s</span><br></pre></td></tr></table></figure></li><li><p>查看所创建的 Pod，你会注意到新 ReplicaSet 所创建的 1 个 Pod 卡顿在镜像拉取循环中。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl get pods</span><br></pre></td></tr></table></figure><p>输出类似于：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">NAME                                READY     STATUS             RESTARTS   AGE</span><br><span class="line">nginx-deployment-1564180365-70iae   1/1       Running            0          25s</span><br><span class="line">nginx-deployment-1564180365-jbqqo   1/1       Running            0          25s</span><br><span class="line">nginx-deployment-1564180365-hysrc   1/1       Running            0          25s</span><br><span class="line">nginx-deployment-3066724191-08mng   0/1       ImagePullBackOff   0          6s</span><br></pre></td></tr></table></figure><p><strong>说明：</strong> Deployment 控制器自动停止有问题的上线过程，并停止对新的 ReplicaSet 扩容。 这行为取决于所指定的 <strong>rollingUpdate</strong> 参数（具体为 <code>maxUnavailable</code>）。 默认情况下，Kubernetes 将此值设置为 25%。</p></li><li><p>获取 Deployment 描述信息：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl describe deployment</span><br></pre></td></tr></table></figure><p>输出类似于：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">Name:           nginx-deployment</span><br><span class="line">Namespace:      default</span><br><span class="line">CreationTimestamp:  Tue, 15 Mar 2016 14:48:04 -0700</span><br><span class="line">Labels:         app=nginx</span><br><span class="line">Selector:       app=nginx</span><br><span class="line">Replicas:       3 desired | 1 updated | 4 total | 3 available | 1 unavailable</span><br><span class="line">StrategyType:       RollingUpdate</span><br><span class="line">MinReadySeconds:    0</span><br><span class="line">RollingUpdateStrategy:  25% max unavailable, 25% max surge</span><br><span class="line">Pod Template:</span><br><span class="line">  Labels:  app=nginx</span><br><span class="line">  Containers:</span><br><span class="line">   nginx:</span><br><span class="line">    Image:        nginx:1.91</span><br><span class="line">    Port:         80/TCP</span><br><span class="line">    Host Port:    0/TCP</span><br><span class="line">    Environment:  &lt;none&gt;</span><br><span class="line">    Mounts:       &lt;none&gt;</span><br><span class="line">  Volumes:        &lt;none&gt;</span><br><span class="line">Conditions:</span><br><span class="line">  Type           Status  Reason</span><br><span class="line">  ----           ------  ------</span><br><span class="line">  Available      True    MinimumReplicasAvailable</span><br><span class="line">  Progressing    True    ReplicaSetUpdated</span><br><span class="line">OldReplicaSets:     nginx-deployment-1564180365 (3/3 replicas created)</span><br><span class="line">NewReplicaSet:      nginx-deployment-3066724191 (1/1 replicas created)</span><br><span class="line">Events:</span><br><span class="line">  FirstSeen LastSeen    Count   From                    SubobjectPath   Type        Reason              Message</span><br><span class="line">  --------- --------    -----   ----                    -------------   --------    ------              -------</span><br><span class="line">  1m        1m          1       &#123;deployment-controller &#125;                Normal      ScalingReplicaSet   Scaled up replica set nginx-deployment-2035384211 to 3</span><br><span class="line">  22s       22s         1       &#123;deployment-controller &#125;                Normal      ScalingReplicaSet   Scaled up replica set nginx-deployment-1564180365 to 1</span><br><span class="line">  22s       22s         1       &#123;deployment-controller &#125;                Normal      ScalingReplicaSet   Scaled down replica set nginx-deployment-2035384211 to 2</span><br><span class="line">  22s       22s         1       &#123;deployment-controller &#125;                Normal      ScalingReplicaSet   Scaled up replica set nginx-deployment-1564180365 to 2</span><br><span class="line">  21s       21s         1       &#123;deployment-controller &#125;                Normal      ScalingReplicaSet   Scaled down replica set nginx-deployment-2035384211 to 1</span><br><span class="line">  21s       21s         1       &#123;deployment-controller &#125;                Normal      ScalingReplicaSet   Scaled up replica set nginx-deployment-1564180365 to 3</span><br><span class="line">  13s       13s         1       &#123;deployment-controller &#125;                Normal      ScalingReplicaSet   Scaled down replica set nginx-deployment-2035384211 to 0</span><br><span class="line">  13s       13s         1       &#123;deployment-controller &#125;                Normal      ScalingReplicaSet   Scaled up replica set nginx-deployment-3066724191 to 1</span><br></pre></td></tr></table></figure><p>要解决此问题，需要回滚到以前稳定的 Deployment 版本。</p></li></ul><h3 id="检查-Deployment-上线历史"><a href="#检查-Deployment-上线历史" class="headerlink" title="检查 Deployment 上线历史"></a>检查 Deployment 上线历史</h3><p>按照如下步骤检查回滚历史：</p><ol><li><p>首先，检查 Deployment 修订历史：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl rollout history deployment.v1.apps/nginx-deployment</span><br></pre></td></tr></table></figure><p>输出类似于：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">deployments &quot;nginx-deployment&quot;</span><br><span class="line">REVISION    CHANGE-CAUSE</span><br><span class="line">1           kubectl apply --filename=https://k8s.io/examples/controllers/nginx-deployment.yaml --record=true</span><br><span class="line">2           kubectl set image deployment.v1.apps/nginx-deployment nginx=nginx:1.9.1 --record=true</span><br><span class="line">3           kubectl set image deployment.v1.apps/nginx-deployment nginx=nginx:1.91 --record=true</span><br></pre></td></tr></table></figure><p><code>CHANGE-CAUSE</code> 的内容是从 Deployment 的 <code>kubernetes.io/change-cause</code> 注解复制过来的。 复制动作发生在修订版本创建时。你可以通过以下方式设置 <code>CHANGE-CAUSE</code> 消息：</p><ul><li>使用 <code>kubectl annotate deployment.v1.apps/nginx-deployment kubernetes.io/change-cause=&quot;image updated to 1.9.1&quot;</code> 为 Deployment 添加注解。</li><li>追加 <code>--record</code> 命令行标志以保存正在更改资源的 <code>kubectl</code> 命令。</li><li>手动编辑资源的清单。</li></ul></li><li><p>要查看修订历史的详细信息，运行：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl rollout history deployment.v1.apps/nginx-deployment --revision=2</span><br></pre></td></tr></table></figure><p>输出类似于：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">deployments &quot;nginx-deployment&quot; revision 2</span><br><span class="line">  Labels:       app=nginx</span><br><span class="line">          pod-template-hash=1159050644</span><br><span class="line">  Annotations:  kubernetes.io/change-cause=kubectl set image deployment.v1.apps/nginx-deployment nginx=nginx:1.16.1 --record=true</span><br><span class="line">  Containers:</span><br><span class="line">   nginx:</span><br><span class="line">    Image:      nginx:1.16.1</span><br><span class="line">    Port:       80/TCP</span><br><span class="line">     QoS Tier:</span><br><span class="line">        cpu:      BestEffort</span><br><span class="line">        memory:   BestEffort</span><br><span class="line">    Environment Variables:      &lt;none&gt;</span><br><span class="line">  No volumes.</span><br></pre></td></tr></table></figure></li></ol><h3 id="回滚到之前的修订版本"><a href="#回滚到之前的修订版本" class="headerlink" title="回滚到之前的修订版本"></a>回滚到之前的修订版本</h3><p>按照下面给出的步骤将 Deployment 从当前版本回滚到以前的版本（即版本 2）。</p><ol><li><p>假定现在你已决定撤消当前上线并回滚到以前的修订版本：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl rollout undo deployment.v1.apps/nginx-deployment</span><br></pre></td></tr></table></figure><p>输出类似于：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">deployment.apps/nginx-deployment</span><br></pre></td></tr></table></figure><p>或者，你也可以通过使用 <code>--to-revision</code> 来回滚到特定修订版本：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl rollout undo deployment.v1.apps/nginx-deployment --to-revision=2</span><br></pre></td></tr></table></figure><p>输出类似于：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">deployment.apps/nginx-deployment</span><br></pre></td></tr></table></figure><p>与回滚相关的指令的更详细信息，请参考 <a href="https://kubernetes.io/docs/reference/generated/kubectl/kubectl-commands#rollout"><code>kubectl rollout</code></a>。</p><p>现在，Deployment 正在回滚到以前的稳定版本。正如你所看到的，Deployment 控制器生成了 回滚到修订版本 2 的 <code>DeploymentRollback</code> 事件。</p></li><li><p>检查回滚是否成功以及 Deployment 是否正在运行，运行：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl get deployment nginx-deployment</span><br></pre></td></tr></table></figure><p>输出类似于：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">NAME               DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE</span><br><span class="line">nginx-deployment   3         3         3            3           30m</span><br></pre></td></tr></table></figure></li><li><p>获取 Deployment 描述信息：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl describe deployment nginx-deployment</span><br></pre></td></tr></table></figure><p>输出类似于：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">Name:                   nginx-deployment</span><br><span class="line">Namespace:              default</span><br><span class="line">CreationTimestamp:      Sun, 02 Sep 2018 18:17:55 -0500</span><br><span class="line">Labels:                 app=nginx</span><br><span class="line">Annotations:            deployment.kubernetes.io/revision=4</span><br><span class="line">                        kubernetes.io/change-cause=kubectl set image deployment.v1.apps/nginx-deployment nginx=nginx:1.16.1 --record=true</span><br><span class="line">Selector:               app=nginx</span><br><span class="line">Replicas:               3 desired | 3 updated | 3 total | 3 available | 0 unavailable</span><br><span class="line">StrategyType:           RollingUpdate</span><br><span class="line">MinReadySeconds:        0</span><br><span class="line">RollingUpdateStrategy:  25% max unavailable, 25% max surge</span><br><span class="line">Pod Template:</span><br><span class="line">  Labels:  app=nginx</span><br><span class="line">  Containers:</span><br><span class="line">   nginx:</span><br><span class="line">    Image:        nginx:1.16.1</span><br><span class="line">    Port:         80/TCP</span><br><span class="line">    Host Port:    0/TCP</span><br><span class="line">    Environment:  &lt;none&gt;</span><br><span class="line">    Mounts:       &lt;none&gt;</span><br><span class="line">  Volumes:        &lt;none&gt;</span><br><span class="line">Conditions:</span><br><span class="line">  Type           Status  Reason</span><br><span class="line">  ----           ------  ------</span><br><span class="line">  Available      True    MinimumReplicasAvailable</span><br><span class="line">  Progressing    True    NewReplicaSetAvailable</span><br><span class="line">OldReplicaSets:  &lt;none&gt;</span><br><span class="line">NewReplicaSet:   nginx-deployment-c4747d96c (3/3 replicas created)</span><br><span class="line">Events:</span><br><span class="line">  Type    Reason              Age   From                   Message</span><br><span class="line">  ----    ------              ----  ----                   -------</span><br><span class="line">  Normal  ScalingReplicaSet   12m   deployment-controller  Scaled up replica set nginx-deployment-75675f5897 to 3</span><br><span class="line">  Normal  ScalingReplicaSet   11m   deployment-controller  Scaled up replica set nginx-deployment-c4747d96c to 1</span><br><span class="line">  Normal  ScalingReplicaSet   11m   deployment-controller  Scaled down replica set nginx-deployment-75675f5897 to 2</span><br><span class="line">  Normal  ScalingReplicaSet   11m   deployment-controller  Scaled up replica set nginx-deployment-c4747d96c to 2</span><br><span class="line">  Normal  ScalingReplicaSet   11m   deployment-controller  Scaled down replica set nginx-deployment-75675f5897 to 1</span><br><span class="line">  Normal  ScalingReplicaSet   11m   deployment-controller  Scaled up replica set nginx-deployment-c4747d96c to 3</span><br><span class="line">  Normal  ScalingReplicaSet   11m   deployment-controller  Scaled down replica set nginx-deployment-75675f5897 to 0</span><br><span class="line">  Normal  ScalingReplicaSet   11m   deployment-controller  Scaled up replica set nginx-deployment-595696685f to 1</span><br><span class="line">  Normal  DeploymentRollback  15s   deployment-controller  Rolled back deployment &quot;nginx-deployment&quot; to revision 2</span><br><span class="line">  Normal  ScalingReplicaSet   15s   deployment-controller  Scaled down replica set nginx-deployment-595696685f to 0</span><br></pre></td></tr></table></figure></li></ol><h2 id="缩放-Deployment"><a href="#缩放-Deployment" class="headerlink" title="缩放 Deployment"></a>缩放 Deployment</h2><p>你可以使用如下指令缩放 Deployment：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl scale deployment.v1.apps/nginx-deployment --replicas=10</span><br></pre></td></tr></table></figure><p>输出类似于：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">deployment.apps/nginx-deployment scaled</span><br></pre></td></tr></table></figure><p>假设集群启用了<a href="https://kubernetes.io/zh/docs/tasks/run-application/horizontal-pod-autoscale-walkthrough/">Pod 的水平自动缩放</a>， 你可以为 Deployment 设置自动缩放器，并基于现有 Pods 的 CPU 利用率选择 要运行的 Pods 个数下限和上限。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl autoscale deployment.v1.apps/nginx-deployment --min=10 --max=15 --cpu-percent=80</span><br></pre></td></tr></table></figure><p>输出类似于：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">deployment.apps/nginx-deployment scaled</span><br></pre></td></tr></table></figure><h3 id="比例缩放"><a href="#比例缩放" class="headerlink" title="比例缩放"></a>比例缩放</h3><p>RollingUpdate 的 Deployment 支持同时运行应用程序的多个版本。 当自动缩放器缩放处于上线进程（仍在进行中或暂停）中的 RollingUpdate Deployment 时， Deployment 控制器会平衡现有的活跃状态的 ReplicaSets（含 Pods 的 ReplicaSets）中的额外副本， 以降低风险。这称为 <em>比例缩放（Proportional Scaling）</em>。</p><p>例如，你正在运行一个 10 个副本的 Deployment，其 <a href="https://kubernetes.io/zh/docs/concepts/workloads/controllers/deployment/#max-surge">maxSurge</a>=3，<a href="https://kubernetes.io/zh/docs/concepts/workloads/controllers/deployment/#max-unavailable">maxUnavailable</a>=2。</p><ul><li><p>确保 Deployment 的这 10 个副本都在运行。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl get deploy</span><br></pre></td></tr></table></figure><p>输出类似于：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">NAME                 DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE</span><br><span class="line">nginx-deployment     10        10        10           10          50s</span><br></pre></td></tr></table></figure></li><li><p>更新 Deployment 使用新镜像，碰巧该镜像无法从集群内部解析。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl set image deployment.v1.apps/nginx-deployment nginx=nginx:sometag</span><br></pre></td></tr></table></figure><p>输出类似于：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">deployment.apps/nginx-deployment image updated</span><br></pre></td></tr></table></figure></li><li><p>镜像更新使用 ReplicaSet <code>nginx-deployment-1989198191</code> 启动新的上线过程， 但由于上面提到的 <code>maxUnavailable</code> 要求，该进程被阻塞了。检查上线状态：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl get rs</span><br></pre></td></tr></table></figure><p>输出类似于：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">NAME                          DESIRED   CURRENT   READY     AGE</span><br><span class="line">nginx-deployment-1989198191   5         5         0         9s</span><br><span class="line">nginx-deployment-618515232    8         8         8         1m</span><br></pre></td></tr></table></figure></li><li><p>然后，出现了新的 Deployment 扩缩请求。自动缩放器将 Deployment 副本增加到 15。 Deployment 控制器需要决定在何处添加 5 个新副本。如果未使用比例缩放，所有 5 个副本 都将添加到新的 ReplicaSet 中。使用比例缩放时，可以将额外的副本分布到所有 ReplicaSet。 较大比例的副本会被添加到拥有最多副本的 ReplicaSet，而较低比例的副本会进入到 副本较少的 ReplicaSet。所有剩下的副本都会添加到副本最多的 ReplicaSet。 具有零副本的 ReplicaSets 不会被扩容。</p></li></ul><p>在上面的示例中，3 个副本被添加到旧 ReplicaSet 中，2 个副本被添加到新 ReplicaSet。 假定新的副本都很健康，上线过程最终应将所有副本迁移到新的 ReplicaSet 中。 要确认这一点，请运行：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl get deploy</span><br></pre></td></tr></table></figure><p>输出类似于：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">NAME                 DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE</span><br><span class="line">nginx-deployment     15        18        7            8           7m</span><br></pre></td></tr></table></figure><p>上线状态确认了副本是如何被添加到每个 ReplicaSet 的。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl get rs</span><br></pre></td></tr></table></figure><p>输出类似于：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">NAME                          DESIRED   CURRENT   READY     AGE</span><br><span class="line">nginx-deployment-1989198191   7         7         0         7m</span><br><span class="line">nginx-deployment-618515232    11        11        11        7m</span><br></pre></td></tr></table></figure><h2 id="Deployment-状态"><a href="#Deployment-状态" class="headerlink" title="Deployment 状态"></a>Deployment 状态</h2><p>Deployment 的生命周期中会有许多状态。上线新的 ReplicaSet 期间可能处于 <a href="https://kubernetes.io/zh/docs/concepts/workloads/controllers/deployment/#progressing-deployment">Progressing（进行中）</a>，可能是 <a href="https://kubernetes.io/zh/docs/concepts/workloads/controllers/deployment/#complete-deployment">Complete（已完成）</a>，也可能是 <a href="https://kubernetes.io/zh/docs/concepts/workloads/controllers/deployment/#failed-deployment">Failed（失败）</a>以至于无法继续进行。</p><h3 id="进行中的-Deployment"><a href="#进行中的-Deployment" class="headerlink" title="进行中的 Deployment"></a>进行中的 Deployment</h3><p>执行下面的任务期间，Kubernetes 标记 Deployment 为 <em>进行中（Progressing）</em>：</p><ul><li>Deployment 创建新的 ReplicaSet</li><li>Deployment 正在为其最新的 ReplicaSet 扩容</li><li>Deployment 正在为其旧有的 ReplicaSet(s) 缩容</li><li>新的 Pods 已经就绪或者可用（就绪至少持续了 <a href="https://kubernetes.io/zh/docs/concepts/workloads/controllers/deployment/#min-ready-seconds">MinReadySeconds</a> 秒）。</li></ul><p>你可以使用 <code>kubectl rollout status</code> 监视 Deployment 的进度。</p><h3 id="完成的-Deployment"><a href="#完成的-Deployment" class="headerlink" title="完成的 Deployment"></a>完成的 Deployment</h3><p>当 Deployment 具有以下特征时，Kubernetes 将其标记为 <em>完成（Complete）</em>：</p><ul><li>与 Deployment 关联的所有副本都已更新到指定的最新版本，这意味着之前请求的所有更新都已完成。</li><li>与 Deployment 关联的所有副本都可用。</li><li>未运行 Deployment 的旧副本。</li></ul><p>你可以使用 <code>kubectl rollout status</code> 检查 Deployment 是否已完成。 如果上线成功完成，<code>kubectl rollout status</code> 返回退出代码 0。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl rollout status deployment/nginx-deployment</span><br></pre></td></tr></table></figure><p>输出类似于：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Waiting for rollout to finish: 2 of 3 updated replicas are available...</span><br><span class="line">deployment &quot;nginx-deployment&quot; successfully rolled out</span><br><span class="line"><span class="meta">$</span><span class="bash"> <span class="built_in">echo</span> $?</span></span><br><span class="line">0</span><br></pre></td></tr></table></figure><h3 id="失败的-Deployment"><a href="#失败的-Deployment" class="headerlink" title="失败的 Deployment"></a>失败的 Deployment</h3><p>你的 Deployment 可能会在尝试部署其最新的 ReplicaSet 受挫，一直处于未完成状态。 造成此情况一些可能因素如下：</p><ul><li>配额（Quota）不足</li><li>就绪探测（Readiness Probe）失败</li><li>镜像拉取错误</li><li>权限不足</li><li>限制范围（Limit Ranges）问题</li><li>应用程序运行时的配置错误</li></ul><p>检测此状况的一种方法是在 Deployment 规约中指定截止时间参数： （[<code>.spec.progressDeadlineSeconds</code>]（#progress-deadline-seconds））。 <code>.spec.progressDeadlineSeconds</code> 给出的是一个秒数值，Deployment 控制器在（通过 Deployment 状态） 标示 Deployment 进展停滞之前，需要等待所给的时长。</p><p>以下 <code>kubectl</code> 命令设置规约中的 <code>progressDeadlineSeconds</code>，从而告知控制器 在 10 分钟后报告 Deployment 没有进展：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl patch deployment.v1.apps/nginx-deployment -p &#x27;&#123;&quot;spec&quot;:&#123;&quot;progressDeadlineSeconds&quot;:600&#125;&#125;&#x27;</span><br></pre></td></tr></table></figure><p>输出类似于：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">deployment.apps/nginx-deployment patched</span><br></pre></td></tr></table></figure><p>超过截止时间后，Deployment 控制器将添加具有以下属性的 DeploymentCondition 到 Deployment 的 <code>.status.conditions</code> 中：</p><ul><li>Type=Progressing</li><li>Status=False</li><li>Reason=ProgressDeadlineExceeded</li></ul><p>Deployment 可能会出现瞬时性的错误，可能因为设置的超时时间过短， 也可能因为其他可认为是临时性的问题。</p><h3 id="对失败-Deployment-的操作"><a href="#对失败-Deployment-的操作" class="headerlink" title="对失败 Deployment 的操作"></a>对失败 Deployment 的操作</h3><p>可应用于已完成的 Deployment 的所有操作也适用于失败的 Deployment。 你可以对其执行扩缩容、回滚到以前的修订版本等操作，或者在需要对 Deployment 的 Pod 模板应用多项调整时，将 Deployment 暂停。</p><h2 id="清理策略"><a href="#清理策略" class="headerlink" title="清理策略"></a>清理策略</h2><p>你可以在 Deployment 中设置 <code>.spec.revisionHistoryLimit</code> 字段以指定保留此 Deployment 的多少个旧有 ReplicaSet。其余的 ReplicaSet 将在后台被垃圾回收。 默认情况下，此值为 10。</p><p><strong>说明：</strong> 显式将此字段设置为 0 将导致 Deployment 的所有历史记录被清空，因此 Deployment 将无法回滚。</p><h2 id="金丝雀部署"><a href="#金丝雀部署" class="headerlink" title="金丝雀部署"></a>金丝雀部署</h2><p>如果要使用 Deployment 向用户子集或服务器子集上线版本，则可以遵循 <a href="https://kubernetes.io/zh/docs/concepts/cluster-administration/manage-deployment/#canary-deployments">资源管理</a> 所描述的金丝雀模式，创建多个 Deployment，每个版本一个。</p><h2 id="编写-Deployment-规约"><a href="#编写-Deployment-规约" class="headerlink" title="编写 Deployment 规约"></a>编写 Deployment 规约</h2><p>同其他 Kubernetes 配置一样， Deployment 需要 <code>apiVersion</code>，<code>kind</code> 和 <code>metadata</code> 字段。 有关配置文件的其他信息，请参考 <a href="https://kubernetes.io/zh/docs/tasks/run-application/run-stateless-application-deployment/">部署 Deployment </a>、配置容器和 <a href="https://kubernetes.io/zh/docs/concepts/overview/working-with-objects/object-management/">使用 kubectl 管理资源</a>等相关文档。</p><p>Deployment 对象的名称必须是合法的 <a href="https://kubernetes.io/zh/docs/concepts/overview/working-with-objects/names#dns-subdomain-names">DNS 子域名</a>。 Deployment 还需要 <a href="https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#spec-and-status"><code>.spec</code> 部分</a>。</p><h3 id="Pod-模板"><a href="#Pod-模板" class="headerlink" title="Pod 模板"></a>Pod 模板</h3><p><code>.spec</code> 中只有 <code>.spec.template</code> 和 <code>.spec.selector</code> 是必需的字段。</p><p><code>.spec.template</code> 是一个 <a href="https://kubernetes.io/zh/docs/concepts/workloads/pods/#pod-templates">Pod 模板</a>。 它和 <a href="https://kubernetes.io/docs/concepts/workloads/pods/pod-overview/">Pod</a> 的语法规则完全相同。 只是这里它是嵌套的，因此不需要 <code>apiVersion</code> 或 <code>kind</code>。</p><p>除了 Pod 的必填字段外，Deployment 中的 Pod 模板必须指定适当的标签和适当的重新启动策略。 对于标签，请确保不要与其他控制器重叠。请参考<a href="https://kubernetes.io/zh/docs/concepts/workloads/controllers/deployment/#selector">选择算符</a>。</p><p>只有 <a href="https://kubernetes.io/zh/docs/concepts/workloads/pods/pod-lifecycle/#restart-policy"><code>.spec.template.spec.restartPolicy</code></a> 等于 <code>Always</code> 才是被允许的，这也是在没有指定时的默认设置。</p><h3 id="副本"><a href="#副本" class="headerlink" title="副本"></a>副本</h3><p><code>.spec.replicas</code> 是指定所需 Pod 的可选字段。它的默认值是1。</p><h3 id="选择算符"><a href="#选择算符" class="headerlink" title="选择算符"></a>选择算符</h3><p><code>.spec.selector</code> 是指定本 Deployment 的 Pod <a href="https://kubernetes.io/zh/docs/concepts/overview/working-with-objects/labels/">标签选择算符</a>的必需字段。</p><p><code>.spec.selector</code> 必须匹配 <code>.spec.template.metadata.labels</code>，否则请求会被 API 拒绝。</p><p>在 API <code>apps/v1</code>版本中，<code>.spec.selector</code> 和 <code>.metadata.labels</code> 如果没有设置的话， 不会被默认设置为 <code>.spec.template.metadata.labels</code>，所以需要明确进行设置。 同时在 <code>apps/v1</code>版本中，Deployment 创建后 <code>.spec.selector</code> 是不可变的。</p><p>当 Pod 的标签和选择算符匹配，但其模板和 <code>.spec.template</code> 不同时，或者此类 Pod 的总数超过 <code>.spec.replicas</code> 的设置时，Deployment 会终结之。 如果 Pods 总数未达到期望值，Deployment 会基于 <code>.spec.template</code> 创建新的 Pod。</p><h3 id="策略"><a href="#策略" class="headerlink" title="策略"></a>策略</h3><p><code>.spec.strategy</code> 策略指定用于用新 Pods 替换旧 Pods 的策略。 <code>.spec.strategy.type</code> 可以是 “Recreate” 或 “RollingUpdate”。“RollingUpdate” 是默认值。</p><h4 id="重新创建-Deployment"><a href="#重新创建-Deployment" class="headerlink" title="重新创建 Deployment"></a>重新创建 Deployment</h4><p>如果 <code>.spec.strategy.type==Recreate</code>，在创建新 Pods 之前，所有现有的 Pods 会被杀死。</p><h4 id="滚动更新-Deployment"><a href="#滚动更新-Deployment" class="headerlink" title="滚动更新 Deployment"></a>滚动更新 Deployment</h4><p>Deployment 会在 <code>.spec.strategy.type==RollingUpdate</code>时，采取 滚动更新的方式更新 Pods。你可以指定 <code>maxUnavailable</code> 和 <code>maxSurge</code> 来控制滚动更新 过程。</p><h5 id="最大不可用"><a href="#最大不可用" class="headerlink" title="最大不可用"></a>最大不可用</h5><p><code>.spec.strategy.rollingUpdate.maxUnavailable</code> 是一个可选字段，用来指定 更新过程中不可用的 Pod 的个数上限。该值可以是绝对数字（例如，5），也可以是 所需 Pods 的百分比（例如，10%）。百分比值会转换成绝对数并去除小数部分。 如果 <code>.spec.strategy.rollingUpdate.maxSurge</code> 为 0，则此值不能为 0。 默认值为 25%。</p><p>例如，当此值设置为 30% 时，滚动更新开始时会立即将旧 ReplicaSet 缩容到期望 Pod 个数的70%。 新 Pod 准备就绪后，可以继续缩容旧有的 ReplicaSet，然后对新的 ReplicaSet 扩容，确保在更新期间 可用的 Pods 总数在任何时候都至少为所需的 Pod 个数的 70%。</p><h5 id="最大峰值"><a href="#最大峰值" class="headerlink" title="最大峰值"></a>最大峰值</h5><p><code>.spec.strategy.rollingUpdate.maxSurge</code> 是一个可选字段，用来指定可以创建的超出 期望 Pod 个数的 Pod 数量。此值可以是绝对数（例如，5）或所需 Pods 的百分比（例如，10%）。 如果 <code>MaxUnavailable</code> 为 0，则此值不能为 0。百分比值会通过向上取整转换为绝对数。 此字段的默认值为 25%。</p><p>例如，当此值为 30% 时，启动滚动更新后，会立即对新的 ReplicaSet 扩容，同时保证新旧 Pod 的总数不超过所需 Pod 总数的 130%。一旦旧 Pods 被杀死，新的 ReplicaSet 可以进一步扩容， 同时确保更新期间的任何时候运行中的 Pods 总数最多为所需 Pods 总数的 130%。</p><h3 id="进度期限秒数"><a href="#进度期限秒数" class="headerlink" title="进度期限秒数"></a>进度期限秒数</h3><p><code>.spec.progressDeadlineSeconds</code> 是一个可选字段，用于指定系统在报告 Deployment <a href="https://kubernetes.io/zh/docs/concepts/workloads/controllers/deployment/#failed-deployment">进展失败</a> 之前等待 Deployment 取得进展的秒数。 这类报告会在资源状态中体现为 <code>Type=Progressing</code>、<code>Status=False</code>、 <code>Reason=ProgressDeadlineExceeded</code>。Deployment 控制器将持续重试 Deployment。 将来，一旦实现了自动回滚，Deployment 控制器将在探测到这样的条件时立即回滚 Deployment。</p><p>如果指定，则此字段值需要大于 <code>.spec.minReadySeconds</code> 取值。</p><h3 id="最短就绪时间"><a href="#最短就绪时间" class="headerlink" title="最短就绪时间"></a>最短就绪时间</h3><p><code>.spec.minReadySeconds</code> 是一个可选字段，用于指定新创建的 Pod 在没有任意容器崩溃情况下的最小就绪时间， 只有超出这个时间 Pod 才被视为可用。默认值为 0（Pod 在准备就绪后立即将被视为可用）。 要了解何时 Pod 被视为就绪，可参考<a href="https://kubernetes.io/zh/docs/concepts/workloads/pods/pod-lifecycle/#container-probes">容器探针</a>。</p><h3 id="修订历史限制"><a href="#修订历史限制" class="headerlink" title="修订历史限制"></a>修订历史限制</h3><p>Deployment 的修订历史记录存储在它所控制的 ReplicaSets 中。</p><p><code>.spec.revisionHistoryLimit</code> 是一个可选字段，用来设定出于会滚目的所要保留的旧 ReplicaSet 数量。 这些旧 ReplicaSet 会消耗 etcd 中的资源，并占用 <code>kubectl get rs</code> 的输出。 每个 Deployment 修订版本的配置都存储在其 ReplicaSets 中；因此，一旦删除了旧的 ReplicaSet， 将失去回滚到 Deployment 的对应修订版本的能力。 默认情况下，系统保留 10 个旧 ReplicaSet，但其理想值取决于新 Deployment 的频率和稳定性。</p><p>更具体地说，将此字段设置为 0 意味着将清理所有具有 0 个副本的旧 ReplicaSet。 在这种情况下，无法撤消新的 Deployment 上线，因为它的修订历史被清除了。</p><h3 id="paused（暂停的）"><a href="#paused（暂停的）" class="headerlink" title="paused（暂停的）"></a>paused（暂停的）</h3><p><code>.spec.paused</code> 是用于暂停和恢复 Deployment 的可选布尔字段。 暂停的 Deployment 和未暂停的 Deployment 的唯一区别是，Deployment 处于暂停状态时， PodTemplateSpec 的任何修改都不会触发新的上线。 Deployment 在创建时是默认不会处于暂停状态。</p><h1 id="ReplicaSet"><a href="#ReplicaSet" class="headerlink" title="ReplicaSet"></a>ReplicaSet</h1><p>ReplicaSet 的目的是<strong>维护一组在任何时候都处于运行状态的 Pod 副本的稳定集合</strong>。 因此，它通常用来保证给定数量的、完全相同的 Pod 的可用性。</p><h2 id="ReplicaSet-的工作原理"><a href="#ReplicaSet-的工作原理" class="headerlink" title="ReplicaSet 的工作原理"></a>ReplicaSet 的工作原理</h2><p>RepicaSet 是通过一组字段来定义的，包括一个用来识别可获得的 Pod 的集合的选择算符、一个用来标明应该维护的副本个数的数值、一个用来指定应该创建新 Pod 以满足副本个数条件时要使用的 Pod 模板等等。 每个 ReplicaSet 都通过根据需要创建和 删除 Pod 以使得副本个数达到期望值， 进而实现其存在价值。当 ReplicaSet 需要创建新的 Pod 时，会使用所提供的 Pod 模板。</p><p>ReplicaSet 通过 Pod 上的 <a href="https://kubernetes.io/zh/docs/concepts/workloads/controllers/garbage-collection/#owners-and-dependents">metadata.ownerReferences</a> 字段连接到附属 Pod，该字段给出当前对象的属主资源。 ReplicaSet 所获得的 Pod 都在其 ownerReferences 字段中包含了属主 ReplicaSet 的标识信息。正是通过这一连接，ReplicaSet 知道它所维护的 Pod 集合的状态， 并据此计划其操作行为。</p><p>ReplicaSet 使用其选择算符来辨识要获得的 Pod 集合。如果某个 Pod 没有 OwnerReference 或者其 OwnerReference 不是一个 <a href="https://kubernetes.io/zh/docs/concepts/architecture/controller/">控制器</a>，且其匹配到 某 ReplicaSet 的选择算符，则该 Pod 立即被此 ReplicaSet 获得。</p><h2 id="何时使用-ReplicaSet"><a href="#何时使用-ReplicaSet" class="headerlink" title="何时使用 ReplicaSet"></a>何时使用 ReplicaSet</h2><p>ReplicaSet 确保任何时间都有指定数量的 Pod 副本在运行。 然而，Deployment 是一个更高级的概念，它管理 ReplicaSet，并向 Pod 提供声明式的更新以及许多其他有用的功能。 因此，我们<strong>建议使用 Deployment 而不是直接使用 ReplicaSet，除非 你需要自定义更新业务流程或根本不需要更新。</strong></p><p>这实际上意味着，你<strong>可能永远不需要操作 ReplicaSet 对象：而是使用 Deployment，并在 spec 部分定义你的应用</strong>。</p><h2 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h2><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ReplicaSet</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">frontend</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">guestbook</span></span><br><span class="line">    <span class="attr">tier:</span> <span class="string">frontend</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="comment"># modify replicas according to your case</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">3</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">tier:</span> <span class="string">frontend</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">tier:</span> <span class="string">frontend</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">php-redis</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">gcr.io/google_samples/gb-frontend:v3</span></span><br></pre></td></tr></table></figure><p>将此清单保存到 <code>frontend.yaml</code> 中，并将其提交到 Kubernetes 集群， 应该就能创建 yaml 文件所定义的 ReplicaSet 及其管理的 Pod。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f https://kubernetes.io/examples/controllers/frontend.yaml</span><br></pre></td></tr></table></figure><p>你可以看到当前被部署的 ReplicaSet：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl get rs</span><br></pre></td></tr></table></figure><p>并看到你所创建的前端：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">NAME       DESIRED   CURRENT   READY   AGE</span><br><span class="line">frontend   3         3         3       6s</span><br></pre></td></tr></table></figure><p>你也可以查看 ReplicaSet 的状态：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl describe rs/frontend</span><br></pre></td></tr></table></figure><p>你会看到类似如下的输出：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">Name:frontend</span><br><span class="line">Namespace:default</span><br><span class="line">Selector:tier=frontend</span><br><span class="line">Labels:app=guestbook</span><br><span class="line">tier=frontend</span><br><span class="line">Annotations:  kubectl.kubernetes.io/last-applied-configuration:</span><br><span class="line">                &#123;&quot;apiVersion&quot;:&quot;apps/v1&quot;,&quot;kind&quot;:&quot;ReplicaSet&quot;,&quot;metadata&quot;:&#123;&quot;annotations&quot;:&#123;&#125;,&quot;labels&quot;:&#123;&quot;app&quot;:&quot;guestbook&quot;,&quot;tier&quot;:&quot;frontend&quot;&#125;,&quot;name&quot;:&quot;frontend&quot;,...</span><br><span class="line">Replicas:3 current / 3 desired</span><br><span class="line">Pods Status:3 Running / 0 Waiting / 0 Succeeded / 0 Failed</span><br><span class="line">Pod Template:</span><br><span class="line">  Labels:       tier=frontend</span><br><span class="line">  Containers:</span><br><span class="line">   php-redis:</span><br><span class="line">    Image:      gcr.io/google_samples/gb-frontend:v3</span><br><span class="line">    Port:         &lt;none&gt;</span><br><span class="line">    Host Port:    &lt;none&gt;</span><br><span class="line">    Environment:  &lt;none&gt;</span><br><span class="line">    Mounts:             &lt;none&gt;</span><br><span class="line">  Volumes:              &lt;none&gt;</span><br><span class="line">Events:</span><br><span class="line">  Type    Reason            Age   From                   Message</span><br><span class="line">  ----    ------            ----  ----                   -------</span><br><span class="line">  Normal  SuccessfulCreate  117s  replicaset-controller  Created pod: frontend-wtsmm</span><br><span class="line">  Normal  SuccessfulCreate  116s  replicaset-controller  Created pod: frontend-b2zdv</span><br><span class="line">  Normal  SuccessfulCreate  116s  replicaset-controller  Created pod: frontend-vcmts</span><br></pre></td></tr></table></figure><p>最后可以查看启动了的 Pods：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl get pods</span><br></pre></td></tr></table></figure><p>你会看到类似如下的 Pod 信息：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">NAME             READY   STATUS    RESTARTS   AGE</span><br><span class="line">frontend-b2zdv   1/1     Running   0          6m36s</span><br><span class="line">frontend-vcmts   1/1     Running   0          6m36s</span><br><span class="line">frontend-wtsmm   1/1     Running   0          6m36s</span><br></pre></td></tr></table></figure><p>你也可以查看 Pods 的属主引用被设置为前端的 ReplicaSet。 要实现这点，可取回运行中的 Pods 之一的 YAML：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl get pods frontend-b2zdv -o yaml</span><br></pre></td></tr></table></figure><p>输出将类似这样，frontend ReplicaSet 的信息被设置在 metadata 的 <code>ownerReferences</code> 字段中：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">creationTimestamp:</span> <span class="string">&quot;2020-02-12T07:06:16Z&quot;</span></span><br><span class="line">  <span class="attr">generateName:</span> <span class="string">frontend-</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">tier:</span> <span class="string">frontend</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">frontend-b2zdv</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">default</span></span><br><span class="line">  <span class="attr">ownerReferences:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line">    <span class="attr">blockOwnerDeletion:</span> <span class="literal">true</span></span><br><span class="line">    <span class="attr">controller:</span> <span class="literal">true</span></span><br><span class="line">    <span class="attr">kind:</span> <span class="string">ReplicaSet</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">frontend</span></span><br><span class="line">    <span class="attr">uid:</span> <span class="string">f391f6db-bb9b-4c09-ae74-6a1f77f3d5cf</span></span><br><span class="line"><span class="string">...</span></span><br></pre></td></tr></table></figure><h2 id="编写-ReplicaSet-的-spec"><a href="#编写-ReplicaSet-的-spec" class="headerlink" title="编写 ReplicaSet 的 spec"></a>编写 ReplicaSet 的 spec</h2><p>与所有其他 Kubernetes API 对象一样，ReplicaSet 也需要 <code>apiVersion</code>、<code>kind</code>、和 <code>metadata</code> 字段。 对于 ReplicaSets 而言，其 <code>kind</code> 始终是 ReplicaSet。 在 Kubernetes 1.9 中，ReplicaSet 上的 API 版本 <code>apps/v1</code> 是其当前版本，且被 默认启用。API 版本 <code>apps/v1beta2</code> 已被废弃。 参考 <code>frontend.yaml</code> 示例的第一行。</p><p>ReplicaSet 对象的名称必须是合法的 <a href="https://kubernetes.io/zh/docs/concepts/overview/working-with-objects/names#dns-subdomain-names">DNS 子域名</a>。</p><p>ReplicaSet 也需要 <a href="https://git.k8s.io/community/contributors/devel/api-conventions.md#spec-and-status"><code>.spec</code></a> 部分。</p><h3 id="Pod-模版-1"><a href="#Pod-模版-1" class="headerlink" title="Pod 模版"></a>Pod 模版</h3><p><code>.spec.template</code> 是一个<a href="https://kubernetes.io/zh/docs/concepts/workloads/pods/#pod-templates">Pod 模版</a>， 要求设置标签。在 <code>frontend.yaml</code> 示例中，我们指定了标签 <code>tier: frontend</code>。 注意不要将标签与其他控制器的选择算符重叠，否则那些控制器会尝试收养此 Pod。</p><p>对于模板的<a href="https://kubernetes.io/zh/docs/concepts/workloads/pods/pod-lifecycle/#restart-policy">重启策略</a> 字段，<code>.spec.template.spec.restartPolicy</code>，唯一允许的取值是 <code>Always</code>，这也是默认值.</p><h3 id="Pod-选择算符"><a href="#Pod-选择算符" class="headerlink" title="Pod 选择算符"></a>Pod 选择算符</h3><p><code>.spec.selector</code> 字段是一个<a href="https://kubernetes.io/zh/docs/concepts/overview/working-with-objects/labels/">标签选择算符</a>。 如前文中<a href="https://kubernetes.io/zh/docs/concepts/workloads/controllers/replicaset/#how-a-replicaset-works">所讨论的</a>，这些是用来标识要被获取的 Pods 的标签。在签名的 <code>frontend.yaml</code> 示例中，选择算符为：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">matchLabels:</span></span><br><span class="line">  <span class="attr">tier:</span> <span class="string">frontend</span></span><br></pre></td></tr></table></figure><p>在 ReplicaSet 中，<code>.spec.template.metadata.labels</code> 的值必须与 <code>spec.selector</code> 值 相匹配，否则该配置会被 API 拒绝。</p><blockquote><p>对于设置了相同的 <code>.spec.selector</code>，但 <code>.spec.template.metadata.labels</code> 和 <code>.spec.template.spec</code> 字段不同的 两个 ReplicaSet 而言，每个 ReplicaSet 都会忽略被另一个 ReplicaSet 所 创建的 Pods。</p></blockquote><h3 id="Replicas"><a href="#Replicas" class="headerlink" title="Replicas"></a>Replicas</h3><p>你可以通过设置 <code>.spec.replicas</code> 来指定要同时运行的 Pod 个数。 ReplicaSet 创建、删除 Pods 以与此值匹配。</p><p>如果你没有指定 <code>.spec.replicas</code>, 那么默认值为 1。</p><h2 id="使用-ReplicaSets"><a href="#使用-ReplicaSets" class="headerlink" title="使用 ReplicaSets"></a>使用 ReplicaSets</h2><h3 id="删除-ReplicaSet-和它的-Pod"><a href="#删除-ReplicaSet-和它的-Pod" class="headerlink" title="删除 ReplicaSet 和它的 Pod"></a>删除 ReplicaSet 和它的 Pod</h3><p>要删除 ReplicaSet 和它的所有 Pod，使用 <a href="https://kubernetes.io/docs/reference/generated/kubectl/kubectl-commands#delete"><code>kubectl delete</code></a> 命令。 默认情况下，<a href="https://kubernetes.io/zh/docs/concepts/workloads/controllers/garbage-collection/">垃圾收集器</a> 自动删除所有依赖的 Pod。</p><p>当使用 REST API 或 <code>client-go</code> 库时，你必须在删除选项中将 <code>propagationPolicy</code> 设置为 <code>Background</code> 或 <code>Foreground</code>。例如：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">kubectl proxy --port=8080</span><br><span class="line">curl -X DELETE  &#x27;localhost:8080/apis/apps/v1/namespaces/default/replicasets/frontend&#x27; \</span><br><span class="line">   -d &#x27;&#123;&quot;kind&quot;:&quot;DeleteOptions&quot;,&quot;apiVersion&quot;:&quot;v1&quot;,&quot;propagationPolicy&quot;:&quot;Foreground&quot;&#125;&#x27; \</span><br><span class="line">   -H &quot;Content-Type: application/json&quot;</span><br></pre></td></tr></table></figure><h3 id="只删除-ReplicaSet"><a href="#只删除-ReplicaSet" class="headerlink" title="只删除 ReplicaSet"></a>只删除 ReplicaSet</h3><p>你可以只删除 ReplicaSet 而不影响它的 Pods，方法是使用 <a href="https://kubernetes.io/docs/reference/generated/kubectl/kubectl-commands#delete"><code>kubectl delete</code></a> 命令并设置 <code>--cascade=orphan</code> 选项。</p><p>当使用 REST API 或 <code>client-go</code> 库时，你必须将 <code>propagationPolicy</code> 设置为 <code>Orphan</code>。 例如：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">kubectl proxy --port=8080</span><br><span class="line">curl -X DELETE  &#x27;localhost:8080/apis/apps/v1/namespaces/default/replicasets/frontend&#x27; \</span><br><span class="line">  -d &#x27;&#123;&quot;kind&quot;:&quot;DeleteOptions&quot;,&quot;apiVersion&quot;:&quot;v1&quot;,&quot;propagationPolicy&quot;:&quot;Orphan&quot;&#125;&#x27; \</span><br><span class="line">  -H &quot;Content-Type: application/json&quot;</span><br></pre></td></tr></table></figure><p>一旦删除了原来的 ReplicaSet，就可以创建一个新的来替换它。 由于新旧 ReplicaSet 的 <code>.spec.selector</code> 是相同的，新的 ReplicaSet 将接管老的 Pod。 但是，它不会努力使现有的 Pod 与新的、不同的 Pod 模板匹配。 若想要以可控的方式更新 Pod 的规约，可以使用 <a href="https://kubernetes.io/zh/docs/concepts/workloads/controllers/deployment/#creating-a-deployment">Deployment</a> 资源，因为 ReplicaSet 并不直接支持滚动更新。</p><h3 id="将-Pod-从-ReplicaSet-中隔离"><a href="#将-Pod-从-ReplicaSet-中隔离" class="headerlink" title="将 Pod 从 ReplicaSet 中隔离"></a>将 Pod 从 ReplicaSet 中隔离</h3><p>可以通过改变标签来从 ReplicaSet 的目标集中移除 Pod。 这种技术可以用来从服务中去除 Pod，以便进行排错、数据恢复等。 以这种方式移除的 Pod 将被自动替换（假设副本的数量没有改变）。</p><h3 id="缩放-RepliaSet"><a href="#缩放-RepliaSet" class="headerlink" title="缩放 RepliaSet"></a>缩放 RepliaSet</h3><p>通过更新 <code>.spec.replicas</code> 字段，ReplicaSet 可以被轻松的进行缩放。ReplicaSet 控制器能确保匹配标签选择器的数量的 Pod 是可用的和可操作的。</p><p>在降低集合规模时，ReplicaSet 控制器通过对可用的 Pods 进行排序来优先选择 要被删除的 Pods。其一般性算法如下：</p><ol><li>首先选择剔除悬决（Pending，且不可调度）的 Pods</li><li>如果设置了 <code>controller.kubernetes.io/pod-deletion-cost</code> 注解，则注解值 较小的优先被裁减掉</li><li>所处节点上副本个数较多的 Pod 优先于所处节点上副本较少者</li><li>如果 Pod 的创建时间不同，最近创建的 Pod 优先于早前创建的 Pod 被裁减。 （当 <code>LogarithmicScaleDown</code> 这一 <a href="https://kubernetes.io/zh/docs/reference/command-line-tools-reference/feature-gates/">特性门控</a> 被启用时，创建时间是按整数幂级来分组的）。</li></ol><p>如果以上比较结果都相同，则随机选择。</p><h3 id="Pod-删除开销"><a href="#Pod-删除开销" class="headerlink" title="Pod 删除开销"></a>Pod 删除开销</h3><p><strong>FEATURE STATE:</strong> <code>Kubernetes v1.22 [beta]</code></p><p>通过使用 <a href="https://kubernetes.io/zh/docs/reference/labels-annotations-taints/#pod-deletion-cost"><code>controller.kubernetes.io/pod-deletion-cost</code></a> 注解，用户可以对 ReplicaSet 缩容时要先删除哪些 Pods 设置偏好。</p><p>此注解要设置到 Pod 上，取值范围为 [-2147483647, 2147483647]。 所代表的的是删除同一 ReplicaSet 中其他 Pod 相比较而言的开销。 删除开销较小的 Pods 比删除开销较高的 Pods 更容易被删除。</p><p>Pods 如果未设置此注解，则隐含的设置值为 0。负值也是可接受的。 如果注解值非法，API 服务器会拒绝对应的 Pod。</p><p>此功能特性处于 Beta 阶段，默认被禁用。你可以通过为 kube-apiserver 和 kube-controller-manager 设置 <a href="https://kubernetes.io/zh/docs/reference/command-line-tools-reference/feature-gates/">特性门控</a> <code>PodDeletionCost</code> 来启用此功能。</p><p><strong>说明：</strong></p><ul><li>此机制实施时仅是尽力而为，并不能对 Pod 的删除顺序作出任何保证；</li><li>用户应避免频繁更新注解值，例如根据某观测度量值来更新此注解值是应该避免的。 这样做会在 API 服务器上产生大量的 Pod 更新操作。</li></ul><h4 id="使用场景示例"><a href="#使用场景示例" class="headerlink" title="使用场景示例"></a>使用场景示例</h4><p>同一应用的不同 Pods 可能其利用率是不同的。在对应用执行缩容操作时，可能 希望移除利用率较低的 Pods。为了避免频繁更新 Pods，应用应该在执行缩容 操作之前更新一次 <code>controller.kubernetes.io/pod-deletion-cost</code> 注解值 （将注解值设置为一个与其 Pod 利用率对应的值）。 如果应用自身控制器缩容操作时（例如 Spark 部署的驱动 Pod），这种机制 是可以起作用的。</p><h3 id="ReplicaSet-作为水平的-Pod-自动缩放器目标"><a href="#ReplicaSet-作为水平的-Pod-自动缩放器目标" class="headerlink" title="ReplicaSet 作为水平的 Pod 自动缩放器目标"></a>ReplicaSet 作为水平的 Pod 自动缩放器目标</h3><p>ReplicaSet 也可以作为 <a href="https://kubernetes.io/zh/docs/tasks/run-application/horizontal-pod-autoscale/">水平的 Pod 缩放器 (HPA)</a> 的目标。也就是说，ReplicaSet 可以被 HPA 自动缩放。 以下是 HPA 以我们在前一个示例中创建的副本集为目标的示例。</p><p><a href="https://raw.githubusercontent.com/kubernetes/website/main/content/zh/examples/controllers/hpa-rs.yaml"><code>controllers/hpa-rs.yaml</code> </a><img src="https://d33wubrfki0l68.cloudfront.net/0901162ab78eb4ff2e9e5dc8b17c3824befc91a6/44ccd/images/copycode.svg" alt="Copy controllers/hpa-rs.yaml to clipboard"></p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">autoscaling/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">HorizontalPodAutoscaler</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">frontend-scaler</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">scaleTargetRef:</span></span><br><span class="line">    <span class="attr">kind:</span> <span class="string">ReplicaSet</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">frontend</span></span><br><span class="line">  <span class="attr">minReplicas:</span> <span class="number">3</span></span><br><span class="line">  <span class="attr">maxReplicas:</span> <span class="number">10</span></span><br><span class="line">  <span class="attr">targetCPUUtilizationPercentage:</span> <span class="number">50</span></span><br></pre></td></tr></table></figure><p>将这个列表保存到 <code>hpa-rs.yaml</code> 并提交到 Kubernetes 集群，就能创建它所定义的 HPA，进而就能根据复制的 Pod 的 CPU 利用率对目标 ReplicaSet进行自动缩放。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f https://k8s.io/examples/controllers/hpa-rs.yaml</span><br></pre></td></tr></table></figure><p>或者，可以使用 <code>kubectl autoscale</code> 命令完成相同的操作。 (而且它更简单！)</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl autoscale rs frontend --max=10 --min=3 --cpu-percent=50</span><br></pre></td></tr></table></figure><h2 id="ReplicaSet-的替代方案"><a href="#ReplicaSet-的替代方案" class="headerlink" title="ReplicaSet 的替代方案"></a>ReplicaSet 的替代方案</h2><h3 id="Deployment-（推荐）"><a href="#Deployment-（推荐）" class="headerlink" title="Deployment （推荐）"></a>Deployment （推荐）</h3><p><a href="https://kubernetes.io/zh/docs/concepts/workloads/controllers/deployment/"><code>Deployment</code></a> 是一个 可以拥有 ReplicaSet 并使用声明式方式在服务器端完成对 Pods 滚动更新的对象。 尽管 ReplicaSet 可以独立使用，目前它们的主要用途是提供给 Deployment 作为 编排 Pod 创建、删除和更新的一种机制。当使用 Deployment 时，你不必关心 如何管理它所创建的 ReplicaSet，Deployment 拥有并管理其 ReplicaSet。 因此，建议你在需要 ReplicaSet 时使用 Deployment。</p><h3 id="裸-Pod"><a href="#裸-Pod" class="headerlink" title="裸 Pod"></a>裸 Pod</h3><p>与用户直接创建 Pod 的情况不同，ReplicaSet 会替换那些由于某些原因被删除或被终止的 Pod，例如在节点故障或破坏性的节点维护（如内核升级）的情况下。 因为这个原因，我们建议你使用 ReplicaSet，即使应用程序只需要一个 Pod。 想像一下，ReplicaSet 类似于进程监视器，只不过它在多个节点上监视多个 Pod， 而不是在单个节点上监视单个进程。 ReplicaSet 将本地容器重启的任务委托给了节点上的某个代理（例如，Kubelet 或 Docker）去完成。</p><h3 id="Job"><a href="#Job" class="headerlink" title="Job"></a>Job</h3><p>使用<a href="https://kubernetes.io/zh/docs/concepts/workloads/controllers/job/"><code>Job</code></a> 代替ReplicaSet， 可以用于那些期望自行终止的 Pod。</p><h3 id="DaemonSet"><a href="#DaemonSet" class="headerlink" title="DaemonSet"></a>DaemonSet</h3><p>对于管理那些提供主机级别功能（如主机监控和主机日志）的容器， 就要用 <a href="https://kubernetes.io/zh/docs/concepts/workloads/controllers/daemonset/"><code>DaemonSet</code></a> 而不用 ReplicaSet。 这些 Pod 的寿命与主机寿命有关：这些 Pod 需要先于主机上的其他 Pod 运行， 并且在机器准备重新启动/关闭时安全地终止。</p><h3 id="ReplicationController"><a href="#ReplicationController" class="headerlink" title="ReplicationController"></a>ReplicationController</h3><p>ReplicaSet 是 <a href="https://kubernetes.io/zh/docs/concepts/workloads/controllers/replicationcontroller/">ReplicationController</a> 的后继者。二者目的相同且行为类似，只是 ReplicationController 不支持 <a href="https://kubernetes.io/zh/docs/concepts/overview/working-with-objects/labels/#label-selectors">标签用户指南</a> 中讨论的基于集合的选择算符需求。 因此，相比于 ReplicationController，应优先考虑 ReplicaSet。</p><h1 id="StatefulSets"><a href="#StatefulSets" class="headerlink" title="StatefulSets"></a>StatefulSets</h1><p>StatefulSet 是用来<strong>管理有状态应用的工作负载 API 对象</strong>。</p><p>StatefulSet 用来管理某 <a href="https://kubernetes.io/docs/concepts/workloads/pods/pod-overview/">Pod</a> 集合的部署和扩缩， 并为这些 Pod 提供持久存储和持久标识符。</p><p>和 <a href="https://kubernetes.io/zh/docs/concepts/workloads/controllers/deployment/">Deployment</a> 类似， StatefulSet 管理基于相同容器规约的一组 Pod。但和 Deployment 不同的是， StatefulSet 为它们的每个 Pod 维护了一个有粘性的 ID。这些 Pod 是基于相同的规约来创建的， 但是不能相互替换：<strong>无论怎么调度，每个 Pod 都有一个永久不变的 ID</strong>。</p><p>如果希望使用存储卷为工作负载提供持久存储，可以使用 StatefulSet 作为解决方案的一部分。 尽管 StatefulSet 中的单个 Pod 仍可能出现故障， 但持久的 Pod 标识符使得将现有卷与替换已失败 Pod 的新 Pod 相匹配变得更加容易。</p><h2 id="使用-StatefulSets"><a href="#使用-StatefulSets" class="headerlink" title="使用 StatefulSets"></a>使用 StatefulSets</h2><p>StatefulSets 对于需要满足以下一个或多个需求的应用程序很有价值：</p><ul><li>稳定的、唯一的网络标识符。</li><li>稳定的、持久的存储。</li><li>有序的、优雅的部署和缩放。</li><li>有序的、自动的滚动更新。</li></ul><p>在上面描述中，“稳定的”意味着 Pod 调度或重调度的整个过程是有持久性的。 如果应用程序不需要任何稳定的标识符或有序的部署、删除或伸缩，则应该使用 由一组无状态的副本控制器提供的工作负载来部署应用程序，比如 <a href="https://kubernetes.io/zh/docs/concepts/workloads/controllers/deployment/">Deployment</a> 或者 <a href="https://kubernetes.io/zh/docs/concepts/workloads/controllers/replicaset/">ReplicaSet</a> 可能更适用于你的无状态应用部署需要。</p><h2 id="限制"><a href="#限制" class="headerlink" title="限制"></a>限制</h2><ul><li>给定 Pod 的存储必须由 <a href="https://github.com/kubernetes/examples/tree/master/staging/persistent-volume-provisioning/README.md">PersistentVolume 驱动</a> 基于所请求的 <code>storage class</code> 来提供，或者由管理员预先提供。</li><li>删除或者收缩 StatefulSet 并<em>不会</em>删除它关联的存储卷。 这样做是为了保证数据安全，它通常比自动清除 StatefulSet 所有相关的资源更有价值。</li><li>StatefulSet 当前需要<a href="https://kubernetes.io/zh/docs/concepts/services-networking/service/#headless-services">无头服务</a> 来负责 Pod 的网络标识。你需要负责创建此服务。</li><li>当删除 StatefulSets 时，StatefulSet 不提供任何终止 Pod 的保证。 为了实现 StatefulSet 中的 Pod 可以有序地且体面地终止，可以在删除之前将 StatefulSet 缩放为 0。</li><li>在默认 <a href="https://kubernetes.io/zh/docs/concepts/workloads/controllers/statefulset/#pod-management-policies">Pod 管理策略</a>(<code>OrderedReady</code>) 时使用 <a href="https://kubernetes.io/zh/docs/concepts/workloads/controllers/statefulset/#rolling-updates">滚动更新</a>，可能进入需要<a href="https://kubernetes.io/zh/docs/concepts/workloads/controllers/statefulset/#forced-rollback">人工干预</a> 才能修复的损坏状态。</li></ul><h2 id="组件"><a href="#组件" class="headerlink" title="组件"></a>组件</h2><p>下面的示例演示了 StatefulSet 的组件。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">nginx</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">port:</span> <span class="number">80</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">web</span></span><br><span class="line">  <span class="attr">clusterIP:</span> <span class="string">None</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">nginx</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">StatefulSet</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">web</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">nginx</span> <span class="comment"># has to match .spec.template.metadata.labels</span></span><br><span class="line">  <span class="attr">serviceName:</span> <span class="string">&quot;nginx&quot;</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">3</span> <span class="comment"># by default is 1</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">nginx</span> <span class="comment"># has to match .spec.selector.matchLabels</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">terminationGracePeriodSeconds:</span> <span class="number">10</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">k8s.gcr.io/nginx-slim:0.8</span></span><br><span class="line">        <span class="attr">ports:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span></span><br><span class="line">          <span class="attr">name:</span> <span class="string">web</span></span><br><span class="line">        <span class="attr">volumeMounts:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">www</span></span><br><span class="line">          <span class="attr">mountPath:</span> <span class="string">/usr/share/nginx/html</span></span><br><span class="line">  <span class="attr">volumeClaimTemplates:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">name:</span> <span class="string">www</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">accessModes:</span> [ <span class="string">&quot;ReadWriteOnce&quot;</span> ]</span><br><span class="line">      <span class="attr">storageClassName:</span> <span class="string">&quot;my-storage-class&quot;</span></span><br><span class="line">      <span class="attr">resources:</span></span><br><span class="line">        <span class="attr">requests:</span></span><br><span class="line">          <span class="attr">storage:</span> <span class="string">1Gi</span></span><br></pre></td></tr></table></figure><p>上述例子中：</p><ul><li>名为 <code>nginx</code> 的 Headless Service 用来控制网络域名。</li><li>名为 <code>web</code> 的 StatefulSet 有一个 Spec，它表明将在独立的 3 个 Pod 副本中启动 nginx 容器。</li><li><code>volumeClaimTemplates</code> 将通过 PersistentVolumes 驱动提供的 <a href="https://kubernetes.io/zh/docs/concepts/storage/persistent-volumes/">PersistentVolumes</a> 来提供稳定的存储。</li></ul><p>StatefulSet 的命名需要遵循<a href="https://kubernetes.io/zh/docs/concepts/overview/working-with-objects/names#dns-subdomain-names">DNS 子域名</a>规范。</p><h2 id="Pod-选择算符-1"><a href="#Pod-选择算符-1" class="headerlink" title="Pod 选择算符"></a>Pod 选择算符</h2><p>你必须设置 StatefulSet 的 <code>.spec.selector</code> 字段，使之匹配其在 <code>.spec.template.metadata.labels</code> 中设置的标签。在 Kubernetes 1.8 版本之前， 被忽略 <code>.spec.selector</code> 字段会获得默认设置值。 在 1.8 和以后的版本中，未指定匹配的 Pod 选择器将在创建 StatefulSet 期间导致验证错误。</p><h2 id="Pod-标识"><a href="#Pod-标识" class="headerlink" title="Pod 标识"></a>Pod 标识</h2><p>StatefulSet Pod 具有唯一的标识，该标识包括顺序标识、稳定的网络标识和稳定的存储。 该标识和 Pod 是绑定的，不管它被调度在哪个节点上。</p><h3 id="有序索引"><a href="#有序索引" class="headerlink" title="有序索引"></a>有序索引</h3><p>对于具有 N 个副本的 StatefulSet，StatefulSet 中的每个 Pod 将被分配一个整数序号， 从 0 到 N-1，该序号在 StatefulSet 上是唯一的。</p><h3 id="稳定的网络-ID"><a href="#稳定的网络-ID" class="headerlink" title="稳定的网络 ID"></a>稳定的网络 ID</h3><p>StatefulSet 中的每个 Pod 根据 StatefulSet 的名称和 Pod 的序号派生出它的主机名。 组合主机名的格式为<code>$(StatefulSet 名称)-$(序号)</code>。 上例将会创建三个名称分别为 <code>web-0、web-1、web-2</code> 的 Pod。 StatefulSet 可以使用 <a href="https://kubernetes.io/zh/docs/concepts/services-networking/service/#headless-services">无头服务</a> 控制它的 Pod 的网络域。管理域的这个服务的格式为： <code>$(服务名称).$(命名空间).svc.cluster.local</code>，其中 <code>cluster.local</code> 是集群域。 一旦每个 Pod 创建成功，就会得到一个匹配的 DNS 子域，格式为： <code>$(pod 名称).$(所属服务的 DNS 域名)</code>，其中所属服务由 StatefulSet 的 <code>serviceName</code> 域来设定。</p><p>取决于集群域内部 DNS 的配置，有可能无法查询一个刚刚启动的 Pod 的 DNS 命名。 当集群内其他客户端在 Pod 创建完成前发出 Pod 主机名查询时，就会发生这种情况。 负缓存 (在 DNS 中较为常见) 意味着之前失败的查询结果会被记录和重用至少若干秒钟， 即使 Pod 已经正常运行了也是如此。</p><p>如果需要在 Pod 被创建之后及时发现它们，有以下选项：</p><ul><li>直接查询 Kubernetes API（比如，利用 watch 机制）而不是依赖于 DNS 查询</li><li>缩短 Kubernetes DNS 驱动的缓存时长（通常这意味着修改 CoreDNS 的 ConfigMap，目前缓存时长为 30 秒）</li></ul><p>正如<a href="https://kubernetes.io/zh/docs/concepts/workloads/controllers/statefulset/#limitations">限制</a>中所述，你需要负责创建<a href="https://kubernetes.io/zh/docs/concepts/services-networking/service/#headless-services">无头服务</a> 以便为 Pod 提供网络标识。</p><p>下面给出一些选择集群域、服务名、StatefulSet 名、及其怎样影响 StatefulSet 的 Pod 上的 DNS 名称的示例：</p><table><thead><tr><th>集群域名</th><th>服务（名字空间/名字）</th><th>StatefulSet（名字空间/名字）</th><th>StatefulSet 域名</th><th>Pod DNS</th><th>Pod 主机名</th></tr></thead><tbody><tr><td>cluster.local</td><td>default/nginx</td><td>default/web</td><td>nginx.default.svc.cluster.local</td><td>web-{0..N-1}.nginx.default.svc.cluster.local</td><td>web-{0..N-1}</td></tr><tr><td>cluster.local</td><td>foo/nginx</td><td>foo/web</td><td>nginx.foo.svc.cluster.local</td><td>web-{0..N-1}.nginx.foo.svc.cluster.local</td><td>web-{0..N-1}</td></tr><tr><td>kube.local</td><td>foo/nginx</td><td>foo/web</td><td>nginx.foo.svc.kube.local</td><td>web-{0..N-1}.nginx.foo.svc.kube.local</td><td>web-{0..N-1}</td></tr></tbody></table><p><strong>说明：</strong> 集群域会被设置为 <code>cluster.local</code>，除非有<a href="https://kubernetes.io/zh/docs/concepts/services-networking/dns-pod-service/">其他配置</a>。</p><h3 id="稳定的存储"><a href="#稳定的存储" class="headerlink" title="稳定的存储"></a>稳定的存储</h3><p>对于 StatefulSet 中定义的每个 VolumeClaimTemplate，每个 Pod 接收到一个 PersistentVolumeClaim。在上面的 nginx 示例中，每个 Pod 将会得到基于 StorageClass <code>my-storage-class</code> 提供的 1 Gib 的 PersistentVolume。 如果没有声明 StorageClass，就会使用默认的 StorageClass。 当一个 Pod 被调度（重新调度）到节点上时，它的 <code>volumeMounts</code> 会挂载与其 PersistentVolumeClaims 相关联的 PersistentVolume。 请注意，当 Pod 或者 StatefulSet 被删除时，与 PersistentVolumeClaims 相关联的 PersistentVolume 并不会被删除。要删除它必须通过手动方式来完成。</p><h3 id="Pod-名称标签"><a href="#Pod-名称标签" class="headerlink" title="Pod 名称标签"></a>Pod 名称标签</h3><p>当 StatefulSet <a href="https://kubernetes.io/zh/docs/concepts/architecture/controller/">控制器（Controller）</a> 创建 Pod 时， 它会添加一个标签 <code>statefulset.kubernetes.io/pod-name</code>，该标签值设置为 Pod 名称。 这个标签允许你给 StatefulSet 中的特定 Pod 绑定一个 Service。</p><h2 id="部署和扩缩保证"><a href="#部署和扩缩保证" class="headerlink" title="部署和扩缩保证"></a>部署和扩缩保证</h2><ul><li>对于包含 N 个 副本的 StatefulSet，当部署 Pod 时，它们是依次创建的，顺序为 <code>0..N-1</code>。</li><li>当删除 Pod 时，它们是逆序终止的，顺序为 <code>N-1..0</code>。</li><li>在将缩放操作应用到 Pod 之前，它前面的所有 Pod 必须是 Running 和 Ready 状态。</li><li>在 Pod 终止之前，所有的继任者必须完全关闭。</li></ul><p>StatefulSet 不应将 <code>pod.Spec.TerminationGracePeriodSeconds</code> 设置为 0。 这种做法是不安全的，要强烈阻止。更多的解释请参考 <a href="https://kubernetes.io/zh/docs/tasks/run-application/force-delete-stateful-set-pod/">强制删除 StatefulSet Pod</a>。</p><p>在上面的 nginx 示例被创建后，会按照 web-0、web-1、web-2 的顺序部署三个 Pod。 在 web-0 进入 <a href="https://kubernetes.io/zh/docs/concepts/workloads/pods/pod-lifecycle/">Running 和 Ready</a> 状态前不会部署 web-1。在 web-1 进入 Running 和 Ready 状态前不会部署 web-2。 如果 web-1 已经处于 Running 和 Ready 状态，而 web-2 尚未部署，在此期间发生了 web-0 运行失败，那么 web-2 将不会被部署，要等到 web-0 部署完成并进入 Running 和 Ready 状态后，才会部署 web-2。</p><p>如果用户想将示例中的 StatefulSet 收缩为 <code>replicas=1</code>，首先被终止的是 web-2。 在 web-2 没有被完全停止和删除前，web-1 不会被终止。 当 web-2 已被终止和删除、web-1 尚未被终止，如果在此期间发生 web-0 运行失败， 那么就不会终止 web-1，必须等到 web-0 进入 Running 和 Ready 状态后才会终止 web-1。</p><h3 id="Pod-管理策略"><a href="#Pod-管理策略" class="headerlink" title="Pod 管理策略"></a>Pod 管理策略</h3><p>在 Kubernetes 1.7 及以后的版本中，StatefulSet 允许你放宽其排序保证， 同时通过它的 <code>.spec.podManagementPolicy</code> 域保持其唯一性和身份保证。</p><h4 id="OrderedReady-Pod-管理"><a href="#OrderedReady-Pod-管理" class="headerlink" title="OrderedReady Pod 管理"></a>OrderedReady Pod 管理</h4><p><code>OrderedReady</code> Pod 管理是 StatefulSet 的默认设置。它实现了 <a href="https://kubernetes.io/zh/docs/concepts/workloads/controllers/statefulset/#deployment-and-scaling-guarantees">上面</a>描述的功能。</p><h4 id="并行-Pod-管理"><a href="#并行-Pod-管理" class="headerlink" title="并行 Pod 管理"></a>并行 Pod 管理</h4><p><code>Parallel</code> Pod 管理让 StatefulSet 控制器并行的启动或终止所有的 Pod， 启动或者终止其他 Pod 前，无需等待 Pod 进入 Running 和 ready 或者完全停止状态。 这个选项只会影响伸缩操作的行为，更新则不会被影响。</p><h2 id="更新策略"><a href="#更新策略" class="headerlink" title="更新策略"></a>更新策略</h2><p>StatefulSet 的 <code>.spec.updateStrategy</code> 字段让 你可以配置和禁用掉自动滚动更新 Pod 的容器、标签、资源请求或限制、以及注解。 有两个允许的值：</p><ul><li><p><code>OnDelete</code></p><p>当 StatefulSet 的 <code>.spec.updateStrategy.type</code> 设置为 <code>OnDelete</code> 时， 它的控制器将不会自动更新 StatefulSet 中的 Pod。 用户必须手动删除 Pod 以便让控制器创建新的 Pod，以此来对 StatefulSet 的 <code>.spec.template</code> 的变动作出反应。</p></li><li><p><code>RollingUpdate</code></p><p><code>RollingUpdate</code> 更新策略对 StatefulSet 中的 Pod 执行自动的滚动更新。这是默认的更新策略。</p></li></ul><h2 id="滚动更新"><a href="#滚动更新" class="headerlink" title="滚动更新"></a>滚动更新</h2><p>当 StatefulSet 的 <code>.spec.updateStrategy.type</code> 被设置为 <code>RollingUpdate</code> 时， StatefulSet 控制器会删除和重建 StatefulSet 中的每个 Pod。 它将按照与 Pod 终止相同的顺序（从最大序号到最小序号）进行，每次更新一个 Pod。</p><p>Kubernetes 控制面会等到被更新的 Pod 进入 Running 和 Ready 状态，然后再更新其前身。 如果你设置了 <code>.spec.minReadySeconds</code>（查看<a href="https://kubernetes.io/zh/docs/concepts/workloads/controllers/statefulset/#minimum-ready-seconds">最短就绪秒数</a>），控制面在 Pod 就绪后会额外等待一定的时间再执行下一步。</p><h3 id="分区滚动更新"><a href="#分区滚动更新" class="headerlink" title="分区滚动更新"></a>分区滚动更新</h3><p>通过声明 <code>.spec.updateStrategy.rollingUpdate.partition</code> 的方式，<code>RollingUpdate</code> 更新策略可以实现分区。 如果声明了一个分区，当 StatefulSet 的 <code>.spec.template</code> 被更新时， 所有序号大于等于该分区序号的 Pod 都会被更新。 所有序号小于该分区序号的 Pod 都不会被更新，并且，即使他们被删除也会依据之前的版本进行重建。 如果 StatefulSet 的 <code>.spec.updateStrategy.rollingUpdate.partition</code> 大于它的 <code>.spec.replicas</code>，对它的 <code>.spec.template</code> 的更新将不会传递到它的 Pod。 在大多数情况下，你不需要使用分区，但如果你希望进行阶段更新、执行金丝雀或执行 分阶段上线，则这些分区会非常有用。</p><h3 id="强制回滚"><a href="#强制回滚" class="headerlink" title="强制回滚"></a>强制回滚</h3><p>在默认 <a href="https://kubernetes.io/zh/docs/concepts/workloads/controllers/statefulset/#pod-management-policies">Pod 管理策略</a>(<code>OrderedReady</code>) 下使用 <a href="https://kubernetes.io/zh/docs/concepts/workloads/controllers/statefulset/#rolling-updates">滚动更新</a> ，可能进入需要人工干预才能修复的损坏状态。</p><p>如果更新后 Pod 模板配置进入无法运行或就绪的状态（例如，由于错误的二进制文件 或应用程序级配置错误），StatefulSet 将停止回滚并等待。</p><p>在这种状态下，仅将 Pod 模板还原为正确的配置是不够的。由于 <a href="https://github.com/kubernetes/kubernetes/issues/67250">已知问题</a>，StatefulSet 将继续等待损坏状态的 Pod 准备就绪（永远不会发生），然后再尝试将其恢复为正常工作配置。</p><p>恢复模板后，还必须删除 StatefulSet 尝试使用错误的配置来运行的 Pod。这样， StatefulSet 才会开始使用被还原的模板来重新创建 Pod。</p><h3 id="最短就绪秒数"><a href="#最短就绪秒数" class="headerlink" title="最短就绪秒数"></a>最短就绪秒数</h3><p><strong>FEATURE STATE:</strong> <code>Kubernetes v1.22 [alpha]</code></p><p><code>.spec.minReadySeconds</code> 是一个可选字段，用于指定新创建的 Pod 就绪（没有任何容器崩溃）后被认为可用的最小秒数。 默认值是 0（Pod 就绪时就被认为可用）。要了解 Pod 何时被认为已就绪，请参阅<a href="https://kubernetes.io/zh/docs/concepts/workloads/pods/pod-lifecycle/#container-probes">容器探针</a>。</p><p>请注意只有当你启用 <code>StatefulSetMinReadySeconds</code> <a href="https://kubernetes.io/zh/docs/reference/command-line-tools-reference/feature-gates/">特性门控</a>时，该字段才会生效。</p><h1 id="DaemonSet-1"><a href="#DaemonSet-1" class="headerlink" title="DaemonSet"></a>DaemonSet</h1><p><em>DaemonSet</em> 确保全部（或者某些）节点上运行一个 Pod 的副本。 当有节点加入集群时， 也会为他们新增一个 Pod 。 当有节点从集群移除时，这些 Pod 也会被回收。删除 DaemonSet 将会删除它创建的所有 Pod。</p><p>DaemonSet 的一些典型用法：</p><ul><li>在<strong>每个节点</strong>上运行集群守护进程</li><li>在<strong>每个节点</strong>上运行日志收集守护进程</li><li>在<strong>每个节点</strong>上运行监控守护进程</li></ul><p>一种简单的用法是为<strong>每种类型的守护进程在所有的节点上</strong>都启动一个 DaemonSet。 一个稍微复杂的用法是为同一种守护进程部署多个 DaemonSet；每个具有不同的标志， 并且对不同硬件类型具有不同的内存、CPU 要求。</p><h2 id="编写-DaemonSet-Spec"><a href="#编写-DaemonSet-Spec" class="headerlink" title="编写 DaemonSet Spec"></a>编写 DaemonSet Spec</h2><h3 id="创建-DaemonSet"><a href="#创建-DaemonSet" class="headerlink" title="创建 DaemonSet"></a>创建 DaemonSet</h3><p>你可以在 YAML 文件中描述 DaemonSet。 例如，下面的 daemonset.yaml 文件描述了一个运行 fluentd-elasticsearch Docker 镜像的 DaemonSet (controllers/daemonset.yaml)：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">DaemonSet</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">fluentd-elasticsearch</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">kube-system</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">k8s-app:</span> <span class="string">fluentd-logging</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">name:</span> <span class="string">fluentd-elasticsearch</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">name:</span> <span class="string">fluentd-elasticsearch</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">tolerations:</span></span><br><span class="line">      <span class="comment"># this toleration is to have the daemonset runnable on master nodes</span></span><br><span class="line">      <span class="comment"># remove it if your masters can&#x27;t run pods</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">node-role.kubernetes.io/master</span></span><br><span class="line">        <span class="attr">operator:</span> <span class="string">Exists</span></span><br><span class="line">        <span class="attr">effect:</span> <span class="string">NoSchedule</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">fluentd-elasticsearch</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">quay.io/fluentd_elasticsearch/fluentd:v2.5.2</span></span><br><span class="line">        <span class="attr">resources:</span></span><br><span class="line">          <span class="attr">limits:</span></span><br><span class="line">            <span class="attr">memory:</span> <span class="string">200Mi</span></span><br><span class="line">          <span class="attr">requests:</span></span><br><span class="line">            <span class="attr">cpu:</span> <span class="string">100m</span></span><br><span class="line">            <span class="attr">memory:</span> <span class="string">200Mi</span></span><br><span class="line">        <span class="attr">volumeMounts:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">varlog</span></span><br><span class="line">          <span class="attr">mountPath:</span> <span class="string">/var/log</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">varlibdockercontainers</span></span><br><span class="line">          <span class="attr">mountPath:</span> <span class="string">/var/lib/docker/containers</span></span><br><span class="line">          <span class="attr">readOnly:</span> <span class="literal">true</span></span><br><span class="line">      <span class="attr">terminationGracePeriodSeconds:</span> <span class="number">30</span></span><br><span class="line">      <span class="attr">volumes:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">varlog</span></span><br><span class="line">        <span class="attr">hostPath:</span></span><br><span class="line">          <span class="attr">path:</span> <span class="string">/var/log</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">varlibdockercontainers</span></span><br><span class="line">        <span class="attr">hostPath:</span></span><br><span class="line">          <span class="attr">path:</span> <span class="string">/var/lib/docker/containers</span></span><br></pre></td></tr></table></figure><p>基于 YAML 文件创建 DaemonSet：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f https://k8s.io/examples/controllers/daemonset.yaml</span><br></pre></td></tr></table></figure><h3 id="必需字段"><a href="#必需字段" class="headerlink" title="必需字段"></a>必需字段</h3><p>和所有其他 Kubernetes 配置一样，DaemonSet 需要 <code>apiVersion</code>、<code>kind</code> 和 <code>metadata</code> 字段。 有关配置文件的基本信息，参见 <a href="https://kubernetes.io/zh/docs/tasks/run-application/run-stateless-application-deployment/">部署应用</a>、 <a href="https://kubernetes.io/zh/docs/tasks/">配置容器</a>和 <a href="https://kubernetes.io/zh/docs/concepts/overview/working-with-objects/object-management/">使用 kubectl 进行对象管理</a> 文档。</p><p>DaemonSet 对象的名称必须是一个合法的 <a href="https://kubernetes.io/zh/docs/concepts/overview/working-with-objects/names#dns-subdomain-names">DNS 子域名</a>。</p><p>DaemonSet 也需要一个 <a href="https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#spec-and-status"><code>.spec</code></a> 配置段。</p><h3 id="Pod-模板-1"><a href="#Pod-模板-1" class="headerlink" title="Pod 模板"></a>Pod 模板</h3><p><code>.spec</code> 中唯一必需的字段是 <code>.spec.template</code>。</p><p><code>.spec.template</code> 是一个 <a href="https://kubernetes.io/zh/docs/concepts/workloads/pods/#pod-templates">Pod 模板</a>。 除了它是嵌套的，因而不具有 <code>apiVersion</code> 或 <code>kind</code> 字段之外，它与 <a href="https://kubernetes.io/docs/concepts/workloads/pods/pod-overview/">Pod</a> 具有相同的 schema。</p><p>除了 Pod 必需字段外，在 DaemonSet 中的 Pod 模板必须指定合理的标签（查看 <a href="https://kubernetes.io/zh/docs/concepts/workloads/controllers/daemonset/#pod-selector">Pod 选择算符</a>）。</p><p>在 DaemonSet 中的 Pod 模板必须具有一个值为 <code>Always</code> 的 <a href="https://kubernetes.io/zh/docs/concepts/workloads/pods/pod-lifecycle/#restart-policy"><code>RestartPolicy</code></a>。 当该值未指定时，默认是 <code>Always</code>。</p><h3 id="Pod-选择算符-2"><a href="#Pod-选择算符-2" class="headerlink" title="Pod 选择算符"></a>Pod 选择算符</h3><p><code>.spec.selector</code> 字段表示 Pod 选择算符，它与 <a href="https://kubernetes.io/zh/docs/concepts/workloads/controllers/job/">Job</a> 的 <code>.spec.selector</code> 的作用是相同的。</p><p>从 Kubernetes 1.8 开始，您必须指定与 <code>.spec.template</code> 的标签匹配的 Pod 选择算符。 用户不指定 Pod 选择算符时，该字段不再有默认值。 选择算符的默认值生成结果与 <code>kubectl apply</code> 不兼容。 此外，一旦创建了 DaemonSet，它的 <code>.spec.selector</code> 就不能修改。 修改 Pod 选择算符可能导致 Pod 意外悬浮，并且这对用户来说是费解的。</p><p><code>spec.selector</code> 是一个对象，如下两个字段组成：</p><ul><li><code>matchLabels</code> - 与 <a href="https://kubernetes.io/zh/docs/concepts/workloads/controllers/replicationcontroller/">ReplicationController</a> 的 <code>.spec.selector</code> 的作用相同。</li><li><code>matchExpressions</code> - 允许构建更加复杂的选择器，可以通过指定 key、value 列表以及将 key 和 value 列表关联起来的 operator。</li></ul><p>当上述两个字段都指定时，结果会按逻辑与（AND）操作处理。</p><p>如果指定了 <code>.spec.selector</code>，必须与 <code>.spec.template.metadata.labels</code> 相匹配。 如果与后者不匹配，则 DeamonSet 会被 API 拒绝。</p><h3 id="仅在某些节点上运行-Pod"><a href="#仅在某些节点上运行-Pod" class="headerlink" title="仅在某些节点上运行 Pod"></a>仅在某些节点上运行 Pod</h3><p>如果指定了 <code>.spec.template.spec.nodeSelector</code>，DaemonSet 控制器将在能够与 <a href="https://kubernetes.io/zh/docs/concepts/scheduling-eviction/assign-pod-node/">Node 选择算符</a> 匹配的节点上创建 Pod。 类似这种情况，可以指定 <code>.spec.template.spec.affinity</code>，之后 DaemonSet 控制器 将在能够与<a href="https://kubernetes.io/zh/docs/concepts/scheduling-eviction/assign-pod-node/">节点亲和性</a> 匹配的节点上创建 Pod。 如果根本就没有指定，则 DaemonSet Controller 将在所有节点上创建 Pod。</p><h2 id="Daemon-Pods-是如何被调度的"><a href="#Daemon-Pods-是如何被调度的" class="headerlink" title="Daemon Pods 是如何被调度的"></a>Daemon Pods 是如何被调度的</h2><h3 id="通过默认调度器调度"><a href="#通过默认调度器调度" class="headerlink" title="通过默认调度器调度"></a>通过默认调度器调度</h3><p><strong>FEATURE STATE:</strong> <code>Kubernetes v1.23 [stable]</code></p><p>DaemonSet 确保所有符合条件的节点都运行该 Pod 的一个副本。 通常，运行 Pod 的节点由 Kubernetes 调度器选择。 不过，DaemonSet Pods 由 DaemonSet 控制器创建和调度。这就带来了以下问题：</p><ul><li>Pod 行为的不一致性：正常 Pod 在被创建后等待调度时处于 <code>Pending</code> 状态， DaemonSet Pods 创建后不会处于 <code>Pending</code> 状态下。这使用户感到困惑。</li><li><a href="https://kubernetes.io/zh/docs/concepts/configuration/pod-priority-preemption/">Pod 抢占</a> 由默认调度器处理。启用抢占后，DaemonSet 控制器将在不考虑 Pod 优先级和抢占 的情况下制定调度决策。</li></ul><p><code>ScheduleDaemonSetPods</code> 允许您使用默认调度器而不是 DaemonSet 控制器来调度 DaemonSets， 方法是将 <code>NodeAffinity</code> 条件而不是 <code>.spec.nodeName</code> 条件添加到 DaemonSet Pods。 默认调度器接下来将 Pod 绑定到目标主机。 如果 DaemonSet Pod 的节点亲和性配置已存在，则被替换 （原始的节点亲和性配置在选择目标主机之前被考虑）。 DaemonSet 控制器仅在创建或修改 DaemonSet Pod 时执行这些操作， 并且不会更改 DaemonSet 的 <code>spec.template</code>。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">nodeAffinity:</span></span><br><span class="line">  <span class="attr">requiredDuringSchedulingIgnoredDuringExecution:</span></span><br><span class="line">    <span class="attr">nodeSelectorTerms:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">matchFields:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">metadata.name</span></span><br><span class="line">        <span class="attr">operator:</span> <span class="string">In</span></span><br><span class="line">        <span class="attr">values:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">target-host-name</span></span><br></pre></td></tr></table></figure><p>此外，系统会自动添加 <code>node.kubernetes.io/unschedulable：NoSchedule</code> 容忍度到 DaemonSet Pods。在调度 DaemonSet Pod 时，默认调度器会忽略 <code>unschedulable</code> 节点。</p><h3 id="污点和容忍度"><a href="#污点和容忍度" class="headerlink" title="污点和容忍度"></a>污点和容忍度</h3><p>尽管 Daemon Pods 遵循<a href="https://kubernetes.io/zh/docs/concepts/scheduling-eviction/taint-and-toleration">污点和容忍度</a> 规则，根据相关特性，控制器会自动将以下容忍度添加到 DaemonSet Pod：</p><table><thead><tr><th>容忍度键名</th><th>效果</th><th>版本</th><th>描述</th></tr></thead><tbody><tr><td><code>node.kubernetes.io/not-ready</code></td><td>NoExecute</td><td>1.13+</td><td>当出现类似网络断开的情况导致节点问题时，DaemonSet Pod 不会被逐出。</td></tr><tr><td><code>node.kubernetes.io/unreachable</code></td><td>NoExecute</td><td>1.13+</td><td>当出现类似于网络断开的情况导致节点问题时，DaemonSet Pod 不会被逐出。</td></tr><tr><td><code>node.kubernetes.io/disk-pressure</code></td><td>NoSchedule</td><td>1.8+</td><td>DaemonSet Pod 被默认调度器调度时能够容忍磁盘压力属性。</td></tr><tr><td><code>node.kubernetes.io/memory-pressure</code></td><td>NoSchedule</td><td>1.8+</td><td>DaemonSet Pod 被默认调度器调度时能够容忍内存压力属性。</td></tr><tr><td><code>node.kubernetes.io/unschedulable</code></td><td>NoSchedule</td><td>1.12+</td><td>DaemonSet Pod 能够容忍默认调度器所设置的 <code>unschedulable</code> 属性.</td></tr><tr><td><code>node.kubernetes.io/network-unavailable</code></td><td>NoSchedule</td><td>1.12+</td><td>DaemonSet 在使用宿主网络时，能够容忍默认调度器所设置的 <code>network-unavailable</code> 属性。</td></tr></tbody></table><h2 id="与-Daemon-Pods-通信"><a href="#与-Daemon-Pods-通信" class="headerlink" title="与 Daemon Pods 通信"></a>与 Daemon Pods 通信</h2><p>与 DaemonSet 中的 Pod 进行通信的几种可能模式如下：</p><ul><li><strong>推送（Push）</strong>：配置 DaemonSet 中的 Pod，将更新发送到另一个服务，例如统计数据库。 这些服务没有客户端。</li><li><strong>NodeIP 和已知端口</strong>：DaemonSet 中的 Pod 可以使用 <code>hostPort</code>，从而可以通过节点 IP 访问到 Pod。客户端能通过某种方法获取节点 IP 列表，并且基于此也可以获取到相应的端口。</li><li><strong>DNS</strong>：创建具有相同 Pod 选择算符的 <a href="https://kubernetes.io/zh/docs/concepts/services-networking/service/#headless-services">无头服务</a>， 通过使用 <code>endpoints</code> 资源或从 DNS 中检索到多个 A 记录来发现 DaemonSet。</li><li><strong>Service</strong>：创建具有相同 Pod 选择算符的服务，并使用该服务随机访问到某个节点上的 守护进程（没有办法访问到特定节点）。</li></ul><h2 id="更新-DaemonSet"><a href="#更新-DaemonSet" class="headerlink" title="更新 DaemonSet"></a>更新 DaemonSet</h2><p>如果节点的标签被修改，DaemonSet 将立刻向新匹配上的节点添加 Pod， 同时删除不匹配的节点上的 Pod。</p><p>你可以修改 DaemonSet 创建的 Pod。不过并非 Pod 的所有字段都可更新。 下次当某节点（即使具有相同的名称）被创建时，DaemonSet 控制器还会使用最初的模板。</p><p>您可以删除一个 DaemonSet。如果使用 <code>kubectl</code> 并指定 <code>--cascade=orphan</code> 选项， 则 Pod 将被保留在节点上。接下来如果创建使用相同选择算符的新 DaemonSet， 新的 DaemonSet 会收养已有的 Pod。 如果有 Pod 需要被替换，DaemonSet 会根据其 <code>updateStrategy</code> 来替换。</p><p>你可以对 DaemonSet <a href="https://kubernetes.io/zh/docs/tasks/manage-daemon/update-daemon-set/">执行滚动更新</a>操作。</p><h2 id="DaemonSet-的替代方案"><a href="#DaemonSet-的替代方案" class="headerlink" title="DaemonSet 的替代方案"></a>DaemonSet 的替代方案</h2><h3 id="init-脚本"><a href="#init-脚本" class="headerlink" title="init 脚本"></a>init 脚本</h3><p>直接在节点上启动守护进程（例如使用 <code>init</code>、<code>upstartd</code> 或 <code>systemd</code>）的做法当然是可行的。 不过，基于 DaemonSet 来运行这些进程有如下一些好处：</p><ul><li>像所运行的其他应用一样，DaemonSet 具备为守护进程提供监控和日志管理的能力。</li><li>为守护进程和应用所使用的配置语言和工具（如 Pod 模板、<code>kubectl</code>）是相同的。</li><li>在资源受限的容器中运行守护进程能够增加守护进程和应用容器的隔离性。 然而，这一点也可以通过在容器中运行守护进程但却不在 Pod 中运行之来实现。 例如，直接基于 Docker 启动。</li></ul><h3 id="裸-Pod-1"><a href="#裸-Pod-1" class="headerlink" title="裸 Pod"></a>裸 Pod</h3><p>直接创建 Pod并指定其运行在特定的节点上也是可以的。 然而，DaemonSet 能够替换由于任何原因（例如节点失败、例行节点维护、内核升级） 而被删除或终止的 Pod。 由于这个原因，你应该使用 DaemonSet 而不是单独创建 Pod。</p><h3 id="静态-Pod-1"><a href="#静态-Pod-1" class="headerlink" title="静态 Pod"></a>静态 Pod</h3><p>通过在一个指定的、受 <code>kubelet</code> 监视的目录下编写文件来创建 Pod 也是可行的。 这类 Pod 被称为<a href="https://kubernetes.io/zh/docs/tasks/configure-pod-container/static-pod/">静态 Pod</a>。 不像 DaemonSet，静态 Pod 不受 <code>kubectl</code> 和其它 Kubernetes API 客户端管理。 静态 Pod 不依赖于 API 服务器，这使得它们在启动引导新集群的情况下非常有用。 此外，静态 Pod 在将来可能会被废弃。</p><h3 id="Deployments-1"><a href="#Deployments-1" class="headerlink" title="Deployments"></a>Deployments</h3><p>DaemonSet 与 <a href="https://kubernetes.io/zh/docs/concepts/workloads/controllers/deployment/">Deployments</a> 非常类似， 它们都能创建 Pod，并且 Pod 中的进程都不希望被终止（例如，Web 服务器、存储服务器）。</p><p><strong>建议为无状态的服务使用 Deployments</strong>，比如前端服务。 对这些服务而言，对副本的数量进行扩缩容、平滑升级，比精确控制 Pod 运行在某个主机上要重要得多。 <strong>当需要 Pod 副本总是运行在全部或特定主机上</strong>，并且当该 DaemonSet 提供了节点级别的功能（允许其他 Pod 在该特定节点上正确运行）时， 应该使用 DaemonSet。</p><p>例如，<a href="https://kubernetes.io/zh/docs/concepts/extend-kubernetes/compute-storage-net/network-plugins/">网络插件</a>通常包含一个以 DaemonSet 运行的组件。 这个 DaemonSet 组件确保它所在的节点的集群网络正常工作。</p><h1 id="Jobs"><a href="#Jobs" class="headerlink" title="Jobs"></a>Jobs</h1><p>Job 会创建一个或者多个 Pods，并将继续重试 Pods 的执行，直到指定数量的 Pods 成功终止。 随着 Pods 成功结束，Job 跟踪记录成功完成的 Pods 个数。 当数量达到指定的成功个数阈值时，任务（即 Job）结束。 删除 Job 的操作会清除所创建的全部 Pods。 挂起 Job 的操作会删除 Job 的所有活跃 Pod，直到 Job 被再次恢复执行。</p><p>一种简单的使用场景下，你会创建一个 Job 对象以便以一种可靠的方式运行某 Pod 直到完成。 当第一个 Pod 失败或者被删除（比如因为节点硬件失效或者重启）时，Job 对象会启动一个新的 Pod。</p><p>你也可以使用 Job 以并行的方式运行多个 Pod。</p><h2 id="运行示例-Job"><a href="#运行示例-Job" class="headerlink" title="运行示例 Job"></a>运行示例 Job</h2><p>下面是一个 Job 配置示例。它负责计算 π 到小数点后 2000 位，并将结果打印出来。 此计算大约需要 10 秒钟完成(controllers/job.yaml)。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">batch/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Job</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">pi</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">pi</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">perl</span></span><br><span class="line">        <span class="attr">command:</span> [<span class="string">&quot;perl&quot;</span>,  <span class="string">&quot;-Mbignum=bpi&quot;</span>, <span class="string">&quot;-wle&quot;</span>, <span class="string">&quot;print bpi(2000)&quot;</span>]</span><br><span class="line">      <span class="attr">restartPolicy:</span> <span class="string">Never</span></span><br><span class="line">  <span class="attr">backoffLimit:</span> <span class="number">4</span></span><br></pre></td></tr></table></figure><p>你可以使用下面的命令来运行此示例：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f https://kubernetes.io/examples/controllers/job.yaml</span><br></pre></td></tr></table></figure><p>输出类似于：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">job.batch/pi created</span><br></pre></td></tr></table></figure><p>使用 <code>kubectl</code> 来检查 Job 的状态：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl describe jobs/pi</span><br></pre></td></tr></table></figure><p>输出类似于：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">Name:           pi</span><br><span class="line">Namespace:      default</span><br><span class="line">Selector:       controller-uid=c9948307-e56d-4b5d-8302-ae2d7b7da67c</span><br><span class="line">Labels:         controller-uid=c9948307-e56d-4b5d-8302-ae2d7b7da67c</span><br><span class="line">                job-name=pi</span><br><span class="line">Annotations:    kubectl.kubernetes.io/last-applied-configuration:</span><br><span class="line">                  &#123;&quot;apiVersion&quot;:&quot;batch/v1&quot;,&quot;kind&quot;:&quot;Job&quot;,&quot;metadata&quot;:&#123;&quot;annotations&quot;:&#123;&#125;,&quot;name&quot;:&quot;pi&quot;,&quot;namespace&quot;:&quot;default&quot;&#125;,&quot;spec&quot;:&#123;&quot;backoffLimit&quot;:4,&quot;template&quot;:...</span><br><span class="line">Parallelism:    1</span><br><span class="line">Completions:    1</span><br><span class="line">Start Time:     Mon, 02 Dec 2019 15:20:11 +0200</span><br><span class="line">Completed At:   Mon, 02 Dec 2019 15:21:16 +0200</span><br><span class="line">Duration:       65s</span><br><span class="line">Pods Statuses:  0 Running / 1 Succeeded / 0 Failed</span><br><span class="line">Pod Template:</span><br><span class="line">  Labels:  controller-uid=c9948307-e56d-4b5d-8302-ae2d7b7da67c</span><br><span class="line">           job-name=pi</span><br><span class="line">  Containers:</span><br><span class="line">   pi:</span><br><span class="line">    Image:      perl</span><br><span class="line">    Port:       &lt;none&gt;</span><br><span class="line">    Host Port:  &lt;none&gt;</span><br><span class="line">    Command:</span><br><span class="line">      perl</span><br><span class="line">      -Mbignum=bpi</span><br><span class="line">      -wle</span><br><span class="line">      print bpi(2000)</span><br><span class="line">    Environment:  &lt;none&gt;</span><br><span class="line">    Mounts:       &lt;none&gt;</span><br><span class="line">  Volumes:        &lt;none&gt;</span><br><span class="line">Events:</span><br><span class="line">  Type    Reason            Age   From            Message</span><br><span class="line">  ----    ------            ----  ----            -------</span><br><span class="line">  Normal  SuccessfulCreate  14m   job-controller  Created pod: pi-5rwd7</span><br></pre></td></tr></table></figure><p>要查看 Job 对应的已完成的 Pods，可以执行 <code>kubectl get pods</code>。</p><p>要以机器可读的方式列举隶属于某 Job 的全部 Pods，你可以使用类似下面这条命令：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pods=$(kubectl get pods --selector=job-name=pi --output=jsonpath=&#x27;&#123;.items[*].metadata.name&#125;&#x27;)</span><br><span class="line">echo $pods</span><br></pre></td></tr></table></figure><p>输出类似于：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pi-5rwd7</span><br></pre></td></tr></table></figure><p>这里，选择算符与 Job 的选择算符相同。<code>--output=jsonpath</code> 选项给出了一个表达式， 用来从返回的列表中提取每个 Pod 的 name 字段。</p><p>查看其中一个 Pod 的标准输出：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl logs $pods</span><br></pre></td></tr></table></figure><p>输出类似于：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">3.1415926535897932384626433832795028841971693993751058209749445923078164062862089986280348253421170679821480865132823066470938446095505822317253594081284811174502841027019385211055596446229489549303819644288109756659334461284756482337867831652712019091456485669234603486104543266482133936072602491412737245870066063155881748815209209628292540917153643678925903600113305305488204665213841469519415116094330572703657595919530921861173819326117931051185480744623799627495673518857527248912279381830119491298336733624406566430860213949463952247371907021798609437027705392171762931767523846748184676694051320005681271452635608277857713427577896091736371787214684409012249534301465495853710507922796892589235420199561121290219608640344181598136297747713099605187072113499999983729780499510597317328160963185950244594553469083026425223082533446850352619311881710100031378387528865875332083814206171776691473035982534904287554687311595628638823537875937519577818577805321712268066130019278766111959092164201989380952572010654858632788659361533818279682303019520353018529689957736225994138912497217752834791315155748572424541506959508295331168617278558890750983817546374649393192550604009277016711390098488240128583616035637076601047101819429555961989467678374494482553797747268471040475346462080466842590694912933136770289891521047521620569660240580381501935112533824300355876402474964732639141992726042699227967823547816360093417216412199245863150302861829745557067498385054945885869269956909272107975093029553211653449872027559602364806654991198818347977535663698074265425278625518184175746728909777727938000816470600161452491921732172147723501414419735685481613611573525521334757418494684385233239073941433345477624168625189835694855620992192221842725502542568876717904946016534668049886272327917860857843838279679766814541009538837863609506800642251252051173929848960841284886269456042419652850222106611863067442786220391949450471237137869609563643719172874677646575739624138908658326459958133904780275901</span><br></pre></td></tr></table></figure><h2 id="编写-Job-规约"><a href="#编写-Job-规约" class="headerlink" title="编写 Job 规约"></a>编写 Job 规约</h2><p>与 Kubernetes 中其他资源的配置类似，Job 也需要 <code>apiVersion</code>、<code>kind</code> 和 <code>metadata</code> 字段。 Job 的名字必须是合法的 <a href="https://kubernetes.io/zh/docs/concepts/overview/working-with-objects/names#dns-subdomain-names">DNS 子域名</a>。</p><p>Job 配置还需要一个<a href="https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#spec-and-status"><code>.spec</code> 节</a>。</p><h3 id="Pod-模版-2"><a href="#Pod-模版-2" class="headerlink" title="Pod 模版"></a>Pod 模版</h3><p>Job 的 <code>.spec</code> 中只有 <code>.spec.template</code> 是必需的字段。</p><p>字段 <code>.spec.template</code> 的值是一个 <a href="https://kubernetes.io/zh/docs/concepts/workloads/pods/#pod-templates">Pod 模版</a>。 其定义规范与 <a href="https://kubernetes.io/docs/concepts/workloads/pods/pod-overview/">Pod</a> 完全相同，只是其中不再需要 <code>apiVersion</code> 或 <code>kind</code> 字段。</p><p>除了作为 Pod 所必需的字段之外，Job 中的 Pod 模版必需设置合适的标签 （参见<a href="https://kubernetes.io/zh/docs/concepts/workloads/controllers/job/#pod-selector">Pod 选择算符</a>）和合适的重启策略。</p><p>Job 中 Pod 的 <a href="https://kubernetes.io/zh/docs/concepts/workloads/pods/pod-lifecycle/#restart-policy"><code>RestartPolicy</code></a> 只能设置为 <code>Never</code> 或 <code>OnFailure</code> 之一。</p><h3 id="Pod-选择算符-3"><a href="#Pod-选择算符-3" class="headerlink" title="Pod 选择算符"></a>Pod 选择算符</h3><p>字段 <code>.spec.selector</code> 是可选的。在绝大多数场合，你都不需要为其赋值。 参阅<a href="https://kubernetes.io/zh/docs/concepts/workloads/controllers/job/#specifying-your-own-pod-selector">设置自己的 Pod 选择算符</a>.</p><h3 id="Job-的并行执行"><a href="#Job-的并行执行" class="headerlink" title="Job 的并行执行"></a>Job 的并行执行</h3><p>适合以 Job 形式来运行的任务主要有三种：</p><ol><li>非并行 Job：<ul><li>通常只启动一个 Pod，除非该 Pod 失败。</li><li>当 Pod 成功终止时，立即视 Job 为完成状态。</li></ul></li><li>具有确定完成计数的并行 Job：<ul><li><code>.spec.completions</code> 字段设置为非 0 的正数值。</li><li>Job 用来代表整个任务，当成功的 Pod 个数达到 <code>.spec.completions</code> 时，Job 被视为完成。</li><li>当使用 <code>.spec.completionMode=&quot;Indexed&quot;</code> 时，每个 Pod 都会获得一个不同的 索引值，介于 0 和 <code>.spec.completions-1</code> 之间。</li></ul></li><li>带工作队列的并行 Job：<ul><li>不设置 <code>spec.completions</code>，默认值为 <code>.spec.parallelism</code>。</li><li><strong>多个 Pod 之间必须相互协调</strong>，或者借助外部服务确定每个 Pod 要处理哪个工作条目。 例如，任一 Pod 都可以从工作队列中取走最多 N 个工作条目。</li><li>每个 Pod 都可以独立确定是否其它 Pod 都已完成，进而确定 Job 是否完成。</li><li>当 Job 中 <em>任何</em> Pod 成功终止，不再创建新 Pod。</li><li>一旦至少 1 个 Pod 成功完成，并且所有 Pod 都已终止，即可宣告 Job 成功完成。</li><li>一旦任何 Pod 成功退出，任何其它 Pod 都不应再对此任务执行任何操作或生成任何输出。 所有 Pod 都应启动退出过程。</li></ul></li></ol><p>对于 <em>非并行</em> 的 Job，你可以不设置 <code>spec.completions</code> 和 <code>spec.parallelism</code>。 这两个属性都不设置时，均取默认值 1。</p><p>对于 <em>确定完成计数</em> 类型的 Job，你应该设置 <code>.spec.completions</code> 为所需要的完成个数。 你可以设置 <code>.spec.parallelism</code>，也可以不设置。其默认值为 1。</p><p>对于一个 <em>工作队列</em> Job，你不可以设置 <code>.spec.completions</code>，但要将<code>.spec.parallelism</code> 设置为一个非负整数。</p><p>关于如何利用不同类型的 Job 的更多信息，请参见 <a href="https://kubernetes.io/zh/docs/concepts/workloads/controllers/job/#job-patterns">Job 模式</a>一节。</p><h4 id="控制并行性"><a href="#控制并行性" class="headerlink" title="控制并行性"></a>控制并行性</h4><p>并行性请求（<code>.spec.parallelism</code>）可以设置为任何非负整数。 如果未设置，则默认为 1。 如果设置为 0，则 Job 相当于启动之后便被暂停，直到此值被增加。</p><p>实际并行性（在任意时刻运行状态的 Pods 个数）可能比并行性请求略大或略小， 原因如下：</p><ul><li>对于 <em>确定完成计数</em> Job，实际上并行执行的 Pods 个数不会超出剩余的完成数。 如果 <code>.spec.parallelism</code> 值较高，会被忽略。</li><li>对于 <em>工作队列</em> Job，有任何 Job 成功结束之后，不会有新的 Pod 启动。 不过，剩下的 Pods 允许执行完毕。</li><li>如果 Job <a href="https://kubernetes.io/zh/docs/concepts/architecture/controller/">控制器</a> 没有来得及作出响应，或者</li><li>如果 Job 控制器因为任何原因（例如，缺少 <code>ResourceQuota</code> 或者没有权限）无法创建 Pods。 Pods 个数可能比请求的数目小。</li><li>Job 控制器可能会因为之前同一 Job 中 Pod 失效次数过多而压制新 Pod 的创建。</li><li>当 Pod 处于体面终止进程中，需要一定时间才能停止。</li></ul><h3 id="完成模式"><a href="#完成模式" class="headerlink" title="完成模式"></a>完成模式</h3><p><strong>FEATURE STATE:</strong> <code>Kubernetes v1.22 [beta]</code></p><p>带有 <em>确定完成计数</em> 的 Job，即 <code>.spec.completions</code> 不为 null 的 Job， 都可以在其 <code>.spec.completionMode</code> 中设置完成模式：</p><ul><li><p><code>NonIndexed</code>（默认值）：当成功完成的 Pod 个数达到 <code>.spec.completions</code> 所 设值时认为 Job 已经完成。换言之，每个 Job 完成事件都是独立无关且同质的。 要注意的是，当 <code>.spec.completions</code> 取值为 null 时，Job 被隐式处理为 <code>NonIndexed</code>。</p></li><li><p><code>Indexed</code>：Job 的 Pod 会获得对应的完成索引，取值为 0 到 <code>.spec.completions-1</code>。 该索引可以通过三种方式获取：</p><ul><li>Pod 注解 <code>batch.kubernetes.io/job-completion-index</code>。</li><li>作为 Pod 主机名的一部分，遵循模式 <code>$(job-name)-$(index)</code>。 当你同时使用带索引的 Job（Indexed Job）与 <a href="https://kubernetes.io/zh/docs/concepts/services-networking/service/">服务（Service）</a>， Job 中的 Pods 可以通过 DNS 使用确切的主机名互相寻址。</li><li>对于容器化的任务，在环境变量 <code>JOB_COMPLETION_INDEX</code> 中。</li></ul><p>当每个索引都对应一个完成完成的 Pod 时，Job 被认为是已完成的。 关于如何使用这种模式的更多信息，可参阅 <a href="https://kubernetes.io/zh/docs/tasks/job/indexed-parallel-processing-static/">用带索引的 Job 执行基于静态任务分配的并行处理</a>。 需要注意的是，对同一索引值可能被启动的 Pod 不止一个，尽管这种情况很少发生。 这时，只有一个会被记入完成计数中。</p></li></ul><h2 id="处理-Pod-和容器失效"><a href="#处理-Pod-和容器失效" class="headerlink" title="处理 Pod 和容器失效"></a>处理 Pod 和容器失效</h2><p>Pod 中的容器可能因为多种不同原因失效，例如因为其中的进程退出时返回值非零， 或者容器因为超出内存约束而被杀死等等。 如果发生这类事件，并且 <code>.spec.template.spec.restartPolicy = &quot;OnFailure&quot;</code>， Pod 则继续留在当前节点，但容器会被重新运行。 因此，你的程序需要能够处理在本地被重启的情况，或者要设置 <code>.spec.template.spec.restartPolicy = &quot;Never&quot;</code>。 关于 <code>restartPolicy</code> 的更多信息，可参阅 <a href="https://kubernetes.io/zh/docs/concepts/workloads/pods/pod-lifecycle/#example-states">Pod 生命周期</a>。</p><p>整个 Pod 也可能会失败，且原因各不相同。 例如，当 Pod 启动时，节点失效（被升级、被重启、被删除等）或者其中的容器失败而 <code>.spec.template.spec.restartPolicy = &quot;Never&quot;</code>。 当 Pod 失败时，Job 控制器会启动一个新的 Pod。 这意味着，你的应用需要处理在一个新 Pod 中被重启的情况。 尤其是应用需要处理之前运行所产生的临时文件、锁、不完整的输出等问题。</p><p>注意，即使你将 <code>.spec.parallelism</code> 设置为 1，且将 <code>.spec.completions</code> 设置为 1，并且 <code>.spec.template.spec.restartPolicy</code> 设置为 “Never”，同一程序仍然有可能被启动两次。</p><p>如果你确实将 <code>.spec.parallelism</code> 和 <code>.spec.completions</code> 都设置为比 1 大的值， 那就有可能同时出现多个 Pod 运行的情况。 为此，你的 Pod 也必须能够处理并发性问题。</p><h3 id="Pod-回退失效策略"><a href="#Pod-回退失效策略" class="headerlink" title="Pod 回退失效策略"></a>Pod 回退失效策略</h3><p>在有些情形下，你可能希望 Job 在经历若干次重试之后直接进入失败状态，因为这很 可能意味着遇到了配置错误。 为了实现这点，可以将 <code>.spec.backoffLimit</code> 设置为视 Job 为失败之前的重试次数。 失效回退的限制值默认为 6。 与 Job 相关的失效的 Pod 会被 Job 控制器重建，回退重试时间将会按指数增长 （从 10 秒、20 秒到 40 秒）最多至 6 分钟。 当 Job 的 Pod 被删除时，或者 Pod 成功时没有其它 Pod 处于失败状态，失效回退的次数也会被重置（为 0）。</p><p><strong>说明：</strong> 如果你的 Job 的 <code>restartPolicy</code> 被设置为 “OnFailure”，就要注意运行该 Job 的 Pod 会在 Job 到达失效回退次数上限时自动被终止。 这会使得调试 Job 中可执行文件的工作变得非常棘手。 我们建议在调试 Job 时将 <code>restartPolicy</code> 设置为 “Never”， 或者使用日志系统来确保失效 Jobs 的输出不会意外遗失。</p><h2 id="Job-终止与清理"><a href="#Job-终止与清理" class="headerlink" title="Job 终止与清理"></a>Job 终止与清理</h2><p>Job 完成时不会再创建新的 Pod，不过已有的 Pod <a href="https://kubernetes.io/zh/docs/concepts/workloads/controllers/job/#pod-backoff-failure-policy">通常</a>也不会被删除。 保留这些 Pod 使得你可以查看已完成的 Pod 的日志输出，以便检查错误、警告 或者其它诊断性输出。 Job 完成时 Job 对象也一样被保留下来，这样你就可以查看它的状态。 在查看了 Job 状态之后删除老的 Job 的操作留给了用户自己。 你可以使用 <code>kubectl</code> 来删除 Job（例如，<code>kubectl delete jobs/pi</code> 或者 <code>kubectl delete -f ./job.yaml</code>）。 当使用 <code>kubectl</code> 来删除 Job 时，该 Job 所创建的 Pods 也会被删除。</p><p>默认情况下，Job 会持续运行，除非某个 Pod 失败（<code>restartPolicy=Never</code>） 或者某个容器出错退出（<code>restartPolicy=OnFailure</code>）。 这时，Job 基于前述的 <code>spec.backoffLimit</code> 来决定是否以及如何重试。 一旦重试次数到达 <code>.spec.backoffLimit</code> 所设的上限，Job 会被标记为失败， 其中运行的 Pods 都会被终止。</p><p>终止 Job 的另一种方式是设置一个活跃期限。 你可以为 Job 的 <code>.spec.activeDeadlineSeconds</code> 设置一个秒数值。 该值适用于 Job 的整个生命期，无论 Job 创建了多少个 Pod。 一旦 Job 运行时间达到 <code>activeDeadlineSeconds</code> 秒，其所有运行中的 Pod 都会被终止，并且 Job 的状态更新为 <code>type: Failed</code> 及 <code>reason: DeadlineExceeded</code>。</p><p>注意 Job 的 <code>.spec.activeDeadlineSeconds</code> 优先级高于其 <code>.spec.backoffLimit</code> 设置。 因此，如果一个 Job 正在重试一个或多个失效的 Pod，该 Job 一旦到达 <code>activeDeadlineSeconds</code> 所设的时限即不再部署额外的 Pod，即使其重试次数还未 达到 <code>backoffLimit</code> 所设的限制。</p><p>例如：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">batch/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Job</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">pi-with-timeout</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">backoffLimit:</span> <span class="number">5</span></span><br><span class="line">  <span class="attr">activeDeadlineSeconds:</span> <span class="number">100</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">pi</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">perl</span></span><br><span class="line">        <span class="attr">command:</span> [<span class="string">&quot;perl&quot;</span>,  <span class="string">&quot;-Mbignum=bpi&quot;</span>, <span class="string">&quot;-wle&quot;</span>, <span class="string">&quot;print bpi(2000)&quot;</span>]</span><br><span class="line">      <span class="attr">restartPolicy:</span> <span class="string">Never</span></span><br></pre></td></tr></table></figure><p>注意 Job 规约和 Job 中的 <a href="https://kubernetes.io/zh/docs/concepts/workloads/pods/init-containers/#detailed-behavior">Pod 模版规约</a> 都有 <code>activeDeadlineSeconds</code> 字段。 请确保你在合适的层次设置正确的字段。</p><p>还要注意的是，<code>restartPolicy</code> 对应的是 Pod，而不是 Job 本身： 一旦 Job 状态变为 <code>type: Failed</code>，就不会再发生 Job 重启的动作。 换言之，由 <code>.spec.activeDeadlineSeconds</code> 和 <code>.spec.backoffLimit</code> 所触发的 Job 终结机制 都会导致 Job 永久性的失败，而这类状态都需要手工干预才能解决。</p><h2 id="自动清理完成的-Job"><a href="#自动清理完成的-Job" class="headerlink" title="自动清理完成的 Job"></a>自动清理完成的 Job</h2><p>完成的 Job 通常不需要留存在系统中。在系统中一直保留它们会给 API 服务器带来额外的压力。 如果 Job 由某种更高级别的控制器来管理，例如 <a href="https://kubernetes.io/zh/docs/concepts/workloads/controllers/cron-jobs/">CronJobs</a>， 则 Job 可以被 CronJob 基于特定的根据容量裁定的清理策略清理掉。</p><h3 id="已完成-Job-的-TTL-机制"><a href="#已完成-Job-的-TTL-机制" class="headerlink" title="已完成 Job 的 TTL 机制"></a>已完成 Job 的 TTL 机制</h3><p><strong>FEATURE STATE:</strong> <code>Kubernetes v1.21 [beta]</code></p><p>自动清理已完成 Job （状态为 <code>Complete</code> 或 <code>Failed</code>）的另一种方式是使用由 <a href="https://kubernetes.io/zh/docs/concepts/workloads/controllers/ttlafterfinished/">TTL 控制器</a>所提供 的 TTL 机制。 通过设置 Job 的 <code>.spec.ttlSecondsAfterFinished</code> 字段，可以让该控制器清理掉 已结束的资源。</p><p>TTL 控制器清理 Job 时，会级联式地删除 Job 对象。 换言之，它会删除所有依赖的对象，包括 Pod 及 Job 本身。 注意，当 Job 被删除时，系统会考虑其生命周期保障，例如其 Finalizers。</p><p>例如：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">batch/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Job</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">pi-with-ttl</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">ttlSecondsAfterFinished:</span> <span class="number">100</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">pi</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">perl</span></span><br><span class="line">        <span class="attr">command:</span> [<span class="string">&quot;perl&quot;</span>,  <span class="string">&quot;-Mbignum=bpi&quot;</span>, <span class="string">&quot;-wle&quot;</span>, <span class="string">&quot;print bpi(2000)&quot;</span>]</span><br><span class="line">      <span class="attr">restartPolicy:</span> <span class="string">Never</span></span><br></pre></td></tr></table></figure><p>Job <code>pi-with-ttl</code> 在结束 100 秒之后，可以成为被自动删除的对象。</p><p>如果该字段设置为 <code>0</code>，Job 在结束之后立即成为可被自动删除的对象。 如果该字段没有设置，Job 不会在结束之后被 TTL 控制器自动清除。</p><h2 id="Job-模式"><a href="#Job-模式" class="headerlink" title="Job 模式"></a>Job 模式</h2><p>Job 对象可以用来支持多个 Pod 的可靠的并发执行。 Job 对象不是设计用来支持相互通信的并行进程的，后者一般在科学计算中应用较多。 Job 的确能够支持对一组相互独立而又有所关联的 <em>工作条目</em> 的并行处理。 这类工作条目可能是要发送的电子邮件、要渲染的视频帧、要编解码的文件、NoSQL 数据库中要扫描的主键范围等等。</p><p>在一个复杂系统中，可能存在多个不同的工作条目集合。这里我们仅考虑用户希望一起管理的 工作条目集合之一 — <em>批处理作业</em>。</p><p>并行计算的模式有好多种，每种都有自己的强项和弱点。这里要权衡的因素有：</p><ul><li>每个工作条目对应一个 Job 或者所有工作条目对应同一 Job 对象。 后者更适合处理大量工作条目的场景； 前者会给用户带来一些额外的负担，而且需要系统管理大量的 Job 对象。</li><li>创建与工作条目相等的 Pod 或者令每个 Pod 可以处理多个工作条目。 前者通常不需要对现有代码和容器做较大改动； 后者则更适合工作条目数量较大的场合，原因同上。</li><li>有几种技术都会用到工作队列。这意味着需要运行一个队列服务，并修改现有程序或容器 使之能够利用该工作队列。 与之比较，其他方案在修改现有容器化应用以适应需求方面可能更容易一些。</li></ul><p>下面是对这些权衡的汇总，列 2 到 4 对应上面的权衡比较。 模式的名称对应了相关示例和更详细描述的链接。</p><table><thead><tr><th>模式</th><th align="center">单个 Job 对象</th><th align="center">Pods 数少于工作条目数？</th><th align="center">直接使用应用无需修改?</th></tr></thead><tbody><tr><td><a href="https://kubernetes.io/zh/docs/tasks/job/coarse-parallel-processing-work-queue/">每工作条目一 Pod 的队列</a></td><td align="center">✓</td><td align="center"></td><td align="center">有时</td></tr><tr><td><a href="https://kubernetes.io/zh/docs/tasks/job/fine-parallel-processing-work-queue/">Pod 数量可变的队列</a></td><td align="center">✓</td><td align="center">✓</td><td align="center"></td></tr><tr><td><a href="https://kubernetes.io/zh/docs/tasks/job/indexed-parallel-processing-static">静态任务分派的带索引的 Job</a></td><td align="center">✓</td><td align="center"></td><td align="center">✓</td></tr><tr><td><a href="https://kubernetes.io/zh/docs/tasks/job/parallel-processing-expansion/">Job 模版扩展</a></td><td align="center"></td><td align="center"></td><td align="center">✓</td></tr></tbody></table><p>当你使用 <code>.spec.completions</code> 来设置完成数时，Job 控制器所创建的每个 Pod 使用完全相同的 <a href="https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#spec-and-status"><code>spec</code></a>。 这意味着任务的所有 Pod 都有相同的命令行，都使用相同的镜像和数据卷，甚至连 环境变量都（几乎）相同。 这些模式是让每个 Pod 执行不同工作的几种不同形式。</p><p>下表显示的是每种模式下 <code>.spec.parallelism</code> 和 <code>.spec.completions</code> 所需要的设置。 其中，<code>W</code> 表示的是工作条目的个数。</p><table><thead><tr><th>模式</th><th align="center"><code>.spec.completions</code></th><th align="center"><code>.spec.parallelism</code></th></tr></thead><tbody><tr><td><a href="https://kubernetes.io/zh/docs/tasks/job/coarse-parallel-processing-work-queue/">每工作条目一 Pod 的队列</a></td><td align="center">W</td><td align="center">任意值</td></tr><tr><td><a href="https://kubernetes.io/zh/docs/tasks/job/fine-parallel-processing-work-queue/">Pod 个数可变的队列</a></td><td align="center">1</td><td align="center">任意值</td></tr><tr><td><a href="https://kubernetes.io/zh/docs/tasks/job/indexed-parallel-processing-static">静态任务分派的带索引的 Job</a></td><td align="center">W</td><td align="center"></td></tr><tr><td><a href="https://kubernetes.io/zh/docs/tasks/job/parallel-processing-expansion/">Job 模版扩展</a></td><td align="center">1</td><td align="center">应该为 1</td></tr></tbody></table><h2 id="高级用法"><a href="#高级用法" class="headerlink" title="高级用法"></a>高级用法</h2><h3 id="挂起-Job"><a href="#挂起-Job" class="headerlink" title="挂起 Job"></a>挂起 Job</h3><p><strong>FEATURE STATE:</strong> <code>Kubernetes v1.21 [alpha]</code></p><p><strong>说明：</strong></p><p>该特性在 Kubernetes 1.21 版本中是 Alpha 阶段，启用该特性需要额外的步骤； 请确保你正在阅读<a href="https://kubernetes.io/zh/docs/home/supported-doc-versions/">与集群版本一致的文档</a>。</p><p>Job 被创建时，Job 控制器会马上开始执行 Pod 创建操作以满足 Job 的需求， 并持续执行此操作直到 Job 完成为止。 不过你可能想要暂时挂起 Job 执行，之后再恢复其执行。 要挂起一个 Job，你可以将 Job 的 <code>.spec.suspend</code> 字段更新为 true。 之后，当你希望恢复其执行时，将其更新为 false。 创建一个 <code>.spec.suspend</code> 被设置为 true 的 Job 本质上会将其创建为被挂起状态。</p><p>当 Job 被从挂起状态恢复执行时，其 <code>.status.startTime</code> 字段会被重置为 当前的时间。这意味着 <code>.spec.activeDeadlineSeconds</code> 计时器会在 Job 挂起时 被停止，并在 Job 恢复执行时复位。</p><p>要记住的是，挂起 Job 会删除其所有活跃的 Pod。当 Job 被挂起时，你的 Pod 会 收到 SIGTERM 信号而被<a href="https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/#pod-termination">终止</a>。 Pod 的体面终止期限会被考虑，不过 Pod 自身也必须在此期限之内处理完信号。 处理逻辑可能包括保存进度以便将来恢复，或者取消已经做出的变更等等。 Pod 以这种形式终止时，不会被记入 Job 的 <code>completions</code> 计数。</p><p>处于被挂起状态的 Job 的定义示例可能是这样子：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">kubectl get job myjob -o yaml</span><br><span class="line">apiVersion: batch/v1</span><br><span class="line">kind: Job</span><br><span class="line">metadata:</span><br><span class="line">  name: myjob</span><br><span class="line">spec:</span><br><span class="line">  suspend: true</span><br><span class="line">  parallelism: 1</span><br><span class="line">  completions: 5</span><br><span class="line">  template:</span><br><span class="line">    spec:</span><br><span class="line">      ...</span><br></pre></td></tr></table></figure><p>Job 的 <code>status</code> 可以用来确定 Job 是否被挂起，或者曾经被挂起。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">kubectl get jobs/myjob -o yaml</span><br><span class="line">apiVersion: batch/v1</span><br><span class="line">kind: Job</span><br><span class="line"><span class="meta">#</span><span class="bash"> .metadata and .spec omitted</span></span><br><span class="line">status:</span><br><span class="line">  conditions:</span><br><span class="line">  - lastProbeTime: &quot;2021-02-05T13:14:33Z&quot;</span><br><span class="line">    lastTransitionTime: &quot;2021-02-05T13:14:33Z&quot;</span><br><span class="line">    status: &quot;True&quot;</span><br><span class="line">    type: Suspended</span><br><span class="line">  startTime: &quot;2021-02-05T13:13:48Z&quot;</span><br></pre></td></tr></table></figure><p>Job 的 “Suspended” 类型的状况在状态值为 “True” 时意味着 Job 正被 挂起；<code>lastTransitionTime</code> 字段可被用来确定 Job 被挂起的时长。 如果此状况字段的取值为 “False”，则 Job 之前被挂起且现在在运行。 如果 “Suspended” 状况在 <code>status</code> 字段中不存在，则意味着 Job 从未 被停止执行。</p><p>当 Job 被挂起和恢复执行时，也会生成事件：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">kubectl describe jobs/myjob</span><br><span class="line">Name:           myjob</span><br><span class="line">...</span><br><span class="line">Events:</span><br><span class="line">  Type    Reason            Age   From            Message</span><br><span class="line">  ----    ------            ----  ----            -------</span><br><span class="line">  Normal  SuccessfulCreate  12m   job-controller  Created pod: myjob-hlrpl</span><br><span class="line">  Normal  SuccessfulDelete  11m   job-controller  Deleted pod: myjob-hlrpl</span><br><span class="line">  Normal  Suspended         11m   job-controller  Job suspended</span><br><span class="line">  Normal  SuccessfulCreate  3s    job-controller  Created pod: myjob-jvb44</span><br><span class="line">  Normal  Resumed           3s    job-controller  Job resumed</span><br></pre></td></tr></table></figure><p>最后四个事件，特别是 “Suspended” 和 “Resumed” 事件，都是因为 <code>.spec.suspend</code> 字段值被改来改去造成的。在这两个事件之间，我们看到没有 Pod 被创建，不过当 Job 被恢复执行时，Pod 创建操作立即被重启执行。</p><h3 id="指定你自己的-Pod-选择算符"><a href="#指定你自己的-Pod-选择算符" class="headerlink" title="指定你自己的 Pod 选择算符"></a>指定你自己的 Pod 选择算符</h3><p>通常，当你创建一个 Job 对象时，你不会设置 <code>.spec.selector</code>。 系统的默认值填充逻辑会在创建 Job 时添加此字段。 它会选择一个不会与任何其他 Job 重叠的选择算符设置。</p><p>不过，有些场合下，你可能需要重载这个自动设置的选择算符。 为了实现这点，你可以手动设置 Job 的 <code>spec.selector</code> 字段。</p><p>做这个操作时请务必小心。 如果你所设定的标签选择算符并不唯一针对 Job 对应的 Pod 集合，甚或该算符还能匹配 其他无关的 Pod，这些无关的 Job 的 Pod 可能会被删除。 或者当前 Job 会将另外一些 Pod 当作是完成自身工作的 Pods， 又或者两个 Job 之一或者二者同时都拒绝创建 Pod，无法运行至完成状态。 如果所设置的算符不具有唯一性，其他控制器（如 RC 副本控制器）及其所管理的 Pod 集合可能会变得行为不可预测。 Kubernetes 不会在你设置 <code>.spec.selector</code> 时尝试阻止你犯这类错误。</p><p>下面是一个示例场景，在这种场景下你可能会使用刚刚讲述的特性。</p><p>假定名为 <code>old</code> 的 Job 已经处于运行状态。 你希望已有的 Pod 继续运行，但你希望 Job 接下来要创建的其他 Pod 使用一个不同的 Pod 模版，甚至希望 Job 的名字也发生变化。 你无法更新现有的 Job，因为这些字段都是不可更新的。 因此，你会删除 <code>old</code> Job，但 <em>允许该 Job 的 Pod 集合继续运行</em>。 这是通过 <code>kubectl delete jobs/old --cascade=orphan</code> 实现的。 在删除之前，我们先记下该 Job 所使用的选择算符。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl get job old -o yaml</span><br></pre></td></tr></table></figure><p>输出类似于：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">kind:</span> <span class="string">Job</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">old</span></span><br><span class="line">  <span class="string">...</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">controller-uid:</span> <span class="string">a8f3d00d-c6d2-11e5-9f87-42010af00002</span></span><br><span class="line">  <span class="string">...</span></span><br></pre></td></tr></table></figure><p>接下来你会创建名为 <code>new</code> 的新 Job，并显式地为其设置相同的选择算符。 由于现有 Pod 都具有标签 <code>controller-uid=a8f3d00d-c6d2-11e5-9f87-42010af00002</code>， 它们也会被名为 <code>new</code> 的 Job 所控制。</p><p>你需要在新 Job 中设置 <code>manualSelector: true</code>，因为你并未使用系统通常自动为你 生成的选择算符。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">kind:</span> <span class="string">Job</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">new</span></span><br><span class="line">  <span class="string">...</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">manualSelector:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">controller-uid:</span> <span class="string">a8f3d00d-c6d2-11e5-9f87-42010af00002</span></span><br><span class="line">  <span class="string">...</span></span><br></pre></td></tr></table></figure><p>新的 Job 自身会有一个不同于 <code>a8f3d00d-c6d2-11e5-9f87-42010af00002</code> 的唯一 ID。 设置 <code>manualSelector: true</code> 是在告诉系统你知道自己在干什么并要求系统允许这种不匹配 的存在。</p><h3 id="使用-Finalizer-追踪-Job"><a href="#使用-Finalizer-追踪-Job" class="headerlink" title="使用 Finalizer 追踪 Job"></a>使用 Finalizer 追踪 Job</h3><p><strong>FEATURE STATE:</strong> <code>Kubernetes v1.22 [alpha]</code></p><p><strong>说明：</strong></p><p>要使用该行为，你必须为 <a href="https://kubernetes.io/zh/docs/reference/command-line-tools-reference/kube-apiserver/">API 服务器</a> 和<a href="https://kubernetes.io/zh/docs/reference/command-line-tools-reference/kube-controller-manager/">控制器管理器</a> 启用 <code>JobTrackingWithFinalizers</code> <a href="https://kubernetes.io/zh/docs/reference/command-line-tools-reference/feature-gates/">特性门控</a>。 默认是禁用的。</p><p>启用后，控制面基于下述行为追踪新的 Job。现有 Job 不受影响。 作为用户，你会看到的唯一区别是控制面对 Job 完成情况的跟踪更加准确。</p><p>该功能未启用时，Job <a href="https://kubernetes.io/zh/docs/concepts/architecture/controller/">控制器（Controller）</a> 依靠计算集群中存在的 Pod 来跟踪作业状态。 也就是说，维持一个统计 <code>succeeded</code> 和 <code>failed</code> 的 Pod 的计数器。 然而，Pod 可以因为一些原因被移除，包括：</p><ul><li>当一个节点宕机时，垃圾收集器会删除孤立（Orphan）Pod。</li><li>垃圾收集器在某个阈值后删除已完成的 Pod（处于 <code>Succeeded</code> 或 <code>Failed</code> 阶段）。</li><li>人工干预删除 Job 的 Pod。</li><li>一个外部控制器（不包含于 Kubernetes）来删除或取代 Pod。</li></ul><p>如果你为你的集群启用了 <code>JobTrackingWithFinalizers</code> 特性，控制面会跟踪属于任何 Job 的 Pod。 并注意是否有任何这样的 Pod 被从 API 服务器上删除。 为了实现这一点，Job 控制器创建的 Pod 带有 Finalizer <code>batch.kubernetes.io/job-tracking</code>。 控制器只有在 Pod 被记入 Job 状态后才会移除 Finalizer，允许 Pod 可以被其他控制器或用户删除。</p><p>Job 控制器只对新的 Job 使用新的算法。在启用该特性之前创建的 Job 不受影响。 你可以根据检查 Job 是否含有 <code>batch.kubernetes.io/job-tracking</code> 注解，来确定 Job 控制器是否正在使用 Pod Finalizer 追踪 Job。 你<strong>不</strong>应该给 Job 手动添加或删除该注解。</p><h2 id="替代方案"><a href="#替代方案" class="headerlink" title="替代方案"></a>替代方案</h2><h3 id="裸-Pod-2"><a href="#裸-Pod-2" class="headerlink" title="裸 Pod"></a>裸 Pod</h3><p>当 Pod 运行所在的节点重启或者失败，Pod 会被终止并且不会被重启。 Job 会重新创建新的 Pod 来替代已终止的 Pod。 因为这个原因，我们建议你使用 Job 而不是独立的裸 Pod， 即使你的应用仅需要一个 Pod。</p><h3 id="副本控制器"><a href="#副本控制器" class="headerlink" title="副本控制器"></a>副本控制器</h3><p>Job 与<a href="https://kubernetes.io/zh/docs/concepts/workloads/controllers/replicationcontroller/">副本控制器</a>是彼此互补的。 副本控制器管理的是那些不希望被终止的 Pod （例如，Web 服务器）， Job 管理的是那些希望被终止的 Pod（例如，批处理作业）。</p><p>正如在 <a href="https://kubernetes.io/zh/docs/concepts/workloads/pods/pod-lifecycle/">Pod 生命期</a> 中讨论的， <code>Job</code> 仅适合于 <code>restartPolicy</code> 设置为 <code>OnFailure</code> 或 <code>Never</code> 的 Pod。 注意：如果 <code>restartPolicy</code> 未设置，其默认值是 <code>Always</code>。</p><h3 id="单个-Job-启动控制器-Pod"><a href="#单个-Job-启动控制器-Pod" class="headerlink" title="单个 Job 启动控制器 Pod"></a>单个 Job 启动控制器 Pod</h3><p>另一种模式是用唯一的 Job 来创建 Pod，而该 Pod 负责启动其他 Pod，因此扮演了一种 后启动 Pod 的控制器的角色。 这种模式的灵活性更高，但是有时候可能会把事情搞得很复杂，很难入门， 并且与 Kubernetes 的集成度很低。</p><p>这种模式的实例之一是用 Job 来启动一个运行脚本的 Pod，脚本负责启动 Spark 主控制器（参见 <a href="https://github.com/kubernetes/examples/tree/master/staging/spark/README.md">Spark 示例</a>）， 运行 Spark 驱动，之后完成清理工作。</p><p>这种方法的优点之一是整个过程得到了 Job 对象的完成保障， 同时维持了对创建哪些 Pod、如何向其分派工作的完全控制能力，</p><h1 id="已完成资源的-TTL-控制器"><a href="#已完成资源的-TTL-控制器" class="headerlink" title="已完成资源的 TTL 控制器"></a>已完成资源的 TTL 控制器</h1><p><strong>FEATURE STATE:</strong> <code>Kubernetes v1.21 [beta]</code></p><p>TTL 控制器提供了一种 TTL 机制来限制已完成执行的资源对象的生命周期。 TTL 控制器目前只处理 <a href="https://kubernetes.io/zh/docs/concepts/workloads/controllers/job/">Job</a>， 可能以后会扩展以处理将完成执行的其他资源，例如 Pod 和自定义资源。</p><p>此功能目前是 Beta 版而自动启用，并且可以通过 <code>kube-apiserver</code> 和 <code>kube-controller-manager</code> 上的 <a href="https://kubernetes.io/zh/docs/reference/command-line-tools-reference/feature-gates/">特性门控</a> <code>TTLAfterFinished</code> 禁用。</p><h2 id="TTL-控制器"><a href="#TTL-控制器" class="headerlink" title="TTL 控制器"></a>TTL 控制器</h2><p>TTL 控制器现在只支持 Job。集群操作员可以通过指定 Job 的 <code>.spec.ttlSecondsAfterFinished</code> 字段来自动清理已结束的作业（<code>Complete</code> 或 <code>Failed</code>），如 <a href="https://kubernetes.io/zh/docs/concepts/workloads/controllers/job/#clean-up-finished-jobs-automatically">示例</a> 所示。</p><p>TTL 控制器假设资源能在执行完成后的 TTL 秒内被清理，也就是当 TTL 过期后。 当 TTL 控制器清理资源时，它将做级联删除操作，即删除资源对象的同时也删除其依赖对象。 注意，当资源被删除时，由该资源的生命周期保证其终结器（Finalizers）等被执行。</p><p>可以随时设置 TTL 秒。以下是设置 Job 的 <code>.spec.ttlSecondsAfterFinished</code> 字段的一些示例：</p><ul><li>在资源清单（manifest）中指定此字段，以便 Job 在完成后的某个时间被自动清除。</li><li>将此字段设置为现有的、已完成的资源，以采用此新功能。</li><li>在创建资源时使用 <a href="https://kubernetes.io/zh/docs/reference/access-authn-authz/extensible-admission-controllers/#admission-webhooks">mutating admission webhook</a> 动态设置该字段。集群管理员可以使用它对完成的资源强制执行 TTL 策略。</li><li>使用 <a href="https://kubernetes.io/zh/docs/reference/access-authn-authz/extensible-admission-controllers/#admission-webhooks">mutating admission webhook</a> 在资源完成后动态设置该字段，并根据资源状态、标签等选择不同的 TTL 值。</li></ul><h2 id="警告"><a href="#警告" class="headerlink" title="警告"></a>警告</h2><h3 id="更新-TTL-秒"><a href="#更新-TTL-秒" class="headerlink" title="更新 TTL 秒"></a>更新 TTL 秒</h3><p>请注意，在创建资源或已经执行结束后，仍可以修改其 TTL 周期，例如 Job 的 <code>.spec.ttlSecondsAfterFinished</code> 字段。 但是一旦 Job 变为可被删除状态（当其 TTL 已过期时），即使您通过 API 增加其 TTL 时长得到了成功的响应，系统也不保证 Job 将被保留。</p><h3 id="时间偏差"><a href="#时间偏差" class="headerlink" title="时间偏差"></a>时间偏差</h3><p>由于 TTL 控制器使用存储在 Kubernetes 资源中的时间戳来确定 TTL 是否已过期， 因此该功能对集群中的时间偏差很敏感，这可能导致 TTL 控制器在错误的时间清理资源对象。</p><p>在 Kubernetes 中，需要在所有节点上运行 NTP（参见 <a href="https://github.com/kubernetes/kubernetes/issues/6159#issuecomment-93844058">#6159</a>） 以避免时间偏差。时钟并不总是如此正确，但差异应该很小。 设置非零 TTL 时请注意避免这种风险。</p><h1 id="CronJob"><a href="#CronJob" class="headerlink" title="CronJob"></a>CronJob</h1><p><strong>FEATURE STATE:</strong> <code>Kubernetes v1.21 [stable]</code></p><p><em>CronJob</em> 创建基于时隔重复调度的 <a href="https://kubernetes.io/zh/docs/concepts/workloads/controllers/job/">Jobs</a>。</p><p>一个 CronJob 对象就像 <em>crontab</em> (cron table) 文件中的一行。 它用 <a href="https://en.wikipedia.org/wiki/Cron">Cron</a> 格式进行编写， 并周期性地在给定的调度时间执行 Job。</p><blockquote><p><strong>注意：</strong></p><p>所有 <strong>CronJob</strong> 的 <code>schedule:</code> 时间都是基于 <a href="https://kubernetes.io/docs/reference/generated/kube-controller-manager/">kube-controller-manager</a>. 的时区。</p><p>如果你的控制平面在 Pod 或是裸容器中运行了 kube-controller-manager， 那么为该容器所设置的时区将会决定 Cron Job 的控制器所使用的时区。</p></blockquote><blockquote><p><strong>注意：</strong></p><p>如 <a href="https://kubernetes.io/zh/docs/reference/kubernetes-api/workload-resources/cron-job-v1/">v1 CronJob API</a> 所述，官方并不支持设置时区。</p><p>Kubernetes 项目官方并不支持设置如 <code>CRON_TZ</code> 或者 <code>TZ</code> 等变量。 <code>CRON_TZ</code> 或者 <code>TZ</code> 是用于解析和计算下一个 Job 创建时间所使用的内部库中一个实现细节。 不建议在生产集群中使用它。</p><p>为 CronJob 资源创建清单时，请确保所提供的名称是一个合法的 <a href="https://kubernetes.io/zh/docs/concepts/overview/working-with-objects/names#dns-subdomain-names">DNS 子域名</a>. 名称不能超过 52 个字符。 这是因为 CronJob 控制器将自动在提供的 Job 名称后附加 11 个字符，并且存在一个限制， 即 Job 名称的最大长度不能超过 63 个字符。</p></blockquote><h2 id="CronJob-1"><a href="#CronJob-1" class="headerlink" title="CronJob"></a>CronJob</h2><p>CronJob 用于执行周期性的动作，例如备份、报告生成等。 这些任务中的每一个都应该配置为周期性重复的（例如：每天/每周/每月一次）； 你可以定义任务开始执行的时间间隔。</p><h3 id="示例-1"><a href="#示例-1" class="headerlink" title="示例"></a>示例</h3><p>下面的 CronJob 示例清单会在每分钟打印出当前时间和问候消息(application/job/cronjob.yaml)：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">batch/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">CronJob</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">hello</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">schedule:</span> <span class="string">&quot;*/1 * * * *&quot;</span></span><br><span class="line">  <span class="attr">jobTemplate:</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">template:</span></span><br><span class="line">        <span class="attr">spec:</span></span><br><span class="line">          <span class="attr">containers:</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">hello</span></span><br><span class="line">            <span class="attr">image:</span> <span class="string">busybox</span></span><br><span class="line">            <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span></span><br><span class="line">            <span class="attr">command:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="string">/bin/sh</span></span><br><span class="line">            <span class="bullet">-</span> <span class="string">-c</span></span><br><span class="line">            <span class="bullet">-</span> <span class="string">date;</span> <span class="string">echo</span> <span class="string">Hello</span> <span class="string">from</span> <span class="string">the</span> <span class="string">Kubernetes</span> <span class="string">cluster</span></span><br><span class="line">          <span class="attr">restartPolicy:</span> <span class="string">OnFailure</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p><a href="https://kubernetes.io/zh/docs/tasks/job/automated-tasks-with-cron-jobs/">使用 CronJob 运行自动化任务</a> 一文会为你详细讲解此例。</p><h3 id="Cron-时间表语法"><a href="#Cron-时间表语法" class="headerlink" title="Cron 时间表语法"></a>Cron 时间表语法</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"># ┌───────────── 分钟 (0 - 59)</span><br><span class="line"># │ ┌───────────── 小时 (0 - 23)</span><br><span class="line"># │ │ ┌───────────── 月的某天 (1 - 31)</span><br><span class="line"># │ │ │ ┌───────────── 月份 (1 - 12)</span><br><span class="line"># │ │ │ │ ┌───────────── 周的某天 (0 - 6)（周日到周一；在某些系统上，7 也是星期日）</span><br><span class="line"># │ │ │ │ │</span><br><span class="line"># │ │ │ │ │</span><br><span class="line"># │ │ │ │ │</span><br><span class="line"># * * * * *</span><br><span class="line"># ┌───────────── 分钟 (0 - 59)</span><br><span class="line"># │ ┌───────────── 小时 (0 - 23)</span><br><span class="line"># │ │ ┌───────────── 月的某天 (1 - 31)</span><br><span class="line"># │ │ │ ┌───────────── 月份 (1 - 12)</span><br><span class="line"># │ │ │ │ ┌───────────── 周的某天 (0 - 6) （周日到周一；在某些系统上，7 也是星期日）</span><br><span class="line"># │ │ │ │ │</span><br><span class="line"># │ │ │ │ │</span><br><span class="line"># │ │ │ │ │</span><br><span class="line"># * * * * *</span><br></pre></td></tr></table></figure><table><thead><tr><th>输入</th><th>描述</th><th>相当于</th></tr></thead><tbody><tr><td>@yearly (or @annually)</td><td>每年 1 月 1 日的午夜运行一次</td><td>0 0 1 1 *</td></tr><tr><td>@monthly</td><td>每月第一天的午夜运行一次</td><td>0 0 1 * *</td></tr><tr><td>@weekly</td><td>每周的周日午夜运行一次</td><td>0 0 * * 0</td></tr><tr><td>@daily (or @midnight)</td><td>每天午夜运行一次</td><td>0 0 * * *</td></tr><tr><td>@hourly</td><td>每小时的开始一次</td><td>0 * * * *</td></tr></tbody></table><p>例如，下面这行指出必须在每个星期五的午夜以及每个月 13 号的午夜开始任务：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">0 0 13 * 5</span><br></pre></td></tr></table></figure><p>要生成 CronJob 时间表表达式，你还可以使用 <a href="https://crontab.guru/">crontab.guru</a> 之类的 Web 工具。</p><h2 id="CronJob-限制"><a href="#CronJob-限制" class="headerlink" title="CronJob 限制"></a>CronJob 限制</h2><p>CronJob 根据其计划编排，在每次该执行任务的时候大约会创建一个 Job。 我们之所以说 “大约”，是因为在某些情况下，可能会创建两个 Job，或者不会创建任何 Job。 我们试图使这些情况尽量少发生，但不能完全杜绝。因此，Job 应该是 <em>幂等的</em>。</p><p>如果 <code>startingDeadlineSeconds</code> 设置为很大的数值或未设置（默认），并且 <code>concurrencyPolicy</code> 设置为 <code>Allow</code>，则作业将始终至少运行一次。</p><blockquote><p><strong>注意：</strong>如果 <code>startingDeadlineSeconds</code> 的设置值低于 10 秒钟，CronJob 可能无法被调度。 这是因为 CronJob 控制器每 10 秒钟执行一次检查。</p></blockquote><p>对于每个 CronJob，CronJob <a href="https://kubernetes.io/zh/docs/concepts/architecture/controller/">控制器（Controller）</a> 检查从上一次调度的时间点到现在所错过了调度次数。如果错过的调度次数超过 100 次， 那么它就不会启动这个任务，并记录这个错误:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Cannot determine if job needs to be started. Too many missed start time (&gt; 100). Set or decrease .spec.startingDeadlineSeconds or check clock skew.</span><br></pre></td></tr></table></figure><p>需要注意的是，如果 <code>startingDeadlineSeconds</code> 字段非空，则控制器会统计从 <code>startingDeadlineSeconds</code> 设置的值到现在而不是从上一个计划时间到现在错过了多少次 Job。 例如，如果 <code>startingDeadlineSeconds</code> 是 <code>200</code>，则控制器会统计在过去 200 秒中错过了多少次 Job。</p><p>如果未能在调度时间内创建 CronJob，则计为错过。 例如，如果 <code>concurrencyPolicy</code> 被设置为 <code>Forbid</code>，并且当前有一个调度仍在运行的情况下， 试图调度的 CronJob 将被计算为错过。</p><p>例如，假设一个 CronJob 被设置为从 <code>08:30:00</code> 开始每隔一分钟创建一个新的 Job， 并且它的 <code>startingDeadlineSeconds</code> 字段未被设置。如果 CronJob 控制器从 <code>08:29:00</code> 到 <code>10:21:00</code> 终止运行，则该 Job 将不会启动，因为其错过的调度 次数超过了 100。</p><p>为了进一步阐述这个概念，假设将 CronJob 设置为从 <code>08:30:00</code> 开始每隔一分钟创建一个新的 Job， 并将其 <code>startingDeadlineSeconds</code> 字段设置为 200 秒。 如果 CronJob 控制器恰好在与上一个示例相同的时间段（<code>08:29:00</code> 到 <code>10:21:00</code>）终止运行， 则 Job 仍将从 <code>10:22:00</code> 开始。 造成这种情况的原因是控制器现在检查在最近 200 秒（即 3 个错过的调度）中发生了多少次错过的 Job 调度，而不是从现在为止的最后一个调度时间开始。</p><p>CronJob 仅负责创建与其调度时间相匹配的 Job，而 Job 又负责管理其代表的 Pod。</p><h2 id="控制器版本"><a href="#控制器版本" class="headerlink" title="控制器版本"></a>控制器版本</h2><p>从 Kubernetes v1.21 版本开始，CronJob 控制器的第二个版本被用作默认实现。 要禁用此默认 CronJob 控制器而使用原来的 CronJob 控制器，请在 <a href="https://kubernetes.io/docs/reference/generated/kube-controller-manager/">kube-controller-manager</a> 中设置<a href="https://kubernetes.io/zh/docs/reference/command-line-tools-reference/feature-gates/">特性门控</a> <code>CronJobControllerV2</code>，将此标志设置为 <code>false</code>。例如：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">--feature-gates=&quot;CronJobControllerV2=false&quot;</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;工作负载&quot;&gt;&lt;a href=&quot;#工作负载&quot; class=&quot;headerlink&quot; title=&quot;工作负载&quot;&gt;&lt;/a&gt;工作负载&lt;/h1&gt;&lt;p&gt;工作负载是在 Kubernetes 上运行的应用程序。&lt;/p&gt;
&lt;p&gt;无论你的负载是单一组件还是由多个一同工作的组件构成，在 Kubernetes 中你 可以在一组 &lt;a href=&quot;https://kubernetes.io/zh/docs/concepts/workloads/pods&quot;&gt;Pods&lt;/a&gt; 中运行它。 在 Kubernetes 中，Pod 代表的是集群上处于运行状态的一组 &lt;a href=&quot;https://kubernetes.io/zh/docs/concepts/overview/what-is-kubernetes/#why-containers&quot;&gt;容器&lt;/a&gt;。&lt;/p&gt;</summary>
    
    
    
    
    <category term="Kubernetes" scheme="http://chengqian90.com/tags/Kubernetes/"/>
    
    <category term="k8s" scheme="http://chengqian90.com/tags/k8s/"/>
    
  </entry>
  
  <entry>
    <title>学习Kubernetes系列3——容器</title>
    <link href="http://chengqian90.com/%E5%AE%B9%E5%99%A8/%E5%AD%A6%E4%B9%A0Kubernetes%E7%B3%BB%E5%88%973%E2%80%94%E2%80%94%E5%AE%B9%E5%99%A8.html"/>
    <id>http://chengqian90.com/%E5%AE%B9%E5%99%A8/%E5%AD%A6%E4%B9%A0Kubernetes%E7%B3%BB%E5%88%973%E2%80%94%E2%80%94%E5%AE%B9%E5%99%A8.html</id>
    <published>2021-06-10T05:20:44.000Z</published>
    <updated>2022-03-08T16:23:40.434Z</updated>
    
    <content type="html"><![CDATA[<h1 id="容器"><a href="#容器" class="headerlink" title="容器"></a>容器</h1><p>每个运行的容器都是可重复的； 包含依赖环境在内的标准，意味着无论您在哪里运行它，您都会得到相同的行为。</p><p>容器将应用程序从底层的主机设施中解耦。 这使得在不同的云或 OS 环境中部署更加容易。</p><span id="more"></span><h1 id="镜像"><a href="#镜像" class="headerlink" title="镜像"></a>镜像</h1><p>容器镜像（Image）所承载的是<strong>封装了应用程序及其所有软件依赖的二进制数据</strong>。 容器镜像是可执行的软件包，可以单独运行；该软件包对所处的运行时环境具有 良定（Well Defined）的假定。</p><p>你通常会创建应用的容器镜像并将其推送到某仓库（Registry），然后在 Pod中引用它。</p><h2 id="镜像名称"><a href="#镜像名称" class="headerlink" title="镜像名称"></a>镜像名称</h2><p>容器镜像通常会被赋予 <code>pause</code>、<code>example/mycontainer</code> 或者 <code>kube-apiserver</code> 这类的名称。 镜像名称也可以包含所在仓库的主机名。例如：<code>fictional.registry.example/imagename</code>。 还可以包含仓库的端口号，例如：<code>fictional.registry.example:10443/imagename</code>。</p><p>如果你不指定仓库的主机名，Kubernetes 认为你在使用 Docker 公共仓库。</p><p>在镜像名称之后，你可以添加一个 <em>标签（Tag）</em> （就像在 <code>docker</code> 或 <code>podman</code> 中也在用的那样）。 使用标签能让你辨识同一镜像序列中的不同版本。</p><p>镜像标签可以包含小写字母、大写字母、数字、下划线（<code>_</code>）、句点（<code>.</code>）和连字符（<code>-</code>）。 关于在镜像标签中何处可以使用分隔字符（<code>_</code>、<code>-</code> 和 <code>.</code>）还有一些额外的规则。 如果你不指定标签，Kubernetes 认为你想使用标签 <code>latest</code>。</p><h2 id="更新镜像"><a href="#更新镜像" class="headerlink" title="更新镜像"></a>更新镜像</h2><p>当你最初创建一个 <a href="https://kubernetes.io/zh/docs/concepts/workloads/controllers/deployment/">Deployment</a>、 <a href="https://kubernetes.io/zh/docs/concepts/workloads/controllers/statefulset/">StatefulSet</a>、Pod 或者其他包含 Pod 模板的对象时，如果没有显式设定的话，Pod 中所有容器的默认镜像 拉取策略是 <code>IfNotPresent</code>。这一策略会使得 <a href="https://kubernetes.io/docs/reference/generated/kubelet">kubelet</a> 在镜像已经存在的情况下直接略过拉取镜像的操作。</p><h3 id="镜像拉取策略"><a href="#镜像拉取策略" class="headerlink" title="镜像拉取策略"></a>镜像拉取策略</h3><p>容器的 <code>imagePullPolicy</code> 和镜像的标签会影响 <a href="https://kubernetes.io/zh/docs/reference/command-line-tools-reference/kubelet/">kubelet</a> 尝试拉取（下载）指定的镜像。</p><p>以下列表包含了 <code>imagePullPolicy</code> 可以设置的值，以及这些值的效果：</p><ul><li><p><code>IfNotPresent</code></p><p>只有当镜像在本地不存在时才会拉取。</p></li><li><p><code>Always</code></p><p>每当 kubelet 启动一个容器时，kubelet 会查询容器的镜像仓库， 将名称解析为一个镜像<a href="https://docs.docker.com/engine/reference/commandline/pull/#pull-an-image-by-digest-immutable-identifier">摘要</a>。 如果 kubelet 有一个容器镜像，并且对应的摘要已在本地缓存，kubelet 就会使用其缓存的镜像； 否则，kubelet 就会使用解析后的摘要拉取镜像，并使用该镜像来启动容器。</p></li><li><p><code>Never</code></p><p>Kubelet 不会尝试获取镜像。如果镜像已经以某种方式存在本地， kubelet 会尝试启动容器；否则，会启动失败。 </p></li></ul><p>只要能够可靠地访问镜像仓库，底层镜像提供者的缓存语义甚至可以使 <code>imagePullPolicy: Always</code> 高效。 你的容器运行时可以注意到节点上已经存在的镜像层，这样就不需要再次下载。</p><blockquote><p>在生产环境中部署容器时，你应该避免使用 <code>:latest</code> 标签，因为这使得正在运行的镜像的版本难以追踪，并且难以正确地回滚。</p><p>相反，应指定一个有意义的标签，如 <code>v1.42.0</code>。</p></blockquote><p>为了确保 Pod 总是使用相同版本的容器镜像，你可以指定镜像的摘要； 将 <code>&lt;image-name&gt;:&lt;tag&gt;</code> 替换为 <code>&lt;image-name&gt;@&lt;digest&gt;</code>，例如 <code>image@sha256:45b23dee08af5e43a7fea6c4cf9c25ccf269ee113168c19722f87876677c5cb2</code>。</p><p>当使用镜像标签时，如果镜像仓库修改了代码所对应的镜像标签，可能会出现新旧代码混杂在 Pod 中运行的情况。 <strong>镜像摘要唯一标识了镜像的特定版本，因此 Kubernetes 每次启动具有指定镜像名称和摘要的容器时，都会运行相同的代码</strong>。 指定一个镜像可以固定你所运行的代码，这样镜像仓库的变化就不会导致版本的混杂。</p><h4 id="默认镜像拉取策略"><a href="#默认镜像拉取策略" class="headerlink" title="默认镜像拉取策略"></a>默认镜像拉取策略</h4><p>当你（或控制器）向 API 服务器提交一个新的 Pod 时，你的集群会在满足特定条件时设置 <code>imagePullPolicy </code>字段：</p><ul><li>如果你省略了 <code>imagePullPolicy</code> 字段，并且容器镜像的标签是 <code>:latest</code>， <code>imagePullPolicy</code> 会自动设置为 <code>Always</code>。</li><li>如果你省略了 <code>imagePullPolicy</code> 字段，并且没有指定容器镜像的标签， <code>imagePullPolicy</code> 会自动设置为 <code>Always</code>。</li><li>如果你省略了 <code>imagePullPolicy</code> 字段，并且为容器镜像指定了非 <code>:latest</code> 的标签， <code>imagePullPolicy</code> 就会自动设置为 <code>IfNotPresent</code>。</li></ul><blockquote><p>容器的 <code>imagePullPolicy</code> 的值总是在对象初次 <em>创建</em> 时设置的，如果后来镜像的标签发生变化，则不会更新。</p><p>例如，如果你用一个 <em>非</em> <code>:latest</code> 的镜像标签创建一个 Deployment， 并在随后更新该 Deployment 的镜像标签为 <code>:latest</code>，则 <code>imagePullPolicy</code> 字段 <em>不会</em> 变成 <code>Always</code>。 你必须手动更改已经创建的资源的拉取策略。</p></blockquote><h4 id="必要的镜像拉取"><a href="#必要的镜像拉取" class="headerlink" title="必要的镜像拉取"></a>必要的镜像拉取</h4><p>如果你想总是强制执行拉取，你可以使用下述的一中方式：</p><ul><li>设置容器的 <code>imagePullPolicy</code> 为 <code>Always</code>。</li><li>省略 <code>imagePullPolicy</code>，并使用 <code>:latest</code> 作为镜像标签； 当你提交 Pod 时，Kubernetes 会将策略设置为 <code>Always</code>。</li><li>省略 <code>imagePullPolicy</code> 和镜像的标签； 当你提交 Pod 时，Kubernetes 会将策略设置为 <code>Always</code>。</li><li>启用准入控制器 <a href="https://kubernetes.io/zh/docs/reference/access-authn-authz/admission-controllers/#alwayspullimages">AlwaysPullImages</a>。</li></ul><h3 id="ImagePullBackOff"><a href="#ImagePullBackOff" class="headerlink" title="ImagePullBackOff"></a>ImagePullBackOff</h3><p>当 kubelet 使用容器运行时创建 Pod 时，容器可能因为 <code>ImagePullBackOff</code> 导致状态为 <a href="https://kubernetes.io/zh/docs/concepts/workloads/pods/pod-lifecycle/#container-state-waiting">Waiting</a>。</p><p><code>ImagePullBackOff</code> 状态意味着容器无法启动， 因为 Kubernetes 无法拉取容器镜像（原因包括无效的镜像名称，或从私有仓库拉取而没有 <code>imagePullSecret</code>）。 <code>BackOff</code> 部分表示 Kubernetes 将继续尝试拉取镜像，并增加回退延迟。</p><p>Kubernetes 会增加每次尝试之间的延迟，直到达到编译限制，即 300 秒（5 分钟）。</p><h2 id="带镜像索引的多架构镜像"><a href="#带镜像索引的多架构镜像" class="headerlink" title="带镜像索引的多架构镜像"></a>带镜像索引的多架构镜像</h2><p>除了提供二进制的镜像之外，容器仓库也可以提供 <a href="https://github.com/opencontainers/image-spec/blob/master/image-index.md">容器镜像索引</a>。 镜像索引可以根据特定于体系结构版本的容器指向镜像的多个 <a href="https://github.com/opencontainers/image-spec/blob/master/manifest.md">镜像清单</a>。 这背后的理念是让你可以为镜像命名（例如：<code>pause</code>、<code>example/mycontainer</code>、<code>kube-apiserver</code>） 的同时，允许不同的系统基于它们所使用的机器体系结构取回正确的二进制镜像。</p><p>Kubernetes 自身通常在命名容器镜像时添加后缀 <code>-$(ARCH)</code>。 为了向前兼容，请在生成较老的镜像时也提供后缀。 这里的理念是为某镜像（如 <code>pause</code>）生成针对所有平台都适用的清单时， 生成 <code>pause-amd64</code> 这类镜像，以便较老的配置文件或者将镜像后缀影编码到其中的 YAML 文件也能兼容。</p><h2 id="使用私有仓库"><a href="#使用私有仓库" class="headerlink" title="使用私有仓库"></a>使用私有仓库</h2><p>从私有仓库读取镜像时可能需要密钥。 凭证可以用以下方式提供:</p><ul><li>配置节点向私有仓库进行身份验证<ul><li>所有 Pod 均可读取任何已配置的私有仓库</li><li>需要集群管理员配置节点</li></ul></li><li>预拉镜像<ul><li>所有 Pod 都可以使用节点上缓存的所有镜像</li><li>需要所有节点的 root 访问权限才能进行设置</li></ul></li><li>在 Pod 中设置 ImagePullSecrets<ul><li>只有提供自己密钥的 Pod 才能访问私有仓库</li></ul></li><li>特定于厂商的扩展或者本地扩展<ul><li>如果你在使用定制的节点配置，你（或者云平台提供商）可以实现让节点 向容器仓库认证的机制</li></ul></li></ul><h3 id="配置-Node-对私有仓库认证"><a href="#配置-Node-对私有仓库认证" class="headerlink" title="配置 Node 对私有仓库认证"></a>配置 Node 对私有仓库认证</h3><p>如果你在节点上运行的是 Docker，你可以配置 Docker 容器运行时来向私有容器仓库认证身份。</p><p>此方法适用于能够对节点进行配置的场合。</p><blockquote><p>Kubernetes 默认仅支持 Docker 配置中的 <code>auths</code> 和 <code>HttpHeaders</code> 部分， 不支持 Docker 凭据辅助程序（<code>credHelpers</code> 或 <code>credsStore</code>）。</p></blockquote><p>Docker 将私有仓库的密钥保存在 <code>$HOME/.dockercfg</code> 或 <code>$HOME/.docker/config.json</code> 文件中。如果你将相同的文件放在下面所列的搜索路径中，<code>kubelet</code> 会在拉取镜像时将其用作凭据 数据来源：</p><ul><li><code>&#123;--root-dir:-/var/lib/kubelet&#125;/config.json</code></li><li><code>&#123;kubelet 当前工作目录&#125;/config.json</code></li><li><code>$&#123;HOME&#125;/.docker/config.json</code></li><li><code>/.docker/config.json</code></li><li><code>&#123;--root-dir:-/var/lib/kubelet&#125;/.dockercfg</code></li><li><code>&#123;kubelet 当前工作目录&#125;/.dockercfg</code></li><li><code>$&#123;HOME&#125;/.dockercfg</code></li><li><code>/.dockercfg</code></li></ul><blockquote><p>可能不得不为 <code>kubelet</code> 进程显式地设置 <code>HOME=/root</code> 环境变量。</p></blockquote><p>推荐采用如下步骤来配置节点以便访问私有仓库。</p><ol><li>针对你要使用的每组凭据，运行 <code>docker login [服务器]</code> 命令。这会更新 你本地环境中的 <code>$HOME/.docker/config.json</code> 文件。</li><li>在编辑器中打开查看 <code>$HOME/.docker/config.json</code> 文件，确保其中仅包含你要 使用的凭据信息。</li><li>获得节点列表；例如：<ul><li>如果想要节点名称：<code>nodes=$(kubectl get nodes -o jsonpath=&#39;&#123;range.items[*].metadata&#125;&#123;.name&#125; &#123;end&#125;&#39;)</code></li><li>如果想要节点 IP ，<code>nodes=$(kubectl get nodes -o jsonpath=&#39;&#123;range .items[*].status.addresses[?(@.type==&quot;ExternalIP&quot;)]&#125;&#123;.address&#125; &#123;end&#125;&#39;)</code></li></ul></li><li>将本地的 <code>.docker/config.json</code> 拷贝到所有节点，放入如上所列的目录之一：<ul><li>例如，可以试一下：<code>for n in $nodes; do scp ~/.docker/config.json root@&quot;$n&quot;:/var/lib/kubelet/config.json; done</code></li></ul></li></ol><p>创建使用私有镜像的 Pod 来验证。例如：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f - &lt;&lt;EOF</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: private-image-test-1</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">    - name: uses-private-image</span><br><span class="line">      image: $PRIVATE_IMAGE_NAME</span><br><span class="line">      imagePullPolicy: Always</span><br><span class="line">      command: [ &quot;echo&quot;, &quot;SUCCESS&quot; ]</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p>输出类似于：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pod/private-image-test-1 created</span><br></pre></td></tr></table></figure><p>如果一切顺利，那么一段时间后你可以执行：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl logs private-image-test-1</span><br></pre></td></tr></table></figure><p>然后可以看到命令的输出：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SUCCESS</span><br></pre></td></tr></table></figure><p>如果你怀疑命令失败了，你可以运行：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl describe pods/private-image-test-1 | grep &#x27;Failed&#x27;</span><br></pre></td></tr></table></figure><p>如果命令确实失败，输出类似于：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Fri, 26 Jun 2015 15:36:13 -0700    Fri, 26 Jun 2015 15:39:13 -0700    19    &#123;kubelet node-i2hq&#125;    spec.containers&#123;uses-private-image&#125;    failed        Failed to pull image &quot;user/privaterepo:v1&quot;: Error: image user/privaterepo:v1 not found</span><br></pre></td></tr></table></figure><p>你必须确保集群中所有节点的 <code>.docker/config.json</code> 文件内容相同。 否则，Pod 会能在一些节点上正常运行而无法在另一些节点上启动。 例如，如果使用节点自动扩缩，那么每个实例模板都需要包含 <code>.docker/config.json</code>， 或者挂载一个包含该文件的驱动器。</p><p>在 <code>.docker/config.json</code> 中配置了私有仓库密钥后，所有 Pod 都将能读取私有仓库中的镜像。</p><h3 id="config-json-说明"><a href="#config-json-说明" class="headerlink" title="config.json 说明"></a>config.json 说明</h3><p>对于 <code>config.json</code> 的解释在原始 Docker 实现和 Kubernetes 的解释之间有所不同。 在 Docker 中，<code>auths</code> 键只能指定根 URL ，而 Kubernetes 允许 glob URLs 以及 前缀匹配的路径。这意味着，像这样的 <code>config.json</code> 是有效的：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">&quot;auths&quot;</span>: &#123;</span><br><span class="line">        <span class="attr">&quot;*my-registry.io/images&quot;</span>: &#123;</span><br><span class="line">            <span class="attr">&quot;auth&quot;</span>: <span class="string">&quot;…&quot;</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>使用以下语法匹配根 URL （<code>*my-registry.io</code>）：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">pattern:</span><br><span class="line">    &#123; term &#125;</span><br><span class="line"></span><br><span class="line">term:</span><br><span class="line">    &#x27;*&#x27;         匹配任何无分隔符字符序列</span><br><span class="line">    &#x27;?&#x27;         匹配任意单个非分隔符</span><br><span class="line">    &#x27;[&#x27; [ &#x27;^&#x27; ] 字符范围</span><br><span class="line">                  字符集（必须非空）</span><br><span class="line">    c           匹配字符 c （c 不为 &#x27;*&#x27;,&#x27;?&#x27;,&#x27;\\&#x27;,&#x27;[&#x27;）</span><br><span class="line">    &#x27;\\&#x27; c      匹配字符 c</span><br><span class="line"></span><br><span class="line">字符范围: </span><br><span class="line">    c           匹配字符 c （c 不为 &#x27;\\&#x27;,&#x27;?&#x27;,&#x27;-&#x27;,&#x27;]&#x27;）</span><br><span class="line">    &#x27;\\&#x27; c      匹配字符 c</span><br><span class="line">    lo &#x27;-&#x27; hi   匹配字符范围在 lo 到 hi 之间字符</span><br></pre></td></tr></table></figure><p>现在镜像拉取操作会将每种有效模式的凭据都传递给 CRI 容器运行时。例如下面的容器镜像名称会匹配成功：</p><ul><li><code>my-registry.io/images</code></li><li><code>my-registry.io/images/my-image</code></li><li><code>my-registry.io/images/another-image</code></li><li><code>sub.my-registry.io/images/my-image</code></li><li><code>a.sub.my-registry.io/images/my-image</code></li></ul><p>kubelet 为每个找到的凭证的镜像按顺序拉取。 这意味着在 <code>config.json</code> 中可能有多项：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">&quot;auths&quot;</span>: &#123;</span><br><span class="line">        <span class="attr">&quot;my-registry.io/images&quot;</span>: &#123;</span><br><span class="line">            <span class="attr">&quot;auth&quot;</span>: <span class="string">&quot;…&quot;</span></span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="attr">&quot;my-registry.io/images/subpath&quot;</span>: &#123;</span><br><span class="line">            <span class="attr">&quot;auth&quot;</span>: <span class="string">&quot;…&quot;</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>如果一个容器指定了要拉取的镜像 <code>my-registry.io/images/subpath/my-image</code>， 并且其中一个失败，kubelet 将尝试从另一个身份验证源下载镜像。</p><h3 id="提前拉取镜像"><a href="#提前拉取镜像" class="headerlink" title="提前拉取镜像"></a>提前拉取镜像</h3><blockquote><p>该方法适用于你能够控制节点配置的场合。 如果你的云供应商负责管理节点并自动置换节点，这一方案无法可靠地工作。</p></blockquote><p>默认情况下，<code>kubelet</code> 会尝试从指定的仓库拉取每个镜像。 但是，如果容器属性 <code>imagePullPolicy</code> 设置为 <code>IfNotPresent</code> 或者 <code>Never</code>， 则会优先使用（对应 <code>IfNotPresent</code>）或者一定使用（对应 <code>Never</code>）本地镜像。</p><p>如果你希望使用提前拉取镜像的方法代替仓库认证，就必须保证集群中所有节点提前拉取的镜像是相同的。</p><p>这一方案可以用来提前载入指定的镜像以提高速度，或者作为向私有仓库执行身份认证的一种替代方案。</p><p>所有的 Pod 都可以使用节点上提前拉取的镜像。</p><h3 id="在-Pod-上指定-ImagePullSecrets"><a href="#在-Pod-上指定-ImagePullSecrets" class="headerlink" title="在 Pod 上指定 ImagePullSecrets"></a>在 Pod 上指定 ImagePullSecrets</h3><blockquote><p>运行使用私有仓库中镜像的容器时，建议使用这种方法。</p></blockquote><p>Kubernetes 支持在 Pod 中设置容器镜像仓库的密钥。</p><h4 id="使用-Docker-Config-创建-Secret"><a href="#使用-Docker-Config-创建-Secret" class="headerlink" title="使用 Docker Config 创建 Secret"></a>使用 Docker Config 创建 Secret</h4><p>运行以下命令，将大写字母代替为合适的值：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">kubectl create secret docker-registry &lt;名称&gt; \</span><br><span class="line">  --docker-server=DOCKER_REGISTRY_SERVER \</span><br><span class="line">  --docker-username=DOCKER_USER \</span><br><span class="line">  --docker-password=DOCKER_PASSWORD \</span><br><span class="line">  --docker-email=DOCKER_EMAIL</span><br></pre></td></tr></table></figure><p>如果你已经有 Docker 凭据文件，则可以将凭据文件导入为 Kubernetes <a href="https://kubernetes.io/zh/docs/concepts/configuration/secret/">Secret</a>， 而不是执行上面的命令。 <a href="https://kubernetes.io/zh/docs/tasks/configure-pod-container/pull-image-private-registry/#registry-secret-existing-credentials">基于已有的 Docker 凭据创建 Secret</a> 解释了如何完成这一操作。</p><p>如果你在使用多个私有容器仓库，这种技术将特别有用。 原因是 <code>kubectl create secret docker-registry</code> 创建的是仅适用于某个私有仓库的 Secret。</p><blockquote><p>Pod 只能引用位于自身所在名字空间中的 Secret，因此需要针对每个名字空间 重复执行上述过程。</p></blockquote><h4 id="在-Pod-中引用-ImagePullSecrets"><a href="#在-Pod-中引用-ImagePullSecrets" class="headerlink" title="在 Pod 中引用 ImagePullSecrets"></a>在 Pod 中引用 ImagePullSecrets</h4><p>现在，在创建 Pod 时，可以在 Pod 定义中增加 <code>imagePullSecrets</code> 部分来引用该 Secret。</p><p>例如：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">cat &lt;&lt;EOF &gt; pod.yaml</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: foo</span><br><span class="line">  namespace: awesomeapps</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">    - name: foo</span><br><span class="line">      image: janedoe/awesomeapp:v1</span><br><span class="line">  imagePullSecrets:</span><br><span class="line">    - name: myregistrykey</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">cat &lt;&lt;EOF &gt;&gt; ./kustomization.yaml</span><br><span class="line">resources:</span><br><span class="line">- pod.yaml</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p>你需要对使用私有仓库的每个 Pod 执行以上操作。 不过，设置该字段的过程也可以通过为 <a href="https://kubernetes.io/zh/docs/tasks/configure-pod-container/configure-service-account/">服务账号</a> 资源设置 <code>imagePullSecrets</code> 来自动完成。 有关详细指令可参见 <a href="https://kubernetes.io/zh/docs/tasks/configure-pod-container/configure-service-account/#add-imagepullsecrets-to-a-service-account">将 ImagePullSecrets 添加到服务账号</a>。</p><p>你也可以将此方法与节点级别的 <code>.docker/config.json</code> 配置结合使用。 来自不同来源的凭据会被合并。</p><h1 id="容器环境"><a href="#容器环境" class="headerlink" title="容器环境"></a>容器环境</h1><p>Kubernetes 的容器环境给容器提供了几个重要的资源：</p><ul><li>文件系统，其中包含一个<a href="https://kubernetes.io/zh/docs/concepts/containers/images/">镜像</a> 和一个或多个的<a href="https://kubernetes.io/zh/docs/concepts/storage/volumes/">卷</a></li><li>容器自身的信息</li><li>集群中其他对象的信息</li></ul><h3 id="容器信息"><a href="#容器信息" class="headerlink" title="容器信息"></a>容器信息</h3><p>容器的 <em>hostname</em> 是它所运行在的 pod 的名称。它可以通过 <code>hostname</code> 命令或者调用 libc 中的 <a href="https://man7.org/linux/man-pages/man2/gethostname.2.html"><code>gethostname</code></a> 函数来获取。</p><p>Pod 名称和命名空间可以通过 <a href="https://kubernetes.io/zh/docs/tasks/inject-data-application/downward-api-volume-expose-pod-information/">下行 API</a> 转换为环境变量。</p><p>Pod 定义中的用户所定义的环境变量也可在容器中使用，就像在 Docker 镜像中静态指定的任何环境变量一样。</p><h3 id="集群信息"><a href="#集群信息" class="headerlink" title="集群信息"></a>集群信息</h3><p>创建容器时正在运行的所有服务都可用作该容器的环境变量。 这里的服务仅限于新容器的 Pod 所在的名字空间中的服务，以及 Kubernetes 控制面的服务。 这些环境变量与 Docker 链接的语法相同。</p><p>对于名为 <em>foo</em> 的服务，当映射到名为 <em>bar</em> 的容器时，以下变量是被定义了的：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">FOO_SERVICE_HOST=&lt;the host the service is running on&gt;</span><br><span class="line">FOO_SERVICE_PORT=&lt;the port the service is running on&gt;</span><br></pre></td></tr></table></figure><p>服务具有专用的 IP 地址。如果启用了 <a href="https://releases.k8s.io/v1.23.0/cluster/addons/dns/">DNS 插件</a>， 可以在容器中通过 DNS 来访问服务。</p><h1 id="容器运行时类（Runtime-Class）"><a href="#容器运行时类（Runtime-Class）" class="headerlink" title="容器运行时类（Runtime Class）"></a>容器运行时类（Runtime Class）</h1><p><strong>FEATURE STATE:</strong> <code>Kubernetes v1.20 [stable]</code></p><p>本页面描述了 RuntimeClass 资源和运行时的选择机制。</p><p>RuntimeClass 是一个用于选择容器运行时配置的特性，容器运行时配置用于运行 Pod 中的容器。</p><h2 id="动机"><a href="#动机" class="headerlink" title="动机"></a>动机</h2><p>你可以在<strong>不同的 Pod 设置不同的 RuntimeClass</strong>，以提供性能与安全性之间的平衡。 例如，如果你的部分工作负载需要高级别的信息安全保证，你可以决定在调度这些 Pod 时尽量使它们在使用<strong>硬件虚拟化</strong>的容器运行时中运行。 这样，你将从这些不同运行时所提供的额外隔离中获益，代价是一些额外的开销。</p><p>你还可以使用 RuntimeClass 运行<strong>具有相同容器运行时但具有不同设置的 Pod</strong>。</p><h2 id="设置"><a href="#设置" class="headerlink" title="设置"></a>设置</h2><ol><li>在节点上配置 CRI 的实现（取决于所选用的运行时）</li><li>创建相应的 RuntimeClass 资源</li></ol><h3 id="1-在节点上配置-CRI-实现"><a href="#1-在节点上配置-CRI-实现" class="headerlink" title="1. 在节点上配置 CRI 实现"></a>1. 在节点上配置 CRI 实现</h3><p>RuntimeClass 的配置依赖于 运行时接口（CRI）的实现。 </p><blockquote><p>RuntimeClass 假设集群中的节点配置是同构的（换言之，所有的节点在容器运行时方面的配置是相同的）。 如果需要支持异构节点，配置方法请参阅下面的 调度 章节。</p></blockquote><p>所有这些配置都具有相应的 <code>handler</code> 名，并被 RuntimeClass 引用。 handler 必须是有效的 <a href="https://kubernetes.io/zh/docs/concepts/overview/working-with-objects/names/#dns-label-names">DNS 标签名</a>。</p><h3 id="创建相应的-RuntimeClass-资源"><a href="#创建相应的-RuntimeClass-资源" class="headerlink" title="创建相应的 RuntimeClass 资源"></a>创建相应的 RuntimeClass 资源</h3><p>在上面步骤 1 中，每个配置都需要有一个用于标识配置的 <code>handler</code>。 针对每个 handler 需要创建一个 RuntimeClass 对象。</p><p>RuntimeClass 资源当前只有两个重要的字段：RuntimeClass 名 (<code>metadata.name</code>) 和 handler (<code>handler</code>)。 对象定义如下所示：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">node.k8s.io/v1</span>  <span class="comment"># RuntimeClass 定义于 node.k8s.io API 组</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">RuntimeClass</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">myclass</span>  <span class="comment"># 用来引用 RuntimeClass 的名字</span></span><br><span class="line">  <span class="comment"># RuntimeClass 是一个集群层面的资源</span></span><br><span class="line"><span class="attr">handler:</span> <span class="string">myconfiguration</span>  <span class="comment"># 对应的 CRI 配置的名称</span></span><br></pre></td></tr></table></figure><blockquote><p>建议将 RuntimeClass 写操作（create、update、patch 和 delete）限定于集群管理员使用。 通常这是默认配置。参阅<a href="https://kubernetes.io/zh/docs/reference/access-authn-authz/authorization/">授权概述</a>了解更多信息。</p></blockquote><h2 id="使用说明"><a href="#使用说明" class="headerlink" title="使用说明"></a>使用说明</h2><p>一旦完成集群中 RuntimeClasses 的配置，使用起来非常方便。 在 Pod spec 中指定 <code>runtimeClassName</code> 即可。例如:</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">mypod</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">runtimeClassName:</span> <span class="string">myclass</span></span><br><span class="line">  <span class="comment"># ...</span></span><br></pre></td></tr></table></figure><p>这一设置会告诉 kubelet 使用所指的 RuntimeClass 来运行该 pod。 如果所指的 RuntimeClass 不存在或者 CRI 无法运行相应的 handler， 那么 pod 将会进入 <code>Failed</code> 终止<a href="https://kubernetes.io/zh/docs/concepts/workloads/pods/pod-lifecycle/#pod-phase">阶段</a>。 你可以查看相应的<a href="https://kubernetes.io/zh/docs/tasks/debug-application-cluster/debug-application-introspection/">事件</a>， 获取执行过程中的错误信息。</p><p>如果未指定 <code>runtimeClassName</code> ，则将使用默认的 RuntimeHandler，相当于禁用 RuntimeClass 功能特性。</p><h3 id="CRI-配置"><a href="#CRI-配置" class="headerlink" title="CRI 配置"></a>CRI 配置</h3><p>关于如何安装 CRI 运行时，请查阅 <a href="https://kubernetes.io/zh/docs/setup/production-environment/container-runtimes/">CRI 安装</a>。</p><h4 id="dockershim"><a href="#dockershim" class="headerlink" title="dockershim"></a>dockershim</h4><p>为 dockershim 设置 RuntimeClass 时，必须将运行时处理程序设置为 <code>docker</code>。 Dockershim 不支持自定义的可配置的运行时处理程序。</p><h4 id="containerd"><a href="#containerd" class="headerlink" title="containerd"></a><a href="https://containerd.io/">containerd</a></h4><p>通过 containerd 的 <code>/etc/containerd/config.toml</code> 配置文件来配置运行时 handler。 handler 需要配置在 runtimes 块中：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[plugins.&quot;io.containerd.grpc.v1.cri&quot;.containerd.runtimes.$&#123;HANDLER_NAME&#125;]</span><br></pre></td></tr></table></figure><p>更详细信息，请查阅 containerd 配置文档： <a href="https://github.com/containerd/cri/blob/master/docs/config.md">https://github.com/containerd/cri/blob/master/docs/config.md</a></p><h4 id="cri-o"><a href="#cri-o" class="headerlink" title="cri-o"></a><a href="https://cri-o.io/">cri-o</a></h4><p>通过 cri-o 的 <code>/etc/crio/crio.conf</code> 配置文件来配置运行时 handler。 handler 需要配置在 <a href="https://github.com/kubernetes-sigs/cri-o/blob/master/docs/crio.conf.5.md#crioruntime-table">crio.runtime 表</a> 下面：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[crio.runtime.runtimes.$&#123;HANDLER_NAME&#125;]</span><br><span class="line">  runtime_path = &quot;$&#123;PATH_TO_BINARY&#125;&quot;</span><br></pre></td></tr></table></figure><p>更详细信息，请查阅 CRI-O <a href="https://github.com/cri-o/cri-o/blob/master/docs/crio.conf.5.md">配置文档</a>。</p><h2 id="调度"><a href="#调度" class="headerlink" title="调度"></a>调度</h2><p><strong>FEATURE STATE:</strong> <code>Kubernetes v1.16 [beta]</code></p><p>通过为 RuntimeClass 指定 <code>scheduling</code> 字段， 你可以通过设置约束，确保运行该 RuntimeClass 的 Pod 被调度到支持该 RuntimeClass 的节点上。 如果未设置 <code>scheduling</code>，则假定所有节点均支持此 RuntimeClass 。</p><p>为了确保 pod 会被调度到支持指定运行时的 node 上，每个 node 需要设置一个通用的 label 用于被 <code>runtimeclass.scheduling.nodeSelector</code> 挑选。在 admission 阶段，RuntimeClass 的 nodeSelector 将会与 pod 的 nodeSelector 合并，取二者的交集。如果有冲突，pod 将会被拒绝。</p><p>如果 node 需要阻止某些需要特定 RuntimeClass 的 pod，可以在 <code>tolerations</code> 中指定。 与 <code>nodeSelector</code> 一样，tolerations 也在 admission 阶段与 pod 的 tolerations 合并，取二者的并集。</p><p>更多有关 node selector 和 tolerations 的配置信息，请查阅 <a href="https://kubernetes.io/zh/docs/concepts/scheduling-eviction/assign-pod-node/">将 Pod 分派到节点</a>。</p><h3 id="Pod-开销"><a href="#Pod-开销" class="headerlink" title="Pod 开销"></a>Pod 开销</h3><p><strong>FEATURE STATE:</strong> <code>Kubernetes v1.18 [beta]</code></p><p>你可以指定与运行 Pod 相关的 <em>开销</em> 资源。声明开销即允许集群（包括调度器）在决策 Pod 和资源时将其考虑在内。 若要使用 Pod 开销特性，你必须确保 PodOverhead <a href="https://kubernetes.io/zh/docs/reference/command-line-tools-reference/feature-gates/">特性门控</a> 处于启用状态（默认为启用状态）。</p><p>Pod 开销通过 RuntimeClass 的 <code>overhead</code> 字段定义。 通过使用这些字段，你可以指定使用该 RuntimeClass 运行 Pod 时的开销并确保 Kubernetes 将这些开销计算在内。</p><h1 id="容器生命周期回调"><a href="#容器生命周期回调" class="headerlink" title="容器生命周期回调"></a>容器生命周期回调</h1><p>描述了 kubelet 管理的容器如何使用容器生命周期回调框架， 藉由其管理生命周期中的事件触发，运行指定代码。</p><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>类似于许多具有生命周期回调组件的编程语言框架，例如 Angular、Kubernetes 为容器提供了生命周期回调。 回调使容器能够了解其管理生命周期中的事件，并在执行相应的生命周期回调时运行在处理程序中实现的代码。</p><h2 id="容器回调"><a href="#容器回调" class="headerlink" title="容器回调"></a>容器回调</h2><p>有两个回调暴露给容器：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">PostStart</span><br></pre></td></tr></table></figure><p>这个回调在容器被创建之后立即被执行。 但是，不能保证回调会在容器入口点（ENTRYPOINT）之前执行。 没有参数传递给处理程序。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">PreStop</span><br></pre></td></tr></table></figure><p>在容器因 API 请求或者管理事件（诸如存活态探针、启动探针失败、资源抢占、资源竞争等） 而被终止之前，此回调会被调用。 如果容器已经处于已终止或者已完成状态，则对 preStop 回调的调用将失败。 在用来停止容器的 TERM 信号被发出之前，回调必须执行结束。 Pod 的终止宽限周期在 <code>PreStop</code> 回调被执行之前即开始计数，所以无论 回调函数的执行结果如何，容器最终都会在 Pod 的终止宽限期内被终止。 没有参数会被传递给处理程序。</p><p>有关终止行为的更详细描述，请参见 <a href="https://kubernetes.io/zh/docs/concepts/workloads/pods/pod-lifecycle/#termination-of-pods">终止 Pod</a>。</p><h3 id="回调处理程序的实现"><a href="#回调处理程序的实现" class="headerlink" title="回调处理程序的实现"></a>回调处理程序的实现</h3><p>容器可以通过实现和注册该回调的处理程序来访问该回调。 针对容器，有两种类型的回调处理程序可供实现：</p><ul><li>Exec - 在容器的 cgroups 和名称空间中执行特定的命令（例如 <code>pre-stop.sh</code>）。 命令所消耗的资源计入容器的资源消耗。</li><li>HTTP - 对容器上的特定端点执行 HTTP 请求。</li></ul><h3 id="回调处理程序执行"><a href="#回调处理程序执行" class="headerlink" title="回调处理程序执行"></a>回调处理程序执行</h3><p>当调用容器生命周期管理回调时，Kubernetes 管理系统根据回调动作执行其处理程序， <code>httpGet</code> 和 <code>tcpSocket</code> 在kubelet 进程执行，而 <code>exec</code> 则由容器内执行 。</p><p>回调处理程序调用在包含容器的 Pod 上下文中是同步的。 这意味着对于 <code>PostStart</code> 回调，容器入口点和回调异步触发。 但是，如果回调运行或挂起的时间太长，则容器无法达到 <code>running</code> 状态。</p><p><code>PreStop</code> 回调并不会与停止容器的信号处理程序异步执行；回调必须在 可以发送信号之前完成执行。 如果 <code>PreStop</code> 回调在执行期间停滞不前，Pod 的阶段会变成 <code>Terminating</code> 并且一致处于该状态，直到其 <code>terminationGracePeriodSeconds</code> 耗尽为止， 这时 Pod 会被杀死。 这一宽限期是针对 <code>PreStop</code> 回调的执行时间及容器正常停止时间的总和而言的。 例如，如果 <code>terminationGracePeriodSeconds</code> 是 60，回调函数花了 55 秒钟 完成执行，而容器在收到信号之后花了 10 秒钟来正常结束，那么容器会在其 能够正常结束之前即被杀死，因为 <code>terminationGracePeriodSeconds</code> 的值 小于后面两件事情所花费的总时间（55+10）。</p><p>如果 <code>PostStart</code> 或 <code>PreStop</code> 回调失败，它会杀死容器。</p><p>用户应该使他们的回调处理程序尽可能的轻量级。 但也需要考虑长时间运行的命令也很有用的情况，比如在停止容器之前保存状态。</p><h3 id="回调递送保证"><a href="#回调递送保证" class="headerlink" title="回调递送保证"></a>回调递送保证</h3><p>回调的递送应该是 <em>至少一次</em>，这意味着对于任何给定的事件， 例如 <code>PostStart</code> 或 <code>PreStop</code>，回调可以被调用多次。 如何正确处理被多次调用的情况，是回调实现所要考虑的问题。</p><p>通常情况下，只会进行单次递送。 例如，如果 HTTP 回调接收器宕机，无法接收流量，则不会尝试重新发送。 然而，偶尔也会发生重复递送的可能。 例如，如果 kubelet 在发送回调的过程中重新启动，回调可能会在 kubelet 恢复后重新发送。</p><h3 id="调试回调处理程序"><a href="#调试回调处理程序" class="headerlink" title="调试回调处理程序"></a>调试回调处理程序</h3><p>回调处理程序的日志不会在 Pod 事件中公开。 如果处理程序由于某种原因失败，它将播放一个事件。 对于 <code>PostStart</code>，这是 <code>FailedPostStartHook</code> 事件，对于 <code>PreStop</code>，这是 <code>FailedPreStopHook</code> 事件。 您可以通过运行 <code>kubectl describe pod &lt;pod_name&gt;</code> 命令来查看这些事件。 下面是运行这个命令的一些事件输出示例:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">Events:</span><br><span class="line">  FirstSeen    LastSeen    Count    From                            SubobjectPath        Type        Reason        Message</span><br><span class="line">  ---------    --------    -----    ----                            -------------        --------    ------        -------</span><br><span class="line">  1m        1m        1    &#123;default-scheduler &#125;                                Normal        Scheduled    Successfully assigned test-1730497541-cq1d2 to gke-test-cluster-default-pool-a07e5d30-siqd</span><br><span class="line">  1m        1m        1    &#123;kubelet gke-test-cluster-default-pool-a07e5d30-siqd&#125;    spec.containers&#123;main&#125;    Normal        Pulling        pulling image &quot;test:1.0&quot;</span><br><span class="line">  1m        1m        1    &#123;kubelet gke-test-cluster-default-pool-a07e5d30-siqd&#125;    spec.containers&#123;main&#125;    Normal        Created        Created container with docker id 5c6a256a2567; Security:[seccomp=unconfined]</span><br><span class="line">  1m        1m        1    &#123;kubelet gke-test-cluster-default-pool-a07e5d30-siqd&#125;    spec.containers&#123;main&#125;    Normal        Pulled        Successfully pulled image &quot;test:1.0&quot;</span><br><span class="line">  1m        1m        1    &#123;kubelet gke-test-cluster-default-pool-a07e5d30-siqd&#125;    spec.containers&#123;main&#125;    Normal        Started        Started container with docker id 5c6a256a2567</span><br><span class="line">  38s        38s        1    &#123;kubelet gke-test-cluster-default-pool-a07e5d30-siqd&#125;    spec.containers&#123;main&#125;    Normal        Killing        Killing container with docker id 5c6a256a2567: PostStart handler: Error executing in Docker Container: 1</span><br><span class="line">  37s        37s        1    &#123;kubelet gke-test-cluster-default-pool-a07e5d30-siqd&#125;    spec.containers&#123;main&#125;    Normal        Killing        Killing container with docker id 8df9fdfd7054: PostStart handler: Error executing in Docker Container: 1</span><br><span class="line">  38s        37s        2    &#123;kubelet gke-test-cluster-default-pool-a07e5d30-siqd&#125;                Warning        FailedSync    Error syncing pod, skipping: failed to &quot;StartContainer&quot; for &quot;main&quot; with RunContainerError: &quot;PostStart handler: Error executing in Docker Container: 1&quot;</span><br><span class="line">  1m         22s         2     &#123;kubelet gke-test-cluster-default-pool-a07e5d30-siqd&#125;    spec.containers&#123;main&#125;    Warning        FailedPostStartHook</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;容器&quot;&gt;&lt;a href=&quot;#容器&quot; class=&quot;headerlink&quot; title=&quot;容器&quot;&gt;&lt;/a&gt;容器&lt;/h1&gt;&lt;p&gt;每个运行的容器都是可重复的； 包含依赖环境在内的标准，意味着无论您在哪里运行它，您都会得到相同的行为。&lt;/p&gt;
&lt;p&gt;容器将应用程序从底层的主机设施中解耦。 这使得在不同的云或 OS 环境中部署更加容易。&lt;/p&gt;</summary>
    
    
    
    
    <category term="Kubernetes" scheme="http://chengqian90.com/tags/Kubernetes/"/>
    
    <category term="k8s" scheme="http://chengqian90.com/tags/k8s/"/>
    
  </entry>
  
  <entry>
    <title>学习Kubernetes系列2——架构</title>
    <link href="http://chengqian90.com/%E5%AE%B9%E5%99%A8/%E5%AD%A6%E4%B9%A0Kubernetes%E7%B3%BB%E5%88%972%E2%80%94%E2%80%94%E6%9E%B6%E6%9E%84.html"/>
    <id>http://chengqian90.com/%E5%AE%B9%E5%99%A8/%E5%AD%A6%E4%B9%A0Kubernetes%E7%B3%BB%E5%88%972%E2%80%94%E2%80%94%E6%9E%B6%E6%9E%84.html</id>
    <published>2021-05-15T11:50:55.000Z</published>
    <updated>2022-03-08T16:23:40.434Z</updated>
    
    <content type="html"><![CDATA[<p>此章节主要讲述k8s中架构中的几个主要部分：节点、控制面到节点的通信、控制器、云控制器管理器、CRI及GC。</p><span id="more"></span><h1 id="节点"><a href="#节点" class="headerlink" title="节点"></a>节点</h1><p>Kubernetes 通过将容器放入在节点（Node）上运行的 Pod 中来执行你的工作负载。 节点可以是一个虚拟机或者物理机器，取决于所在的集群配置。 每个节点包含运行 Pods 所需的服务； 这些节点由 控制面 负责管理。</p><p>通常集群中会有若干个节点；而在一个学习用或者资源受限的环境中，你的集群中也可能 只有一个节点。</p><p>节点上的组件包括 <a href="https://kubernetes.io/docs/reference/generated/kubelet">kubelet</a>、 <a href="https://kubernetes.io/zh/docs/setup/production-environment/container-runtimes">容器运行时</a>以及 <a href="https://kubernetes.io/zh/docs/reference/command-line-tools-reference/kube-proxy/">kube-proxy</a>。</p><h2 id="管理"><a href="#管理" class="headerlink" title="管理"></a>管理</h2><p>向 API 服务器添加节点的方式主要有两种：</p><ol><li>节点上的 <code>kubelet</code> 向控制面执行自注册；</li><li>你，或者别的什么人，手动添加一个 Node 对象。</li></ol><p>在你创建了 Node 对象或者节点上的 <code>kubelet</code> 执行了自注册操作之后， 控制面会检查新的 Node 对象是否合法。例如，如果你使用下面的 JSON 对象来创建 Node 对象：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">&quot;kind&quot;</span>: <span class="string">&quot;Node&quot;</span>,</span><br><span class="line">  <span class="attr">&quot;apiVersion&quot;</span>: <span class="string">&quot;v1&quot;</span>,</span><br><span class="line">  <span class="attr">&quot;metadata&quot;</span>: &#123;</span><br><span class="line">    <span class="attr">&quot;name&quot;</span>: <span class="string">&quot;10.240.79.157&quot;</span>,</span><br><span class="line">    <span class="attr">&quot;labels&quot;</span>: &#123;</span><br><span class="line">      <span class="attr">&quot;name&quot;</span>: <span class="string">&quot;my-first-k8s-node&quot;</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Kubernetes 会在内部创建一个 Node 对象作为节点的表示。Kubernetes 检查 <code>kubelet</code> 向 API 服务器注册节点时使用的 <code>metadata.name</code> 字段是否匹配。 如果节点是健康的（即所有必要的服务都在运行中），则该节点可以用来运行 Pod。 否则，直到该节点变为健康之前，所有的集群活动都会忽略该节点。</p><blockquote><p>Kubernetes 会一直保存着非法节点对应的对象，并持续检查该节点是否已经 变得健康。 你，或者某个<a href="https://kubernetes.io/zh/docs/concepts/architecture/controller/">控制器</a>必需显式地 删除该 Node 对象以停止健康检查操作。</p></blockquote><p>Node 对象的名称必须是合法的 <a href="https://kubernetes.io/zh/docs/concepts/overview/working-with-objects/names#dns-subdomain-names">DNS 子域名</a>。</p><h3 id="节点自注册"><a href="#节点自注册" class="headerlink" title="节点自注册"></a>节点自注册</h3><p>当 kubelet 标志 <code>--register-node</code> 为 true（默认）时，它会尝试向 API 服务注册自己。 这是首选模式，被绝大多数发行版选用。</p><p>对于自注册模式，kubelet 使用下列参数启动：</p><ul><li><code>--kubeconfig</code> - 用于向 API 服务器表明身份的凭据路径。</li><li><code>--cloud-provider</code> - 与某云驱动进行通信以读取与自身相关的元数据的方式。</li><li><code>--register-node</code> - 自动向 API 服务注册。</li><li><code>--register-with-taints</code> - 使用所给的污点列表（逗号分隔的 <code>&lt;key&gt;=&lt;value&gt;:&lt;effect&gt;</code>）注册节点。 当 <code>register-node</code> 为 false 时无效。</li><li><code>--node-ip</code> - 节点 IP 地址。</li><li><code>--node-labels</code> - 在集群中注册节点时要添加的 标签。 （参见 <a href="https://kubernetes.io/zh/docs/reference/access-authn-authz/admission-controllers/#noderestriction">NodeRestriction 准入控制插件</a>所实施的标签限制）。</li><li><code>--node-status-update-frequency</code> - 指定 kubelet 向控制面发送状态的频率。</li></ul><p>启用<a href="https://kubernetes.io/zh/docs/reference/access-authn-authz/node/">节点授权模式</a>和 <a href="https://kubernetes.io/zh/docs/reference/access-authn-authz/admission-controllers/#noderestriction">NodeRestriction 准入插件</a> 时，仅授权 <code>kubelet</code> 创建或修改其自己的节点资源。</p><h3 id="手动节点管理"><a href="#手动节点管理" class="headerlink" title="手动节点管理"></a>手动节点管理</h3><p>你可以使用 <a href="https://kubernetes.io/docs/user-guide/kubectl-overview/">kubectl</a> 来创建和修改 Node 对象。</p><p>如果你希望手动创建节点对象时，请设置 kubelet 标志 <code>--register-node=false</code>。</p><p>你可以修改 Node 对象（忽略 <code>--register-node</code> 设置）。 例如，修改节点上的标签或标记其为不可调度。</p><p>你可以结合使用节点上的标签和 Pod 上的选择算符来控制调度。 例如，你可以限制某 Pod 只能在符合要求的节点子集上运行。</p><p>如果标记节点为不可调度（unschedulable），将阻止新 Pod 调度到该节点之上，但不会 影响任何已经在其上的 Pod。 这是重启节点或者执行其他维护操作之前的一个有用的准备步骤。</p><p>要标记一个节点为不可调度，执行以下命令：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl cordon $NODENAME</span><br></pre></td></tr></table></figure><p>更多细节参考<a href="https://kubernetes.io/zh/docs/tasks/administer-cluster/safely-drain-node/">安全腾空节点</a>。</p><blockquote><p> 被 <a href="https://kubernetes.io/zh/docs/concepts/workloads/controllers/daemonset/">DaemonSet</a> 控制器创建的 Pod 能够容忍节点的不可调度属性。 DaemonSet 通常提供节点本地的服务，即使节点上的负载应用已经被腾空，这些服务也仍需 运行在节点之上。</p></blockquote><h2 id="节点状态"><a href="#节点状态" class="headerlink" title="节点状态"></a>节点状态</h2><p>一个节点的状态包含以下信息:</p><ul><li>地址</li><li>状况</li><li>容量与可分配</li><li>信息</li></ul><p>你可以使用 <code>kubectl</code> 来查看节点状态和其他细节信息：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl describe node &lt;节点名称&gt;</span><br></pre></td></tr></table></figure><p>下面对每个部分进行详细描述。</p><h3 id="地址"><a href="#地址" class="headerlink" title="地址"></a>地址</h3><p>这些字段的用法取决于你的云服务商或者物理机配置。</p><ul><li>HostName：由节点的内核设置。可以通过 kubelet 的 <code>--hostname-override</code> 参数覆盖。</li><li>ExternalIP：通常是节点的可外部路由（从集群外可访问）的 IP 地址。</li><li>InternalIP：通常是节点的仅可在集群内部路由的 IP 地址。</li></ul><h3 id="状况"><a href="#状况" class="headerlink" title="状况"></a>状况</h3><p><code>conditions</code> 字段描述了所有 <code>Running</code> 节点的状态。状况的示例包括：</p><table><thead><tr><th>节点状况</th><th>描述</th></tr></thead><tbody><tr><td><code>Ready</code></td><td>如节点是健康的并已经准备好接收 Pod 则为 <code>True</code>；<code>False</code> 表示节点不健康而且不能接收 Pod；<code>Unknown</code> 表示节点控制器在最近 <code>node-monitor-grace-period</code> 期间（默认 40 秒）没有收到节点的消息</td></tr><tr><td><code>DiskPressure</code></td><td><code>True</code> 表示节点存在磁盘空间压力，即磁盘可用量低, 否则为 <code>False</code></td></tr><tr><td><code>MemoryPressure</code></td><td><code>True</code> 表示节点存在内存压力，即节点内存可用量低，否则为 <code>False</code></td></tr><tr><td><code>PIDPressure</code></td><td><code>True</code> 表示节点存在进程压力，即节点上进程过多；否则为 <code>False</code></td></tr><tr><td><code>NetworkUnavailable</code></td><td><code>True</code> 表示节点网络配置不正确；否则为 <code>False</code></td></tr></tbody></table><blockquote><p>如果使用命令行工具来打印已保护（Cordoned）节点的细节，其中的 Condition 字段可能 包括 <code>SchedulingDisabled</code>。<code>SchedulingDisabled</code> 不是 Kubernetes API 中定义的 Condition，被保护起来的节点在其规约中被标记为不可调度（Unschedulable）。</p></blockquote><p>在 Kubernetes API 中，节点的状况表示节点资源中<code>.status</code> 的一部分。 例如，以下 JSON 结构描述了一个健康节点：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;conditions&quot;</span>: [</span><br><span class="line">  &#123;</span><br><span class="line">    <span class="attr">&quot;type&quot;</span>: <span class="string">&quot;Ready&quot;</span>,</span><br><span class="line">    <span class="attr">&quot;status&quot;</span>: <span class="string">&quot;True&quot;</span>,</span><br><span class="line">    <span class="attr">&quot;reason&quot;</span>: <span class="string">&quot;KubeletReady&quot;</span>,</span><br><span class="line">    <span class="attr">&quot;message&quot;</span>: <span class="string">&quot;kubelet is posting ready status&quot;</span>,</span><br><span class="line">    <span class="attr">&quot;lastHeartbeatTime&quot;</span>: <span class="string">&quot;2019-06-05T18:38:35Z&quot;</span>,</span><br><span class="line">    <span class="attr">&quot;lastTransitionTime&quot;</span>: <span class="string">&quot;2019-06-05T11:41:27Z&quot;</span></span><br><span class="line">  &#125;</span><br><span class="line">]</span><br></pre></td></tr></table></figure><p>如果 Ready 条件的 <code>status</code> 处于 <code>Unknown</code> 或者 <code>False</code> 状态的时间超过了 <code>pod-eviction-timeout</code> 值， （一个传递给 kube-controller-manager的参数）， 节点控制器会对节点上的所有 Pod 触发 <a href="https://kubernetes.io/zh/docs/concepts/scheduling-eviction/pod-eviction/#api-eviction">API-发起的驱逐</a>。 默认的逐出超时时长为 <strong>5 分钟</strong>。 某些情况下，当节点不可达时，API 服务器不能和其上的 kubelet 通信。 删除 Pod 的决定不能传达给 kubelet，直到它重新建立和 API 服务器的连接为止。 与此同时，被计划删除的 Pod 可能会继续在游离的节点上运行。</p><p>节点控制器在确认 Pod 在集群中已经停止运行前，不会强制删除它们。 你可以看到这些可能在无法访问的节点上运行的 Pod 处于 <code>Terminating</code> 或者 <code>Unknown</code> 状态。 如果 kubernetes 不能基于下层基础设施推断出某节点是否已经永久离开了集群， 集群管理员可能需要<strong>手动删除该节点对象</strong>。 从 Kubernetes 删除节点对象将导致 API 服务器删除节点上所有运行的 Pod 对象并释放它们的名字。</p><p>节点生命周期控制器会自动创建代表状况的 <a href="https://kubernetes.io/zh/docs/concepts/scheduling-eviction/taint-and-toleration/">污点</a>。 当调度器将 Pod 指派给某节点时，会考虑节点上的污点。 Pod 则可以通过容忍度（Toleration）表达所能容忍的污点。</p><h3 id="容量与可分配"><a href="#容量与可分配" class="headerlink" title="容量与可分配"></a>容量与可分配</h3><p>描述节点上的可用资源：<strong>CPU、内存和可以调度到节点上的 Pod 的个数上限</strong>。</p><p><code>capacity</code> 块中的字段标示节点拥有的资源总量。 <code>allocatable</code> 块指示节点上可供普通 Pod 消耗的资源量。</p><p>可以在学习如何在节点上<a href="https://kubernetes.io/zh/docs/tasks/administer-cluster/reserve-compute-resources/#node-allocatable">预留计算资源</a> 的时候了解有关容量和可分配资源的更多信息。</p><h3 id="信息"><a href="#信息" class="headerlink" title="信息"></a>信息</h3><p>描述节点的一般信息，如内核版本、Kubernetes 版本（<code>kubelet</code> 和 <code>kube-proxy</code> 版本）、 容器运行时详细信息，以及 节点使用的操作系统。 <code>kubelet</code> 从节点收集这些信息并将其发布到 Kubernetes API。</p><h2 id="心跳"><a href="#心跳" class="headerlink" title="心跳"></a>心跳</h2><p>Kubernetes 节点发送的心跳帮助你的集群确定每个节点的可用性，并在检测到故障时采取行动。</p><p>对于节点，有两种形式的心跳:</p><ul><li>更新节点的 <code>.status</code></li><li><a href="https://kubernetes.io/docs/reference/kubernetes-api/cluster-resources/lease-v1/">Lease</a> 对象 在 <code>kube-node-lease</code> <a href="https://kubernetes.io/zh/docs/concepts/overview/working-with-objects/namespaces/">命名空间</a>中。 每个节点都有一个关联的 Lease 对象。</li></ul><p>kubelet 负责创建和更新节点的 <code>.status</code>，以及更新它们对应的 <code>Lease</code>。</p><ul><li>当状态发生变化时，或者在配置的时间间隔内没有更新事件时，kubelet 会更新 <code>.status</code>。 <code>.status</code> 更新的默认间隔为 5 分钟（比不可达节点的 40 秒默认超时时间长很多）。</li><li><code>kubelet</code> 会每 10 秒（默认更新间隔时间）创建并更新其 <code>Lease</code> 对象。 <code>Lease</code> 更新独立于 <code>NodeStatus</code> 更新而发生。 如果 <code>Lease</code> 的更新操作失败，<code>kubelet</code> 会采用指数回退机制，从 200 毫秒开始 重试，最长重试间隔为 7 秒钟。</li></ul><h2 id="节点控制器"><a href="#节点控制器" class="headerlink" title="节点控制器"></a>节点控制器</h2><p>节点<a href="https://kubernetes.io/zh/docs/concepts/architecture/controller/">控制器</a>是 Kubernetes 控制面组件，管理节点的方方面面。</p><p>节点控制器在节点的生命周期中扮演多个角色。 第一个是当节点注册时为它分配一个 CIDR 区段（如果启用了 CIDR 分配）。</p><p>第二个是保持节点控制器内的节点列表与云服务商所提供的可用机器列表同步。 如果在云环境下运行，只要某节点不健康，节点控制器就会<strong>询问云服务是否节点的虚拟机仍可用</strong>。 如果不可用，节点控制器会将该节点从它的节点列表删除。</p><p>第三个是监控节点的健康状况。 节点控制器是负责：</p><ul><li>在节点节点不可达的情况下，在 Node 的 <code>.status</code> 中更新 <code>NodeReady</code> 状况。 在这种情况下，节点控制器将 <code>NodeReady</code> 状况更新为 <code>ConditionUnknown</code> 。</li><li>如果节点仍然无法访问：对于不可达节点上的所有 Pod触发 <a href="https://kubernetes.io/zh/docs/concepts/scheduling-eviction/api-eviction/">API-发起的逐出</a>。 默认情况下，节点控制器 在将节点标记为 <code>ConditionUnknown</code> 后等待 5 分钟 提交第一个驱逐请求。</li></ul><p>节点控制器每隔 <code>--node-monitor-period</code> 秒检查每个节点的状态。</p><h3 id="逐出速率限制"><a href="#逐出速率限制" class="headerlink" title="逐出速率限制"></a>逐出速率限制</h3><p>大部分情况下，节点控制器把逐出速率限制在每秒 <code>--node-eviction-rate</code> 个（默认为 0.1）。 这表示它每 10 秒钟内至多从一个节点驱逐 Pod。</p><p>当一个可用区域（Availability Zone）中的节点变为不健康时，节点的驱逐行为将发生改变。 节点控制器会同时检查可用区域中不健康（NodeReady 状况为 <code>ConditionUnknown</code> 或 <code>ConditionFalse</code>） 的节点的百分比：</p><ul><li>如果不健康节点的比例超过 <code>--unhealthy-zone-threshold</code> （默认为 0.55）， 驱逐速率将会降低。</li><li>如果集群较小（意即小于等于 <code>--large-cluster-size-threshold</code> 个节点 - 默认为 50），驱逐操作将会停止。</li><li>否则驱逐速率将降为每秒 <code>--secondary-node-eviction-rate</code> 个（默认为 0.01）。</li></ul><p>在单个可用区域实施这些策略的原因是当一个可用区域可能从控制面脱离时其它可用区域 可能仍然保持连接。 如果你的集群没有跨越云服务商的多个可用区域，那（整个集群）就只有一个可用区域。</p><p>跨多个可用区域部署你的节点的一个关键原因是当某个可用区域整体出现故障时， 工作负载可以转移到健康的可用区域。 因此，如果一个可用区域中的所有节点都不健康时，节点控制器会以正常的速率 <code>--node-eviction-rate</code> 进行驱逐操作。 在所有的可用区域都不健康（也即集群中没有健康节点）的极端情况下， 节点控制器将假设控制面与节点间的连接出了某些问题，它将停止所有驱逐动作（如果故障后部分节点重新连接， 节点控制器会从剩下不健康或者不可达节点中驱逐 <code>pods</code>）。</p><p>节点控制器还负责驱逐运行在拥有 <code>NoExecute</code> 污点的节点上的 Pod， 除非这些 Pod 能够容忍此污点。 节点控制器还负责根据节点故障（例如节点不可访问或没有就绪）为其添加 <a href="https://kubernetes.io/zh/docs/concepts/scheduling-eviction/taint-and-toleration/">污点</a>。 这意味着调度器不会将 Pod 调度到不健康的节点上。</p><h3 id="资源容量跟踪"><a href="#资源容量跟踪" class="headerlink" title="资源容量跟踪"></a>资源容量跟踪</h3><p>Node 对象会跟踪节点上资源的容量（例如可用内存和 CPU 数量）。 通过<a href="https://kubernetes.io/zh/docs/concepts/architecture/nodes/#self-registration-of-nodes">自注册</a>机制生成的 Node 对象会在注册期间报告自身容量。 如果你<a href="https://kubernetes.io/zh/docs/concepts/architecture/nodes/#manual-node-administration">手动</a>添加了 Node，你就需要在添加节点时 手动设置节点容量。</p><p>Kubernetes <a href="https://kubernetes.io/docs/reference/generated/kube-scheduler/">调度器</a>保证节点上 有足够的资源供其上的所有 Pod 使用。它会检查节点上所有容器的请求的总和不会超过节点的容量。 总的请求包括由 kubelet 启动的所有容器，但不包括由容器运行时直接启动的容器， 也不包括不受 <code>kubelet</code> 控制的其他进程。</p><blockquote><p> 如果要为非 Pod 进程显式保留资源。请参考 <a href="https://kubernetes.io/zh/docs/tasks/administer-cluster/reserve-compute-resources/#system-reserved">为系统守护进程预留资源</a>。</p></blockquote><h1 id="控制面到节点通信"><a href="#控制面到节点通信" class="headerlink" title="控制面到节点通信"></a>控制面到节点通信</h1><h2 id="节点到控制面"><a href="#节点到控制面" class="headerlink" title="节点到控制面"></a>节点到控制面</h2><p>Kubernetes 采用的是中心辐射型（Hub-and-Spoke）API 模式。 所有从集群（或所运行的 Pods）发出的 API 调用都终止于 apiserver。 其它控制面组件都没有被设计为可暴露远程服务。 apiserver 被配置为在一个安全的 HTTPS 端口（通常为 443）上监听远程连接请求， 并启用一种或多种形式的客户端<a href="https://kubernetes.io/zh/docs/reference/access-authn-authz/authentication/">身份认证</a>机制。 一种或多种客户端<a href="https://kubernetes.io/zh/docs/reference/access-authn-authz/authorization/">鉴权机制</a>应该被启用， 特别是在允许使用<a href="https://kubernetes.io/zh/docs/reference/access-authn-authz/authentication/#anonymous-requests">匿名请求</a> 或<a href="https://kubernetes.io/zh/docs/reference/access-authn-authz/authentication/#service-account-tokens">服务账号令牌</a>的时候。</p><p>应该使用集群的公共根证书开通节点，这样它们就能够基于有效的客户端凭据安全地连接 apiserver。 一种好的方法是以客户端证书的形式将客户端凭据提供给 kubelet。 请查看 <a href="https://kubernetes.io/zh/docs/reference/command-line-tools-reference/kubelet-tls-bootstrapping/">kubelet TLS 启动引导</a> 以了解如何自动提供 kubelet 客户端证书。</p><p>想要连接到 apiserver 的 Pod 可以使用服务账号安全地进行连接。 当 Pod 被实例化时，Kubernetes 自动把公共根证书和一个有效的持有者令牌注入到 Pod 里。 <code>kubernetes</code> 服务（位于 <code>default</code> 名字空间中）配置了一个虚拟 IP 地址，用于（通过 kube-proxy）转发 请求到 apiserver 的 HTTPS 末端。</p><p>控制面组件也通过安全端口与集群的 apiserver 通信。</p><p>这样，从集群节点和节点上运行的 Pod 到控制面的连接的缺省操作模式即是安全的， 能够在不可信的网络或公网上运行。</p><h2 id="控制面到节点"><a href="#控制面到节点" class="headerlink" title="控制面到节点"></a>控制面到节点</h2><p>从控制面（apiserver）到节点有两种主要的通信路径。 第一种是从 apiserver 到集群中每个节点上运行的 kubelet 进程。 第二种是从 apiserver 通过它的代理功能连接到任何节点、Pod 或者服务。</p><h3 id="API-服务器到-kubelet"><a href="#API-服务器到-kubelet" class="headerlink" title="API 服务器到 kubelet"></a>API 服务器到 kubelet</h3><p>从 apiserver 到 kubelet 的连接用于：</p><ul><li>获取 Pod 日志</li><li>挂接（通过 kubectl）到运行中的 Pod</li><li>提供 kubelet 的端口转发功能。</li></ul><p>这些连接终止于 kubelet 的 HTTPS 末端。 默认情况下，apiserver 不检查 kubelet 的服务证书。这使得此类连接容易受到中间人攻击， 在非受信网络或公开网络上运行也是 <strong>不安全的</strong>。</p><p>为了对这个连接进行认证，使用 <code>--kubelet-certificate-authority</code> 标志给 apiserver 提供一个根证书包，用于 kubelet 的服务证书。</p><p>如果无法实现这点，又要求避免在非受信网络或公共网络上进行连接，可在 apiserver 和 kubelet 之间使用 <a href="https://kubernetes.io/zh/docs/concepts/architecture/control-plane-node-communication/#ssh-tunnels">SSH 隧道</a>。</p><p>最后，应该启用 <a href="https://kubernetes.io/zh/docs/reference/command-line-tools-reference/kubelet-authentication-authorization/">kubelet 用户认证和/或鉴权</a> 来保护 kubelet API。</p><h3 id="apiserver-到节点、Pod-和服务"><a href="#apiserver-到节点、Pod-和服务" class="headerlink" title="apiserver 到节点、Pod 和服务"></a>apiserver 到节点、Pod 和服务</h3><p>从 apiserver 到节点、Pod 或服务的连接默认为纯 HTTP 方式，因此既没有认证，也没有加密。 这些连接可通过给 API URL 中的节点、Pod 或服务名称添加前缀 <code>https:</code> 来运行在安全的 HTTPS 连接上。 不过这些连接既不会验证 HTTPS 末端提供的证书，也不会提供客户端证书。 因此，虽然连接是加密的，仍无法提供任何完整性保证。 这些连接 <strong>目前还不能安全地</strong> 在非受信网络或公共网络上运行。</p><h3 id="SSH-隧道"><a href="#SSH-隧道" class="headerlink" title="SSH 隧道"></a>SSH 隧道</h3><p>Kubernetes 支持使用 SSH 隧道来保护从控制面到节点的通信路径。在这种配置下，apiserver 建立一个到集群中各节点的 SSH 隧道（连接到在 22 端口监听的 SSH 服务） 并通过这个隧道传输所有到 kubelet、节点、Pod 或服务的请求。 这一隧道保证通信不会被暴露到集群节点所运行的网络之外。</p><p>SSH 隧道目前已被废弃。除非你了解个中细节，否则不应使用。 Konnectivity 服务是对此通信通道的替代品。</p><h1 id="控制器"><a href="#控制器" class="headerlink" title="控制器"></a>控制器</h1><p>在 Kubernetes 中，控制器通过监控<a href="https://kubernetes.io/zh/docs/reference/glossary/?all=true#term-cluster">集群</a> 的公共状态，并致力于将当前状态转变为期望的状态。</p><h2 id="控制器模式"><a href="#控制器模式" class="headerlink" title="控制器模式"></a>控制器模式</h2><p>一个控制器至少追踪一种类型的 Kubernetes 资源。这些 <a href="https://kubernetes.io/zh/docs/concepts/overview/working-with-objects/kubernetes-objects/">对象</a> 有一个代表期望状态的 <code>spec</code> 字段。 该资源的控制器负责确保其当前状态接近期望状态。</p><p>控制器可能会自行执行操作；在 Kubernetes 中更常见的是一个控制器会发送信息给 <a href="https://kubernetes.io/zh/docs/reference/command-line-tools-reference/kube-apiserver/">API 服务器</a>，这会有副作用。 具体可参看后文的例子。</p><h3 id="通过-API-服务器来控制"><a href="#通过-API-服务器来控制" class="headerlink" title="通过 API 服务器来控制"></a>通过 API 服务器来控制</h3><p><a href="https://kubernetes.io/zh/docs/concepts/workloads/controllers/job/">Job</a> (任务)控制器是一个 Kubernetes 内置控制器的例子。 内置控制器通过和集群 API 服务器交互来管理状态。</p><p>Job 是一种 Kubernetes 资源，它运行一个或者多个 <a href="https://kubernetes.io/docs/concepts/workloads/pods/pod-overview/">Pod</a>， 来执行一个任务然后停止。 （一旦<a href="https://kubernetes.io/zh/docs/concepts/scheduling-eviction/">被调度了</a>，对 <code>kubelet</code> 来说 Pod 对象就会变成了期望状态的一部分）。</p><p>在集群中，当 Job 控制器拿到新任务时，它会保证一组 Node 节点上的 <code>kubelet</code> 可以运行正确数量的 Pod 来完成工作。 Job 控制器不会自己运行任何的 Pod 或者容器。Job 控制器是通知 API 服务器来创建或者移除 Pod。 <a href="https://kubernetes.io/zh/docs/reference/glossary/?all=true#term-control-plane">控制面</a>中的其它组件 根据新的消息作出反应（调度并运行新 Pod）并且最终完成工作。</p><p>创建新 Job 后，所期望的状态就是完成这个 Job。Job 控制器会让 Job 的当前状态不断接近期望状态：创建为 Job 要完成工作所需要的 Pod，使 Job 的状态接近完成。</p><p>控制器也会更新配置对象。例如：一旦 Job 的工作完成了，Job 控制器会更新 Job 对象的状态为 <code>Finished</code>。</p><h3 id="直接控制"><a href="#直接控制" class="headerlink" title="直接控制"></a>直接控制</h3><p>相比 Job 控制器，有些控制器<strong>需要对集群外的一些东西进行修改</strong>。</p><p>例如，如果你使用一个控制回路来保证集群中有足够的 <a href="https://kubernetes.io/zh/docs/concepts/architecture/nodes/">节点</a>，那么控制器就需要当前集群外的 一些服务在需要时创建新节点。</p><p>和外部状态交互的控制器从 API 服务器获取到它想要的状态，然后直接和外部系统进行通信 并使当前状态更接近期望状态。</p><p>（实际上有一个<a href="https://github.com/kubernetes/autoscaler/">控制器</a> 可以水平地扩展集群中的节点。）</p><p>这里，很重要的一点是，控制器做出了一些变更以使得事物更接近你的期望状态， 之后将当前状态报告给集群的 API 服务器。 其他控制回路可以观测到所汇报的数据的这种变化并采取其各自的行动。</p><h2 id="期望状态与当前状态"><a href="#期望状态与当前状态" class="headerlink" title="期望状态与当前状态"></a>期望状态与当前状态</h2><p>Kubernetes 采用了系统的云原生视图，并且可以处理持续的变化。</p><p>在任务执行时，集群随时都可能被修改，并且控制回路会自动修复故障。 这意味着很可能集群永远不会达到稳定状态。</p><p>只要集群中的控制器在运行并且进行有效的修改，整体状态的稳定与否是无关紧要的。</p><h2 id="运行控制器的方式"><a href="#运行控制器的方式" class="headerlink" title="运行控制器的方式"></a>运行控制器的方式</h2><p>Kubernetes 内置一组控制器，运行在 <a href="https://kubernetes.io/docs/reference/generated/kube-controller-manager/">kube-controller-manager</a> 内。 这些内置的控制器提供了重要的核心功能。</p><p>Deployment 控制器和 Job 控制器是 Kubernetes 内置控制器的典型例子。 Kubernetes 允许你运行一个稳定的控制平面，这样即使某些内置控制器失败了， 控制平面的其他部分会接替它们的工作。</p><p>你会遇到某些控制器运行在控制面之外，用以扩展 Kubernetes。 或者，如果你愿意，你也可以自己编写新控制器。 你可以以一组 Pod 来运行你的控制器，或者运行在 Kubernetes 之外。 最合适的方案取决于控制器所要执行的功能是什么。</p><h1 id="云控制器管理器"><a href="#云控制器管理器" class="headerlink" title="云控制器管理器"></a>云控制器管理器</h1><p>使用云基础设施技术，你可以在公有云、私有云或者混合云环境中运行 Kubernetes。 Kubernetes 的信条是基于自动化的、API 驱动的基础设施，同时避免组件间紧密耦合。</p><p>组件 cloud-controller-manager 是指云控制器管理器， 云控制器管理器是指嵌入特定云的控制逻辑的 <a href="https://kubernetes.io/zh/docs/reference/glossary/?all=true#term-control-plane">控制平面</a>组件。 云控制器管理器使得你可以将你的集群连接到云提供商的 API 之上， 并将与该云平台交互的组件同与你的集群交互的组件分离开来。</p><p>通过分离 Kubernetes 和底层云基础设置之间的互操作性逻辑， 云控制器管理器组件使云提供商能够以不同于 Kubernetes 主项目的 步调发布新特征。</p><p><code>cloud-controller-manager</code> 组件是基于一种插件机制来构造的， 这种机制使得不同的云厂商都能将其平台与 Kubernetes 集成。</p><h2 id="设计"><a href="#设计" class="headerlink" title="设计"></a>设计</h2><p><img src="/images/%E5%AD%A6%E4%B9%A0Kubernetes%E7%B3%BB%E5%88%97%E4%B9%8B%E6%A6%82%E5%BF%B5/components-of-kubernetes.svg" alt="components-of-kubernetes"></p><p>云控制器管理器以一组多副本的进程集合的形式运行在控制面中，通常表现为 Pod 中的容器。每个 <code>cloud-controller-manager</code> 在同一进程中实现多个 <a href="https://kubernetes.io/zh/docs/concepts/architecture/controller/">控制器</a>。</p><h3 id="节点控制器-1"><a href="#节点控制器-1" class="headerlink" title="节点控制器"></a>节点控制器</h3><p>节点控制器负责在云基础设施中创建了新服务器时为之 更新 <a href="https://kubernetes.io/zh/docs/concepts/architecture/nodes/">节点（Node）</a>对象。 节点控制器从云提供商获取当前租户中主机的信息。节点控制器执行以下功能：</p><ol><li>使用从云平台 API 获取的对应服务器的唯一标识符更新 Node 对象；</li><li>利用特定云平台的信息为 Node 对象添加注解和标签，例如节点所在的 区域（Region）和所具有的资源（CPU、内存等等）；</li><li>获取节点的网络地址和主机名；</li><li>检查节点的健康状况。如果节点无响应，控制器通过云平台 API 查看该节点是否 已从云中禁用、删除或终止。如果节点已从云中删除，则控制器从 Kubernetes 集群 中删除 Node 对象。</li></ol><p>某些云驱动实现中，这些任务被划分到一个节点控制器和一个节点生命周期控制器中。</p><h3 id="路由控制器"><a href="#路由控制器" class="headerlink" title="路由控制器"></a>路由控制器</h3><p>Route 控制器负责适当地配置云平台中的路由，以便 Kubernetes 集群中不同节点上的 容器之间可以相互通信。</p><p>取决于云驱动本身，路由控制器可能也会为 Pod 网络分配 IP 地址块。</p><h3 id="服务控制器"><a href="#服务控制器" class="headerlink" title="服务控制器"></a>服务控制器</h3><p><a href="https://kubernetes.io/zh/docs/concepts/services-networking/service/">服务（Service）</a>与受控的负载均衡器、 IP 地址、网络包过滤、目标健康检查等云基础设施组件集成。 服务控制器与云驱动的 API 交互，以配置负载均衡器和其他基础设施组件。 你所创建的 Service 资源会需要这些组件服务。</p><h2 id="鉴权"><a href="#鉴权" class="headerlink" title="鉴权"></a>鉴权</h2><p>本节分别讲述云控制器管理器为了完成自身工作而产生的对各类 API 对象的访问需求。</p><h3 id="节点控制器-2"><a href="#节点控制器-2" class="headerlink" title="节点控制器"></a>节点控制器</h3><p>节点控制器只操作 Node 对象。它需要读取和修改 Node 对象的完全访问权限。</p><p><code>v1/Node</code>:</p><ul><li>Get</li><li>List</li><li>Create</li><li>Update</li><li>Patch</li><li>Watch</li><li>Delete</li></ul><h3 id="路由控制器-1"><a href="#路由控制器-1" class="headerlink" title="路由控制器"></a>路由控制器</h3><p>路由控制器会监听 Node 对象的创建事件，并据此配置路由设施。 它需要读取 Node 对象的 Get 权限。</p><p><code>v1/Node</code>:</p><ul><li>Get</li></ul><h3 id="服务控制器-1"><a href="#服务控制器-1" class="headerlink" title="服务控制器"></a>服务控制器</h3><p>服务控制器监测 Service 对象的 Create、Update 和 Delete 事件，并配置 对应服务的 Endpoints 对象。 为了访问 Service 对象，它需要 List、Watch 访问权限；为了更新 Service 对象 它需要 Patch 和 Update 访问权限。 为了能够配置 Service 对应的 Endpoints 资源，它需要 Create、List、Get、Watch 和 Update 等访问权限。</p><p><code>v1/Service</code>:</p><ul><li>List</li><li>Get</li><li>Watch</li><li>Patch</li><li>Update</li></ul><h3 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h3><p>云控制器管理器的实现中，其核心部分需要创建 Event 对象的访问权限以及 创建 ServiceAccount 资源以保证操作安全性的权限。</p><p><code>v1/Event</code>:</p><ul><li>Create</li><li>Patch</li><li>Update</li></ul><p><code>v1/ServiceAccount</code>:</p><ul><li>Create</li></ul><p>用于云控制器管理器 <a href="https://kubernetes.io/zh/docs/reference/access-authn-authz/rbac/">RBAC</a> 的 ClusterRole 如下例所示：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ClusterRole</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">cloud-controller-manager</span></span><br><span class="line"><span class="attr">rules:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">apiGroups:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">&quot;&quot;</span></span><br><span class="line">  <span class="attr">resources:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">events</span></span><br><span class="line">  <span class="attr">verbs:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">create</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">patch</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">update</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">apiGroups:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">&quot;&quot;</span></span><br><span class="line">  <span class="attr">resources:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">nodes</span></span><br><span class="line">  <span class="attr">verbs:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">&#x27;*&#x27;</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">apiGroups:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">&quot;&quot;</span></span><br><span class="line">  <span class="attr">resources:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">nodes/status</span></span><br><span class="line">  <span class="attr">verbs:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">patch</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">apiGroups:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">&quot;&quot;</span></span><br><span class="line">  <span class="attr">resources:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">services</span></span><br><span class="line">  <span class="attr">verbs:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">list</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">patch</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">update</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">watch</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">apiGroups:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">&quot;&quot;</span></span><br><span class="line">  <span class="attr">resources:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">serviceaccounts</span></span><br><span class="line">  <span class="attr">verbs:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">create</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">apiGroups:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">&quot;&quot;</span></span><br><span class="line">  <span class="attr">resources:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">persistentvolumes</span></span><br><span class="line">  <span class="attr">verbs:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">get</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">list</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">update</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">watch</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">apiGroups:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">&quot;&quot;</span></span><br><span class="line">  <span class="attr">resources:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">endpoints</span></span><br><span class="line">  <span class="attr">verbs:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">create</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">get</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">list</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">watch</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">update</span></span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">&lt;p&gt;此章节主要讲述k8s中架构中的几个主要部分：节点、控制面到节点的通信、控制器、云控制器管理器、CRI及GC。&lt;/p&gt;</summary>
    
    
    
    
    <category term="Kubernetes" scheme="http://chengqian90.com/tags/Kubernetes/"/>
    
    <category term="k8s" scheme="http://chengqian90.com/tags/k8s/"/>
    
  </entry>
  
  <entry>
    <title>学习Kubernetes系列1——概述</title>
    <link href="http://chengqian90.com/%E5%AE%B9%E5%99%A8/%E5%AD%A6%E4%B9%A0Kubernetes%E7%B3%BB%E5%88%971%E2%80%94%E2%80%94%E6%A6%82%E8%BF%B0.html"/>
    <id>http://chengqian90.com/%E5%AE%B9%E5%99%A8/%E5%AD%A6%E4%B9%A0Kubernetes%E7%B3%BB%E5%88%971%E2%80%94%E2%80%94%E6%A6%82%E8%BF%B0.html</id>
    <published>2021-05-05T01:57:52.000Z</published>
    <updated>2022-03-08T16:23:40.434Z</updated>
    
    <content type="html"><![CDATA[<p>终于下定决心搞清楚k8s的架构、原理，本blog k8s系列文章仅做浏览官网时的笔记，同样需要学习k8s的同学，可以直接去 <a href="https://kubernetes.io/zh/docs/concepts/">Kubernetes官网</a>查看各种文档。</p><h1 id="Kubernetes-是什么？"><a href="#Kubernetes-是什么？" class="headerlink" title="Kubernetes 是什么？"></a>Kubernetes 是什么？</h1><p>Kubernetes 是一个可移植的、可扩展的开源平台，用于<strong>管理容器化的工作负载和服务</strong>，可促进声明式配置和自动化。 Kubernetes 拥有一个庞大且快速增长的生态系统。Kubernetes 的服务、支持和工具广泛可用。</p><span id="more"></span><h2 id="容器技术发展"><a href="#容器技术发展" class="headerlink" title="容器技术发展"></a>容器技术发展</h2><p><img src="/images/%E5%AD%A6%E4%B9%A0Kubernetes%E7%B3%BB%E5%88%97%E4%B9%8B%E6%A6%82%E5%BF%B5/container_evolution.svg" alt="container_evolution"></p><p><strong>传统部署时代：</strong></p><p>早期，应用程序运行于物理服务器上，但是无法为应用程序定义资源边界，这会导致资源分配问题。</p><ul><li><strong>资源不足</strong>：多个应用程序运行于单台物理服务器，可能会出现一个程序占用大部分资源的情况， 结果可能导致其他程序的性能下降。 </li><li><strong>资源过剩</strong>：多个应用程序运行于多台物理服务器，可能导致资源利用不足而无法扩展， 并且维护许多物理服务器的成本很高。</li></ul><p><strong>虚拟化部署时代：</strong></p><p>作为解决方案，引入了虚拟化。虚拟化技术允许在单个物理服务器的 CPU 上运行多个虚拟机（VM）。 虚拟化允许应用程序在 VM 之间隔离，并提供一定程度的安全，因为一个应用程序的信息 不能被另一应用程序随意访问。</p><p>虚拟化技术能够更好地利用物理服务器上的资源，并且因为可轻松地添加或更新应用程序 而可以实现更好的可伸缩性，降低硬件成本等等。</p><p>每个 VM 是一台完整的计算机，在虚拟化硬件之上<strong>运行所有组件，包括其自己的操作系统</strong>。</p><p><strong>容器部署时代：</strong></p><p>容器类似于 VM，但是它们具有被放宽的隔离属性，可以在应用程序之间共享操作系统（OS）。因此，容器被认为是轻量级的。</p><p>容器与 VM 类似，具有自己的文件系统、CPU、内存、进程空间等。 由于它们与基础架构分离，因此可以跨云和 OS 发行版本进行移植。</p><p>容器因具有许多优势而变得流行起来。下面列出的是容器的一些好处：</p><ul><li>敏捷应用程序的创建和部署：与使用 VM 镜像相比，提高了容器镜像创建的简便性和效率。</li><li>持续开发、集成和部署：通过快速简单的回滚（由于镜像不可变性），支持可靠且频繁的 容器镜像构建和部署。</li><li>关注开发与运维的分离：在<strong>构建/发布</strong>时而不是在部署时创建应用程序容器镜像， 从而将应用程序与基础架构分离。</li><li>可观察性：不仅可以显示操作系统级别的信息和指标，还可以显示应用程序的运行状况和其他指标信号。</li><li>跨开发、测试和生产的环境一致性：在便携式计算机上与在云中相同地运行。</li><li>跨云和操作系统发行版本的可移植性：可在 Ubuntu、RHEL、CoreOS、本地、 Google Kubernetes Engine 和其他任何地方运行。</li><li>以应用程序为中心的管理：提高抽象级别，从在虚拟硬件上运行 OS 到使用逻辑资源在 OS 上运行应用程序。</li><li>松散耦合、分布式、弹性、解放的微服务：应用程序被分解成较小的独立部分， 并且可以动态部署和管理 - 而不是在一台大型单机上整体运行。</li><li>资源隔离：可预测的应用程序性能。</li><li>资源利用：高效率和高密度。</li></ul><h1 id="Kubernetes-能做什么？"><a href="#Kubernetes-能做什么？" class="headerlink" title="Kubernetes 能做什么？"></a>Kubernetes 能做什么？</h1><p>容器是打包和运行应用程序的好方式。在生产环境中，需要管理运行应用程序的容器，并确保服务不会停机（容器故障，需要新启动容器）。</p><p>Kubernetes 提供了一个<strong>可弹性运行分布式系统的框架</strong>。 Kubernetes 会满足你的扩展要求、故障转移、部署模式等。</p><ul><li><p><strong>服务发现和负载均衡</strong></p><p>Kubernetes 可以使用 DNS 名称或自己的 IP 地址公开容器，如果进入容器的流量很大， Kubernetes 可以负载均衡并分配网络流量，从而使部署稳定。</p></li><li><p><strong>存储编排</strong></p><p>Kubernetes 允许你自动挂载你选择的存储系统，例如本地存储、公共云提供商等。</p></li><li><p><strong>自动部署和回滚</strong></p><p>你可以使用 Kubernetes 描述已部署容器的所需状态，它可以以受控的速率将实际状态 更改为期望状态。例如，你可以自动化 Kubernetes 来为你的部署创建新容器， 删除现有容器并将它们的所有资源用于新容器。</p></li><li><p><strong>自动完成装箱计算</strong></p><p>Kubernetes 允许你指定每个容器所需 CPU 和内存（RAM）。 当容器指定了资源请求时，Kubernetes 可以做出更好的决策来管理容器的资源。</p></li><li><p><strong>自我修复</strong></p><p>Kubernetes 重新启动失败的容器、替换容器、杀死不响应用户定义的 运行状况检查的容器，并且在准备好服务之前不将其通告给客户端。</p></li><li><p><strong>密钥与配置管理</strong></p><p>Kubernetes 允许你存储和管理敏感信息，例如密码、OAuth 令牌和 ssh 密钥。 你可以在不重建容器镜像的情况下部署和更新密钥和应用程序配置，也无需在堆栈配置中暴露密钥。</p></li></ul><h1 id="Kubernetes-组件"><a href="#Kubernetes-组件" class="headerlink" title="Kubernetes 组件"></a>Kubernetes 组件</h1><p>先提前熟悉两个概念，**Pod和节点(Node)**。</p><p><em>Pod</em> 是可以在 Kubernetes 中创建和管理的、<strong>最小的可部署的计算单元</strong>。是 Kubernetes 抽象出来的，表示一组（<strong>一个或多个</strong>）应用程序容器（如 Docker），以及这些容器的一些共享资源。这些资源包括:</p><ul><li>共享存储，当作卷</li><li>网络，作为唯一的集群 IP 地址</li><li>有关每个容器如何运行的信息，例如容器映像版本或要使用的特定端口。</li></ul><p>Pod 中的容器<strong>共享 IP 地址和端口</strong>，始终位于<strong>同一位置并且共同调度</strong>，并在<strong>同一工作节点上的共享上下文中运行</strong>。</p><p>在 Kubernetes 上创建 Deployment 时，该 Deployment 会在其中创建包含容器的 Pod （而不是直接创建容器）。每个 Pod 都与调度它的工作节点绑定，并保持在那里直到终止（根据重启策略）或删除。 如果工作节点发生故障，则会在群集中的其他可用工作节点上调度相同的 Pod。</p><p><img src="/images/%E5%AD%A6%E4%B9%A0Kubernetes%E7%B3%BB%E5%88%97%E4%B9%8B%E6%A6%82%E5%BF%B5/module_03_pods.svg" alt="module_03_pods"></p><p><strong>节点</strong>可以是一个虚拟机或者物理机器，取决于所在的集群配置。</p><p>一个 pod 总是运行在 <strong>工作节点</strong>。工作节点是 Kubernetes 中的参与计算的机器，可以是虚拟机或物理计算机，具体取决于集群。每个工作节点由主节点管理。工作节点可以有多个 pod ，Kubernetes 主节点会自动处理在群集中的工作节点上调度 pod 。 主节点的自动调度考量了每个工作节点上的可用资源。</p><p>每个 Kubernetes 工作节点至少运行：</p><ul><li>Kubelet，负责 Kubernetes 主节点和工作节点之间通信的过程; 它管理 Pod 和机器上运行的容器。</li><li>Container runtime（如 Docker）负责从仓库中提取容器镜像，解压缩容器以及运行应用程序。</li></ul><p><img src="/images/%E5%AD%A6%E4%B9%A0Kubernetes%E7%B3%BB%E5%88%97%E4%B9%8B%E6%A6%82%E5%BF%B5/module_03_nodes.svg" alt="module_03_nodes"></p><p>所以，<strong>节点并不等于Pod，一个节点可以有多个Pod，一个Pod是一组（一个或多个）（共享资源的）容器</strong>。</p><p>正式开始组件概念学习。</p><p>一个 Kubernetes 集群由<strong>一组</strong>被称作<strong>节点</strong>的机器组成。这些节点上运行 Kubernetes 所管理的<strong>容器化应用</strong>。集群具有至少一个工作节点。</p><p>工作节点托管作为应用负载的组件的 Pod 。控制平面管理集群中的工作节点和 Pod 。 为集群提供故障转移和高可用性，这些控制平面一般跨多主机运行，集群跨多个节点运行。</p><p><img src="/images/%E5%AD%A6%E4%B9%A0Kubernetes%E7%B3%BB%E5%88%97%E4%B9%8B%E6%A6%82%E5%BF%B5/Kubernetes%E9%9B%86%E7%BE%A4%E7%9A%84%E7%BB%84%E4%BB%B6.svg" alt="Kubernetes集群的组件"></p><h2 id="控制面组件（Control-Plane-Components）"><a href="#控制面组件（Control-Plane-Components）" class="headerlink" title="控制面组件（Control Plane Components）"></a>控制面组件（Control Plane Components）</h2><p>控制平面的组件对集群做出全局决策(比如调度)，以及检测和响应集群事件（例如，当不满足部署的 <code>replicas</code> 字段时，启动新的pod）。</p><p>控制平面组件<strong>可以在集群中的任何节点上运行</strong>。通常会在同一个服务器上启动所有控制平面组件， 并且不会在此计算机上运行用户容器。（管理、业务分离）</p><p>请参阅<a href="https://kubernetes.io/zh/docs/setup/production-environment/tools/kubeadm/high-availability/">使用 kubeadm 构建高可用性集群</a> 中关于多 VM 控制平面设置的示例。</p><h3 id="kube-apiserver"><a href="#kube-apiserver" class="headerlink" title="kube-apiserver"></a>kube-apiserver</h3><p>API server作为 Kubernetes 控制面的前端，公开了 Kubernetes API。 <a href="https://kubernetes.io/zh/docs/reference/command-line-tools-reference/kube-apiserver/">kube-apiserver</a> 是Kubernetes API server的主要实现。</p><p>kube-apiserver 设计上考虑了水平伸缩，可以运行 kube-apiserver 的多个实例，并在这些实例之间平衡流量。</p><h3 id="etcd"><a href="#etcd" class="headerlink" title="etcd"></a>etcd</h3><p>etcd 是兼具<strong>一致性</strong>和<strong>高可用性</strong>的键值数据库，可以作为保存 Kubernetes 所有集群数据的后台数据库。</p><p>如果使用etcd作为 Kubernetes 集群的存储后台，请确保为etcd制定<a href="https://kubernetes.io/zh/docs/tasks/administer-cluster/configure-upgrade-etcd/#%E5%A4%87%E4%BB%BD-etcd-%E9%9B%86%E7%BE%A4">备份计划</a>。</p><p>要了解 etcd 更深层次的信息，请参考 <a href="https://etcd.io/docs/">etcd 文档</a>。</p><h3 id="kube-scheduler"><a href="#kube-scheduler" class="headerlink" title="kube-scheduler"></a>kube-scheduler</h3><p>控制面组件，负责<strong>监视</strong>新创建的、未指定运行<a href="https://kubernetes.io/zh/docs/concepts/architecture/nodes/">节点（node）</a>的 <a href="https://kubernetes.io/docs/concepts/workloads/pods/pod-overview/">Pods</a>，选择节点让 Pod 在上面运行。</p><p><strong>调度决策</strong>考虑的因素包括单个 Pod 和 Pod 集合的资源需求、硬件/软件/策略约束、亲和性和反亲和性规范、数据位置、工作负载间的干扰和最后时限。</p><h3 id="kube-controller-manager"><a href="#kube-controller-manager" class="headerlink" title="kube-controller-manager"></a>kube-controller-manager</h3><p>运行<a href="https://kubernetes.io/zh/docs/concepts/architecture/controller/">控制器</a>进程的控制面组件。</p><p>从逻辑上讲，每个<a href="https://kubernetes.io/zh/docs/concepts/architecture/controller/">控制器</a>都是一个单独的进程， 但是为了降低复杂性，它们都被编译到同一个可执行文件，并在一个进程中运行。</p><p>这些控制器包括:</p><ul><li>节点控制器（Node Controller）: 负责在<strong>节点出现故障时进行通知和响应</strong></li><li>任务控制器（Job controller）: 监测代表一次性任务的 Job 对象，然后创建 Pods 来运行这些任务直至完成</li><li>端点控制器（Endpoints Controller）: 填充端点(Endpoints)对象(即加入 Service 与 Pod)</li><li>服务帐户和令牌控制器（Service Account &amp; Token Controllers）: 为新的命名空间创建默认帐户和 API 访问令牌</li></ul><h3 id="cloud-controller-manager"><a href="#cloud-controller-manager" class="headerlink" title="cloud-controller-manager"></a>cloud-controller-manager</h3><p>云控制器管理器是指嵌入特定云的控制逻辑的 <a href="https://kubernetes.io/zh/docs/reference/glossary/?all=true#term-control-plane">控制平面</a>组件。 cloud-controller-manager使得你可以将你的<strong>集群连接到云提供商的 API 之上</strong>， 并将与该云平台交互的组件同与你的集群交互的组件分离开来。</p><p><code>cloud-controller-manager</code> 仅运行特定于云平台的控制回路。 如果你在自己的环境中运行 Kubernetes，或者在本地计算机中运行学习环境， 所部署的环境中不需要云控制器管理器。</p><p>与 <code>kube-controller-manager</code> 类似，<code>cloud-controller-manager</code> 将若干逻辑上独立的 控制回路组合到同一个可执行文件中，供你以同一进程的方式运行。 你可以对其执行水平扩容（运行不止一个副本）以提升性能或者增强容错能力。</p><p>下面的控制器都包含对云平台驱动的依赖：</p><ul><li>节点控制器（Node Controller）: 用于在节点终止响应后检查云提供商以确定节点是否已被删除</li><li>路由控制器（Route Controller）: 用于在底层云基础架构中设置路由</li><li>服务控制器（Service Controller）: 用于创建、更新和删除云提供商负载均衡器.</li></ul><h2 id="Node-组件"><a href="#Node-组件" class="headerlink" title="Node 组件"></a>Node 组件</h2><p>节点组件在每个节点上运行，维护运行的 Pod 并提供 Kubernetes 运行环境。</p><h3 id="kubelet"><a href="#kubelet" class="headerlink" title="kubelet"></a>kubelet</h3><p>一个在集群中每个节点（node）上运行的代理。 它保证容器（containers）都运行在 Pod中。</p><p>kubelet 接收一组通过各类机制提供给它的 <strong>PodSpecs</strong>，确保这些 PodSpecs 中描述的容器处于运行状态且健康。</p><p>kubelet 不会管理不是由 Kubernetes 创建的容器。</p><h3 id="kube-proxy"><a href="#kube-proxy" class="headerlink" title="kube-proxy"></a>kube-proxy</h3><p><a href="https://kubernetes.io/zh/docs/reference/command-line-tools-reference/kube-proxy/">kube-proxy</a> 是集群中每个节点上运行的网络代理， 实现 Kubernetes <a href="https://kubernetes.io/zh/docs/concepts/services-networking/service/">服务（Service）</a> 概念的一部分。</p><p>kube-proxy <strong>维护节点上的网络规则</strong>。这些网络规则允许从集群内部或外部的网络会话与 Pod 进行网络通信。</p><p>如果操作系统提供了数据包过滤层并可用的话，kube-proxy 会通过它来实现网络规则。否则， kube-proxy 仅转发流量本身。</p><h3 id="容器运行时（Container-Runtime）"><a href="#容器运行时（Container-Runtime）" class="headerlink" title="容器运行时（Container Runtime）"></a>容器运行时（Container Runtime）</h3><p>容器运行环境是负责运行容器的软件。</p><p>Kubernetes 支持多个容器运行环境: <a href="https://kubernetes.io/zh/docs/reference/kubectl/docker-cli-to-kubectl/">Docker</a>、 <a href="https://containerd.io/docs/">containerd</a>、<a href="https://cri-o.io/#what-is-cri-o">CRI-O</a> 以及任何实现 <a href="https://github.com/kubernetes/community/blob/master/contributors/devel/sig-node/container-runtime-interface.md">Kubernetes CRI (容器运行环境接口)</a>。</p><h2 id="插件（Addons）"><a href="#插件（Addons）" class="headerlink" title="插件（Addons）"></a>插件（Addons）</h2><p>插件使用 Kubernetes 资源（<a href="https://kubernetes.io/zh/docs/concepts/workloads/controllers/daemonset/">DaemonSet</a>、 <a href="https://kubernetes.io/zh/docs/concepts/workloads/controllers/deployment/">Deployment</a>等）实现集群功能。 因为这些插件提供集群级别的功能，插件中命名空间域的资源属于 <code>kube-system</code> 命名空间。</p><p>下面描述众多插件中的几种。有关可用插件的完整列表，请参见 <a href="https://kubernetes.io/zh/docs/concepts/cluster-administration/addons/">插件（Addons）</a>。</p><h3 id="DNS"><a href="#DNS" class="headerlink" title="DNS"></a>DNS</h3><p>尽管其他插件都并非严格意义上的必需组件，但几乎所有 Kubernetes 集群都应该 有<a href="https://kubernetes.io/zh/docs/concepts/services-networking/dns-pod-service/">集群 DNS</a>， 因为很多示例都需要 DNS 服务。</p><p>集群 DNS 是一个 DNS 服务器，和环境中的其他 DNS 服务器一起工作，它为 Kubernetes 服务提供 DNS 记录。</p><p>Kubernetes 启动的容器自动将此 DNS 服务器包含在其 DNS 搜索列表中。</p><h3 id="Web-界面（仪表盘）"><a href="#Web-界面（仪表盘）" class="headerlink" title="Web 界面（仪表盘）"></a>Web 界面（仪表盘）</h3><p><a href="https://kubernetes.io/zh/docs/tasks/access-application-cluster/web-ui-dashboard/">Dashboard</a> 是 Kubernetes 集群的通用的、基于 Web 的用户界面。 它使用户可以管理集群中运行的应用程序以及集群本身并进行故障排除。</p><h3 id="容器资源监控"><a href="#容器资源监控" class="headerlink" title="容器资源监控"></a>容器资源监控</h3><p><a href="https://kubernetes.io/zh/docs/tasks/debug-application-cluster/resource-usage-monitoring/">容器资源监控</a> 将关于容器的一些常见的时间序列度量值保存到一个集中的数据库中，并提供用于浏览这些数据的界面。</p><h3 id="集群层面日志"><a href="#集群层面日志" class="headerlink" title="集群层面日志"></a>集群层面日志</h3><p><a href="https://kubernetes.io/zh/docs/concepts/cluster-administration/logging/">集群层面日志</a> 机制负责将容器的日志数据 保存到一个集中的日志存储中，该存储能够提供搜索和浏览接口。</p><h1 id="Kubernetes-对象"><a href="#Kubernetes-对象" class="headerlink" title="Kubernetes 对象"></a>Kubernetes 对象</h1><p>在 Kubernetes 系统中，<em>Kubernetes 对象</em> 是<strong>持久化的实体</strong>。 Kubernetes 使用这些实体去<strong>表示整个集群的状态</strong>。特别地，它们描述了如下信息：</p><ul><li>哪些容器化应用在运行（以及在哪些节点上）</li><li>可以被应用使用的资源</li><li>关于应用运行时表现的策略，比如重启策略、升级策略，以及容错策略</li></ul><p>Kubernetes 对象是 “目标性记录” —— <strong>一旦创建对象，Kubernetes 系统将持续工作以确保对象存在</strong>。 通过创建对象，本质上是在告知 Kubernetes 系统，所需要的集群工作负载看起来是什么样子的， 这就是 Kubernetes 集群的 <strong>期望状态（Desired State）</strong>。</p><p>操作 Kubernetes 对象 —— 无论是创建、修改，或者删除 —— 需要使用 <a href="https://kubernetes.io/zh/docs/concepts/overview/kubernetes-api">Kubernetes API</a>。 比如，当使用 <code>kubectl</code> 命令行接口时，CLI 会执行必要的 Kubernetes API 调用， 也可以在程序中使用 <a href="https://kubernetes.io/zh/docs/reference/using-api/client-libraries/">客户端库</a>直接调用 Kubernetes API。</p><h3 id="对象规约（Spec）与状态（Status）"><a href="#对象规约（Spec）与状态（Status）" class="headerlink" title="对象规约（Spec）与状态（Status）"></a>对象规约（Spec）与状态（Status）</h3><p>几乎每个 Kubernetes 对象包含<strong>两个嵌套的对象字段</strong>，它们负责管理对象的配置： 对象 <em><code>spec</code>（规约）</em> 和 对象 <em><code>status</code>（状态）</em> 。</p><p>对于具有 <code>spec</code> 的对象，必须在创建对象时设置其内容，描述希望对象所具有的特征： <em>期望状态（Desired State）</em> 。</p><p><code>status</code> 描述了对象的 <em>当前状态（Current State）</em>，它是由 Kubernetes 系统和组件 设置并更新的。在任何时刻，Kubernetes <a href="https://kubernetes.io/zh/docs/reference/glossary/?all=true#term-control-plane">控制面</a> 都一直积极地管理着对象的实际状态，以使之与期望状态相匹配。</p><p>例如，Kubernetes 中的 Deployment 对象能够表示运行在集群中的应用。 当创建 Deployment 时，可能需要设置 Deployment 的 <code>spec</code>，以指定该应用需要有 3 个副本运行。 Kubernetes 系统读取 Deployment 规约，并启动我们所期望的应用的 3 个实例 —— 更新状态以与规约相匹配。 如果这些实例中有的失败了（一种状态变更），Kubernetes 系统通过执行修正操作 来响应规约和状态间的不一致 —— 在这里意味着它会启动一个新的实例来替换。</p><p>关于对象 spec、status 和 metadata 的更多信息，可参阅 <a href="https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md">Kubernetes API 约定</a>。</p><h3 id="描述-Kubernetes-对象"><a href="#描述-Kubernetes-对象" class="headerlink" title="描述 Kubernetes 对象"></a>描述 Kubernetes 对象</h3><p>创建 Kubernetes 对象时，必须提供对象的规约，用来描述该对象的期望状态， 以及关于对象的一些基本信息（例如名称）。 当使用 Kubernetes API 创建对象时（或者直接创建，或者基于<code>kubectl</code>）， API 请求必须在请求体中包含 JSON 格式的信息。 <strong>大多数情况下，需要在 .yaml 文件中为 <code>kubectl</code> 提供这些信息</strong>。 <code>kubectl</code> 在发起 API 请求时，将这些信息转换成 JSON 格式。</p><p>下面的示例展示了 Kubernetes Deployment 的<strong>必需字段和对象规约</strong></p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">nginx-deployment</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">nginx</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">2</span> <span class="comment"># tells deployment to run 2 pods matching the template</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">nginx</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">nginx:1.14.2</span></span><br><span class="line">        <span class="attr">ports:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span></span><br></pre></td></tr></table></figure><p>使用类似于上面的 <code>.yaml</code> 文件来创建 Deployment的一种方式是使用 <code>kubectl</code> 命令行接口（CLI）中的 <a href="https://kubernetes.io/docs/reference/generated/kubectl/kubectl-commands#apply"><code>kubectl apply</code></a> 命令， 将 <code>.yaml</code> 文件作为参数。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f https://k8s.io/examples/application/deployment.yaml --record</span><br></pre></td></tr></table></figure><p>输出类似如下这样：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">deployment.apps/nginx-deployment created</span><br></pre></td></tr></table></figure><h3 id="必需字段"><a href="#必需字段" class="headerlink" title="必需字段"></a>必需字段</h3><p>在想要创建的 Kubernetes 对象对应的 <code>.yaml</code> 文件中，需要配置如下的字段：</p><ul><li><code>apiVersion</code> - 创建该对象所使用的 Kubernetes API 的版本</li><li><code>kind</code> - 想要创建的对象的类别</li><li><code>metadata</code> - 帮助唯一性标识对象的一些数据，包括一个 <code>name</code> 字符串、UID 和可选的 <code>namespace</code></li><li><code>spec</code> - 你所期望的该对象的状态</li></ul><p>对象 <code>spec</code> 的精确格式对每个 Kubernetes 对象来说是不同的，包含了特定于该对象的嵌套字段。</p><p> <a href="https://kubernetes.io/docs/reference/kubernetes-api/">Kubernetes API 参考</a> 能够帮助我们找到任何我们想创建的对象的规约格式。例如，Pod 参考文档详细说明了 API 中 Pod 的 <a href="https://kubernetes.io/docs/reference/kubernetes-api/workload-resources/pod-v1/#PodSpec"><code>spec</code> 字段</a>， Deployment 的参考文档则详细说明了 Deployment 的 <a href="https://kubernetes.io/docs/reference/kubernetes-api/workload-resources/deployment-v1/#DeploymentSpec"><code>spec</code> 字段</a>。 </p><p>在这些 API 参考页面中，将看到提到的 PodSpec 和 DeploymentSpec。 这些名字是 Kubernetes 用来实现其 API 的 Golang 代码的实现细节。</p><h1 id="Kubernetes-对象管理"><a href="#Kubernetes-对象管理" class="headerlink" title="Kubernetes 对象管理"></a>Kubernetes 对象管理</h1><p><code>kubectl</code> 命令行工具支持多种不同的方式来创建和管理 Kubernetes 对象。阅读 <a href="https://kubectl.docs.kubernetes.io/">Kubectl book</a> 来了解 kubectl 管理对象的详细信息。</p><h2 id="管理技巧"><a href="#管理技巧" class="headerlink" title="管理技巧"></a>管理技巧</h2><blockquote><p>应该只使用一种技术来管理 Kubernetes 对象。混合和匹配技术作用在同一对象上将导致未定义行为。</p></blockquote><table><thead><tr><th>管理技术</th><th>作用于</th><th>建议的环境</th><th>支持的写者</th><th>学习难度</th></tr></thead><tbody><tr><td>指令式命令</td><td>活跃对象</td><td>开发项目</td><td>1+</td><td>最低</td></tr><tr><td>指令式对象配置</td><td>单个文件</td><td>生产项目</td><td>1</td><td>中等</td></tr><tr><td>声明式对象配置</td><td>文件目录</td><td>生产项目</td><td>1+</td><td>最高</td></tr></tbody></table><h2 id="指令式命令"><a href="#指令式命令" class="headerlink" title="指令式命令"></a>指令式命令</h2><p>使用指令式命令时，用户可以在集群中的<strong>活动对象</strong>上进行操作。用户将操作传给 <code>kubectl</code> 命令作为参数或标志。</p><p>这是开始或者在集群中运行一次性任务的推荐方法。因为这个技术直接在活跃对象 上操作，所以它<strong>不提供以前配置的历史记录</strong>。</p><p>通过创建 Deployment 对象来运行 nginx 容器的实例：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl create deployment nginx --image nginx</span><br></pre></td></tr></table></figure><h3 id="权衡"><a href="#权衡" class="headerlink" title="权衡"></a>权衡</h3><p>与对象配置相比的优点：</p><ul><li>命令简单，易学且易于记忆。</li><li>命令仅需一步即可对集群进行更改。</li></ul><p>与对象配置相比的缺点：</p><ul><li>命令不与变更审查流程集成。</li><li>命令不提供与更改关联的审核跟踪。</li><li>除了实时内容外，命令不提供记录源。</li><li>命令不提供用于创建新对象的模板。</li></ul><h2 id="指令式对象配置"><a href="#指令式对象配置" class="headerlink" title="指令式对象配置"></a>指令式对象配置</h2><p>在指令式对象配置中，kubectl 命令指定操作（创建，替换等），可选标志和 至少一个文件名。指定的文件必须包含 YAML 或 JSON 格式的对象的完整定义。</p><blockquote><p><code>replace</code> 指令式命令将现有规范替换为新提供的规范，并放弃对配置文件中 缺少的对象的所有更改。</p><p>此方法不应与 对象规约被独立于配置文件进行更新的资源 类型一起使用。比如类型为 <code>LoadBalancer</code> 的服务，它的 <code>externalIPs</code> 字段就是独立于集群配置进行更新。</p></blockquote><p>创建配置文件中定义的对象：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl create -f nginx.yaml</span><br></pre></td></tr></table></figure><p>删除两个配置文件中定义的对象：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl delete -f nginx.yaml -f redis.yaml</span><br></pre></td></tr></table></figure><p>通过覆盖活动配置来更新配置文件中定义的对象：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl replace -f nginx.yaml</span><br></pre></td></tr></table></figure><h3 id="权衡-1"><a href="#权衡-1" class="headerlink" title="权衡"></a>权衡</h3><p>与指令式命令相比的优点：</p><ul><li>对象配置可以存储在源控制系统中，比如 Git。</li><li>对象配置可以与流程集成，例如在推送和审计之前检查更新。</li><li>对象配置提供了用于创建新对象的模板。</li></ul><p>与指令式命令相比的缺点：</p><ul><li>对象配置需要对对象架构有基本的了解。</li><li>对象配置需要额外的步骤来编写 YAML 文件。</li></ul><p>与声明式对象配置相比的优点：</p><ul><li>指令式对象配置行为更加简单易懂。</li><li>从 Kubernetes 1.5 版本开始，指令对象配置更加成熟。</li></ul><p>与声明式对象配置相比的缺点：</p><ul><li><strong>指令式对象配置更适合文件，而非目录</strong>。</li><li>对活动对象的更新必须反映在配置文件中，否则会在下一次替换时丢失。</li></ul><h2 id="声明式对象配置"><a href="#声明式对象配置" class="headerlink" title="声明式对象配置"></a>声明式对象配置</h2><p>使用声明式对象配置时，用户对本地存储的对象配置文件进行操作，但是用户未定义要对该文件执行的操作。 <code>kubectl</code> 会自动检测每个文件的创建、更新和删除操作。 这使得配置可以在目录上工作，根据目录中配置文件对不同的对象执行不同的操作。</p><blockquote><p>声明式对象配置保留其他编写者所做的修改，即使这些更改并未合并到对象配置文件中。 可以通过使用 <code>patch</code> API 操作仅写入观察到的差异，而不是使用 <code>replace</code> API 操作来替换整个对象配置来实现。</p></blockquote><p>处理 <code>configs</code> 目录中的所有对象配置文件，创建并更新活跃对象。 可以首先使用 <code>diff</code> 子命令查看将要进行的更改，然后在进行应用：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kubectl diff -f configs/</span><br><span class="line">kubectl apply -f configs/</span><br></pre></td></tr></table></figure><p>递归处理目录：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kubectl diff -R -f configs/</span><br><span class="line">kubectl apply -R -f configs/</span><br></pre></td></tr></table></figure><h3 id="权衡-2"><a href="#权衡-2" class="headerlink" title="权衡"></a>权衡</h3><p>与指令式对象配置相比的优点：</p><ul><li>对活动对象所做的更改即使未合并到配置文件中，也会被保留下来。</li><li>声明性对象配置更好地支持对目录进行操作并自动检测每个文件的操作类型（创建，修补，删除）。</li></ul><p>与指令式对象配置相比的缺点：</p><ul><li>声明式对象配置难于调试并且出现异常时结果难以理解。</li><li>使用 diff 产生的部分更新会创建复杂的合并和补丁操作。</li></ul><h1 id="对象名称和-IDs"><a href="#对象名称和-IDs" class="headerlink" title="对象名称和 IDs"></a>对象名称和 IDs</h1><p>集群中的每一个对象都有一个<code>名称</code>来标识在<strong>同类资源</strong>中的唯一性。</p><p>每个 Kubernetes 对象也有一个<code>UID</code>来标识在整个集群中的唯一性。</p><p>比如，在同一个<code>名字空间</code>中有一个名为 <code>myapp-1234</code> 的 Pod, 但是可以命名一个 Pod 和一个 Deployment 同为 <code>myapp-1234</code>.</p><p>对于用户提供的非唯一性的属性，Kubernetes 提供了 标签（Labels）和 注解（Annotation）机制。</p><h2 id="名称"><a href="#名称" class="headerlink" title="名称"></a>名称</h2><p>客户端提供的字符串，引用资源 url 中的对象，如<code>/api/v1/pods/some name</code>。</p><p>某一时刻，只能有一个给定类型的对象具有给定的名称。但是，如果删除该对象，则可以创建同名的新对象。</p><blockquote><p>当对象所代表的是一个物理实体（例如代表一台物理主机的 Node）时， 如果在 Node 对象未被删除并重建的条件下，重新创建了同名的物理主机， 则 Kubernetes 会将新的主机看作是老的主机，这可能会带来某种不一致性。</p></blockquote><p>比较常见的四种资源命名约束。</p><h3 id="DNS-子域名"><a href="#DNS-子域名" class="headerlink" title="DNS 子域名"></a>DNS 子域名</h3><p>很多资源类型需要可以用作 DNS 子域名的名称。 DNS 子域名的定义可参见 <a href="https://tools.ietf.org/html/rfc1123">RFC 1123</a>。 这一要求意味着名称必须满足如下规则：</p><ul><li>不能超过253个字符</li><li>只能包含小写字母、数字，以及’-‘ 和 ‘.’</li><li>须以字母数字开头</li><li>须以字母数字结尾</li></ul><h3 id="RFC-1123-标签名"><a href="#RFC-1123-标签名" class="headerlink" title="RFC 1123 标签名"></a>RFC 1123 标签名</h3><p>某些资源类型需要其名称遵循 <a href="https://tools.ietf.org/html/rfc1123">RFC 1123</a> 所定义的 DNS 标签标准。也就是命名必须满足如下规则：</p><ul><li>最多 63 个字符</li><li>只能包含小写字母、数字，以及 ‘-‘</li><li>须以字母、数字开头</li><li>须以字母数字结尾</li></ul><h3 id="RFC-1035-标签名"><a href="#RFC-1035-标签名" class="headerlink" title="RFC 1035 标签名"></a>RFC 1035 标签名</h3><p>某些资源类型需要其名称遵循 <a href="https://tools.ietf.org/html/rfc1035">RFC 1035</a> 所定义的 DNS 标签标准。也就是命名必须满足如下规则：</p><ul><li>最多 63 个字符</li><li>只能包含小写字母、数字，以及 ‘-‘</li><li>须以字母开头</li><li>须以字母数字结尾</li></ul><h3 id="路径分段名称"><a href="#路径分段名称" class="headerlink" title="路径分段名称"></a>路径分段名称</h3><p>某些资源类型要求名称能被安全地用作路径中的片段。 换句话说，其名称不能是 <code>.</code>、<code>..</code>，也不可以包含 <code>/</code> 或 <code>%</code> 这些字符。</p><p>下面是一个名为<code>nginx-demo</code>的 Pod 的配置清单：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">nginx-demo</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">nginx:1.14.2</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span></span><br></pre></td></tr></table></figure><p><strong>说明：</strong> 某些资源类型可能具有额外的命名约束。</p><h2 id="UIDs"><a href="#UIDs" class="headerlink" title="UIDs"></a>UIDs</h2><p>Kubernetes 系统生成的字符串，唯一标识对象。</p><p>在 Kubernetes 集群的整个生命周期中创建的每个对象都有一个不同的 uid，它旨在区分类似实体的历史事件。</p><p>Kubernetes UIDs 是全局唯一标识符（也叫 UUIDs）。 UUIDs 是标准化的，见 ISO/IEC 9834-8 和 ITU-T X.667.</p><h1 id="名字空间"><a href="#名字空间" class="headerlink" title="名字空间"></a>名字空间</h1><p>Kubernetes 支持多个虚拟集群，它们底层依赖于同一个物理集群。 这些<strong>虚拟集群被称为名字空间</strong>。 在一些文档里名字空间也称为命名空间。</p><h2 id="何时使用多个名字空间"><a href="#何时使用多个名字空间" class="headerlink" title="何时使用多个名字空间"></a>何时使用多个名字空间</h2><p>名字空间适用于存在很多跨多个团队或项目的用户的场景。对于只有几到几十个用户的集群，根本不需要创建或考虑名字空间。</p><p>名字空间为名称提供了一个范围。<strong>资源的名称需要在名字空间内是唯一的</strong>，但不能跨名字空间。 <strong>名字空间不能相互嵌套，每个 Kubernetes 资源只能在一个名字空间中</strong>。</p><p>名字空间是在多个用户之间划分集群资源的一种方法（通过<a href="https://kubernetes.io/zh/docs/concepts/policy/resource-quotas/">资源配额</a>）。</p><p>不必使用多个名字空间来分隔仅仅轻微不同的资源，例如同一软件的不同版本： 应该使用<a href="https://kubernetes.io/zh/docs/concepts/overview/working-with-objects/labels/">标签</a> 来区分同一名字空间中的不同资源。</p><h2 id="使用名字空间"><a href="#使用名字空间" class="headerlink" title="使用名字空间"></a>使用名字空间</h2><p>名字空间的创建和删除在<a href="https://kubernetes.io/zh/docs/tasks/administer-cluster/namespaces/">名字空间的管理指南文档</a>描述。</p><blockquote><p>避免使用前缀 <code>kube-</code> 创建名字空间，因为它是为 Kubernetes 系统名字空间保留的。</p></blockquote><h3 id="查看名字空间"><a href="#查看名字空间" class="headerlink" title="查看名字空间"></a>查看名字空间</h3><p>可以使用以下命令列出集群中现存的名字空间：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">kubectl get namespace</span><br><span class="line">NAME          STATUS    AGE</span><br><span class="line">default       Active    1d</span><br><span class="line">kube-node-lease   Active   1d</span><br><span class="line">kube-system   Active    1d</span><br><span class="line">kube-public   Active    1d</span><br></pre></td></tr></table></figure><p>Kubernetes 会创建四个初始名字空间：</p><ul><li><code>default</code> 没有指明使用其它名字空间的对象所使用的默认名字空间</li><li><code>kube-system</code> Kubernetes 系统创建对象所使用的名字空间</li><li><code>kube-public</code> 这个名字空间是自动创建的，所有用户（包括未经过身份验证的用户）都可以读取它。 这个名字空间主要用于集群使用，以防某些资源在整个集群中应该是可见和可读的。 这个名字空间的公共方面只是一种约定，而不是要求。</li><li><code>kube-node-lease</code> 此名字空间用于与各个节点相关的 <a href="https://kubernetes.io/docs/reference/kubernetes-api/cluster-resources/lease-v1/">租约（Lease）</a>对象。 节点租期允许 kubelet 发送<a href="https://kubernetes.io/zh/docs/concepts/architecture/nodes/#heartbeats">心跳</a>，由此控制面能够检测到节点故障。</li></ul><h3 id="为请求设置名字空间"><a href="#为请求设置名字空间" class="headerlink" title="为请求设置名字空间"></a>为请求设置名字空间</h3><p>要为当前请求设置名字空间，请使用 <code>--namespace</code> 参数。</p><p>例如：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kubectl run nginx --image=nginx --namespace=&lt;名字空间名称&gt;</span><br><span class="line">kubectl get pods --namespace=&lt;名字空间名称&gt;</span><br></pre></td></tr></table></figure><h3 id="设置名字空间偏好"><a href="#设置名字空间偏好" class="headerlink" title="设置名字空间偏好"></a>设置名字空间偏好</h3><p>你可以永久保存名字空间，以用于对应上下文中所有后续 kubectl 命令。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kubectl config set-context --current --namespace=&lt;名字空间名称&gt;</span><br><span class="line"><span class="meta">#</span><span class="bash"> 验证之</span></span><br><span class="line">kubectl config view | grep namespace:</span><br></pre></td></tr></table></figure><h2 id="名字空间和-DNS"><a href="#名字空间和-DNS" class="headerlink" title="名字空间和 DNS"></a>名字空间和 DNS</h2><p>当你创建一个服务时， Kubernetes 会创建一个相应的 DNS 条目。</p><p>该条目的形式是 <code>&lt;服务名称&gt;.&lt;名字空间名称&gt;.svc.cluster.local</code>，这意味着如果容器只使用 <code>&lt;服务名称&gt;</code>，它将被解析到本地名字空间的服务。这对于跨多个名字空间（如开发、分级和生产） 使用相同的配置非常有用。如果你希望跨名字空间访问，则需要使用完全限定域名（FQDN）。</p><h2 id="并非所有对象都在名字空间中"><a href="#并非所有对象都在名字空间中" class="headerlink" title="并非所有对象都在名字空间中"></a>并非所有对象都在名字空间中</h2><p>大多数 kubernetes 资源（例如 Pod、Service、副本控制器等）都位于某些名字空间中。 但是名字空间资源本身并不在名字空间中。而且底层资源，例如 节点 和持久化卷不属于任何名字空间。</p><p>查看哪些 Kubernetes 资源在名字空间中，哪些不在名字空间中：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 位于名字空间中的资源</span></span><br><span class="line">kubectl api-resources --namespaced=true</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 不在名字空间中的资源</span></span><br><span class="line">kubectl api-resources --namespaced=false</span><br></pre></td></tr></table></figure><h2 id="自动打标签"><a href="#自动打标签" class="headerlink" title="自动打标签"></a>自动打标签</h2><p><strong>FEATURE STATE:</strong> <code>Kubernetes 1.21 [beta]</code></p><p>Kubernetes 控制面会为所有名字空间设置一个不可变更的 标签<code>kubernetes.io/metadata.name</code>，只要 <code>NamespaceDefaultLabelName</code> 这一 <a href="https://kubernetes.io/zh/docs/reference/command-line-tools-reference/feature-gates/">特性门控</a> 被启用。标签的值是名字空间的名称。</p><h1 id="标签和选择算符"><a href="#标签和选择算符" class="headerlink" title="标签和选择算符"></a>标签和选择算符</h1><p><em>标签（Labels）</em> 是附加到 Kubernetes 对象（比如 Pods）上的键值对。 标签旨在用于指定对用户有意义且相关的对象的标识属性，但不直接对核心系统有语义含义。 标签可以用于组织和选择对象的子集。标签可以在创建时附加到对象，随后可以随时添加和修改。 每个对象都可以定义一组键/值标签。每个键对于给定对象必须是唯一的。</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;metadata&quot;</span>: &#123;</span><br><span class="line">  <span class="attr">&quot;labels&quot;</span>: &#123;</span><br><span class="line">    <span class="attr">&quot;key1&quot;</span> : <span class="string">&quot;value1&quot;</span>,</span><br><span class="line">    <span class="attr">&quot;key2&quot;</span> : <span class="string">&quot;value2&quot;</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>标签能够支持高效的查询和监听操作，对于用户界面和命令行是很理想的。 应使用<a href="https://kubernetes.io/zh/docs/concepts/overview/working-with-objects/annotations/">注解</a> 记录非识别信息。</p><h2 id="动机"><a href="#动机" class="headerlink" title="动机"></a>动机</h2><p>标签使用户能够以松散耦合的方式将他们自己的组织结构映射到系统对象，而无需客户端存储这些映射。</p><p>服务部署和批处理流水线通常是多维实体（例如，多个分区或部署、多个发行序列、多个层，每层多个微服务）。 管理通常需要交叉操作，这打破了严格的层次表示的封装，特别是由基础设施而不是用户确定的严格的层次结构。</p><p>示例标签：</p><ul><li><code>&quot;release&quot; : &quot;stable&quot;</code>, <code>&quot;release&quot; : &quot;canary&quot;</code></li><li><code>&quot;environment&quot; : &quot;dev&quot;</code>, <code>&quot;environment&quot; : &quot;qa&quot;</code>, <code>&quot;environment&quot; : &quot;production&quot;</code></li><li><code>&quot;tier&quot; : &quot;frontend&quot;</code>, <code>&quot;tier&quot; : &quot;backend&quot;</code>, <code>&quot;tier&quot; : &quot;cache&quot;</code></li><li><code>&quot;partition&quot; : &quot;customerA&quot;</code>, <code>&quot;partition&quot; : &quot;customerB&quot;</code></li><li><code>&quot;track&quot; : &quot;daily&quot;</code>, <code>&quot;track&quot; : &quot;weekly&quot;</code></li></ul><p>有一些<a href="https://kubernetes.io/zh/docs/concepts/overview/working-with-objects/common-labels/">常用标签</a>的例子; 你可以任意制定自己的约定。 请记住，标签的 Key 对于给定对象必须是唯一的。</p><h2 id="语法和字符集"><a href="#语法和字符集" class="headerlink" title="语法和字符集"></a>语法和字符集</h2><p><em>标签</em> 是键值对。有效的标签键有两个段：<strong>可选的前缀</strong>和<strong>名称</strong>，用斜杠（<code>/</code>）分隔。 名称段是必需的，必须小于等于 63 个字符，以字母数字字符（<code>[a-z0-9A-Z]</code>）开头和结尾， 带有破折号（<code>-</code>），下划线（<code>_</code>），点（ <code>.</code>）和之间的字母数字。 前缀是可选的。如果指定，前缀必须是 DNS 子域：由点（<code>.</code>）分隔的一系列 DNS 标签，总共不超过 253 个字符， 后跟斜杠（<code>/</code>）。</p><p>如果省略前缀，则假定标签键对用户是私有的。 向最终用户对象添加标签的自动系统组件（例如 <code>kube-scheduler</code>、<code>kube-controller-manager</code>、 <code>kube-apiserver</code>、<code>kubectl</code> 或其他第三方自动化工具）必须指定前缀。</p><p><code>kubernetes.io/</code> 和 <code>k8s.io/</code> 前缀是为 Kubernetes 核心组件<a href="https://kubernetes.io/zh/docs/reference/labels-annotations-taints/">保留的</a>。</p><p>有效标签值：</p><ul><li>必须为 63 个字符或更少（可以为空）</li><li>除非标签值为空，必须以字母数字字符（<code>[a-z0-9A-Z]</code>）开头和结尾</li><li>包含破折号（<code>-</code>）、下划线（<code>_</code>）、点（<code>.</code>）和字母或数字。</li></ul><h2 id="标签选择算符"><a href="#标签选择算符" class="headerlink" title="标签选择算符"></a>标签选择算符</h2><p>与<a href="https://kubernetes.io/zh/docs/concepts/overview/working-with-objects/names/">名称和 UID</a> 不同， 标签不支持唯一性。通常，我们希望许多对象携带相同的标签。</p><p>通过 <em>标签选择算符</em>，客户端/用户可以识别一组对象。标签选择算符是 Kubernetes 中的核心分组原语。</p><p>API 目前支持两种类型的选择算符：<em>基于等值的</em> 和 <em>基于集合的</em>。 标签选择算符可以<strong>由逗号分隔</strong>的多个 <em>需求</em> 组成。 在多个需求的情况下，必须满足所有要求，因此逗号分隔符充当逻辑 <em>与</em>（<code>&amp;&amp;</code>）运算符。</p><p>空标签选择算符或者未指定的选择算符的语义取决于上下文， 支持使用选择算符的 API 类别应该将算符的合法性和含义用文档记录下来。</p><blockquote><p>对于某些 API 类别（例如 ReplicaSet）而言，两个实例的标签选择算符不得在命名空间内重叠， 否则它们的控制器将互相冲突，无法确定应该存在的副本个数。</p></blockquote><blockquote><p>对于基于等值的和基于集合的条件而言，不存在逻辑或（<code>||</code>）操作符。 你要确保你的过滤语句按合适的方式组织。</p></blockquote><h3 id="基于等值的-需求"><a href="#基于等值的-需求" class="headerlink" title="基于等值的 需求 "></a><em>基于等值的</em> 需求<a href="https://kubernetes.io/zh/docs/concepts/overview/working-with-objects/labels/#%E5%9F%BA%E4%BA%8E%E7%AD%89%E5%80%BC%E7%9A%84-%E9%9C%80%E6%B1%82"> </a></h3><p><em>基于等值</em> 或 <em>基于不等值</em> 的需求允许按标签键和值进行过滤。 匹配对象必须满足所有指定的标签约束，尽管它们也可能具有其他标签。 可接受的运算符有<code>=</code>、<code>==</code> 和 <code>!=</code> 三种。 前两个表示 <em>相等</em>（并且只是同义词），而后者表示 <em>不相等</em>。例如：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">environment = production</span><br><span class="line">tier != frontend</span><br></pre></td></tr></table></figure><p>前者选择所有资源，其键名等于 <code>environment</code>，值等于 <code>production</code>。 后者选择所有资源，其键名等于 <code>tier</code>，值不同于 <code>frontend</code>，所有资源都没有带有 <code>tier</code> 键的标签。 可以使用逗号运算符来过滤 <code>production</code> 环境中的非 <code>frontend</code> 层资源：<code>environment=production,tier!=frontend</code>。</p><p>基于等值的标签要求的一种使用场景是 Pod 要指定节点选择标准。 例如，下面的示例 Pod 选择带有标签 “<code>accelerator=nvidia-tesla-p100</code>“。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">cuda-test</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">cuda-test</span></span><br><span class="line">      <span class="attr">image:</span> <span class="string">&quot;k8s.gcr.io/cuda-vector-add:v0.1&quot;</span></span><br><span class="line">      <span class="attr">resources:</span></span><br><span class="line">        <span class="attr">limits:</span></span><br><span class="line">          <span class="attr">nvidia.com/gpu:</span> <span class="number">1</span></span><br><span class="line">  <span class="attr">nodeSelector:</span></span><br><span class="line">    <span class="attr">accelerator:</span> <span class="string">nvidia-tesla-p100</span></span><br></pre></td></tr></table></figure><h3 id="基于集合-的需求"><a href="#基于集合-的需求" class="headerlink" title="基于集合 的需求"></a><em>基于集合</em> 的需求</h3><p><em>基于集合</em> 的标签需求允许你通过一组值来过滤键。 支持三种操作符：<code>in</code>、<code>notin</code> 和 <code>exists</code> (只可以用在键标识符上)。例如：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">environment in (production, qa)</span><br><span class="line">tier notin (frontend, backend)</span><br><span class="line">partition</span><br><span class="line">!partition</span><br></pre></td></tr></table></figure><ul><li>第一个示例选择了所有键等于 <code>environment</code> 并且值等于 <code>production</code> 或者 <code>qa</code> 的资源。</li><li>第二个示例选择了所有键等于 <code>tier</code> 并且值不等于 <code>frontend</code> 或者 <code>backend</code> 的资源，以及所有没有 <code>tier</code> 键标签的资源。</li><li>第三个示例选择了所有包含了有 <code>partition</code> 标签的资源；没有校验它的值。</li><li>第四个示例选择了所有没有 <code>partition</code> 标签的资源；没有校验它的值。 类似地，逗号分隔符充当 <em>与</em> 运算符。因此，使用 <code>partition</code> 键（无论为何值）和 <code>environment</code> 不同于 <code>qa</code> 来过滤资源可以使用 <code>partition, environment notin（qa)</code> 来实现。</li></ul><p><em>基于集合</em> 的标签选择算符是相等标签选择算符的一般形式，因为 <code>environment=production</code> 等同于 <code>environment in（production）</code>；<code>!=</code> 和 <code>notin</code> 也是类似的。</p><p><em>基于集合</em> 的要求可以与基于 <em>相等</em> 的要求混合使用。例如：<code>partition in (customerA, customerB),environment!=qa</code>。</p><h1 id="注解"><a href="#注解" class="headerlink" title="注解"></a>注解</h1><p>你可以使用 Kubernetes 注解为对象附加任意的非标识的元数据。客户端程序（例如工具和库）能够获取这些元数据信息。</p><h2 id="为对象附加元数据"><a href="#为对象附加元数据" class="headerlink" title="为对象附加元数据"></a>为对象附加元数据</h2><p>你可以使用标签或注解将元数据附加到 Kubernetes 对象。 标签可以用来<strong>选择对象和查找</strong>满足某些条件的对象集合。 相反，注解不用于标识和选择对象。 注解中的元数据，可以很小，也可以很大，可以是结构化的，也可以是非结构化的，能够包含标签不允许的字符。</p><p>注解和标签一样，是键/值对:</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;metadata&quot;</span>: &#123;</span><br><span class="line">  <span class="attr">&quot;annotations&quot;</span>: &#123;</span><br><span class="line">    <span class="attr">&quot;key1&quot;</span> : <span class="string">&quot;value1&quot;</span>,</span><br><span class="line">    <span class="attr">&quot;key2&quot;</span> : <span class="string">&quot;value2&quot;</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>Map 中的键和值必须是字符串。 换句话说，你不能使用数字、布尔值、列表或其他类型的键或值。</p></blockquote><p>以下是一些例子，用来说明哪些信息可以使用注解来记录:</p><ul><li><p>由声明性配置所管理的字段。 将这些字段附加为注解，能够将它们与客户端或服务端设置的默认值、 自动生成的字段以及通过自动调整大小或自动伸缩系统设置的字段区分开来。</p></li><li><p>构建、发布或镜像信息（如时间戳、发布 ID、Git 分支、PR 数量、镜像哈希、仓库地址）。</p></li><li><p>指向日志记录、监控、分析或审计仓库的指针。</p></li><li><p>可用于调试目的的客户端库或工具信息：例如，名称、版本和构建信息。</p></li><li><p>用户或者工具/系统的来源信息，例如来自其他生态系统组件的相关对象的 URL。</p></li><li><p>轻量级上线工具的元数据信息：例如，配置或检查点。</p></li><li><p>负责人员的电话或呼机号码，或指定在何处可以找到该信息的目录条目，如团队网站。</p></li><li><p>从用户到最终运行的指令，以修改行为或使用非标准功能。</p></li></ul><p>你可以将这类信息存储在外部数据库或目录中而不使用注解， 但这样做就使得开发人员很难生成用于部署、管理、自检的客户端共享库和工具。</p><h2 id="语法和字符集-1"><a href="#语法和字符集-1" class="headerlink" title="语法和字符集"></a>语法和字符集</h2><p><em>注解（Annotations）</em> 存储的形式是键/值对。有效的注解键分为两部分： 可选的前缀和名称，以斜杠（<code>/</code>）分隔。 名称段是必需项，并且必须在63个字符以内，以字母数字字符（<code>[a-z0-9A-Z]</code>）开头和结尾， 并允许使用破折号（<code>-</code>），下划线（<code>_</code>），点（<code>.</code>）和字母数字。 前缀是可选的。如果指定，则前缀必须是DNS子域：一系列由点（<code>.</code>）分隔的DNS标签， 总计不超过253个字符，后跟斜杠（<code>/</code>）。 如果省略前缀，则假定注解键对用户是私有的。 由系统组件添加的注解 （例如，<code>kube-scheduler</code>，<code>kube-controller-manager</code>，<code>kube-apiserver</code>，<code>kubectl</code> 或其他第三方组件），必须为终端用户添加注解前缀。</p><p><code>kubernetes.io/</code> 和 <code>k8s.io/</code> 前缀是为Kubernetes核心组件保留的。</p><p>例如，下面是一个 Pod 的配置文件，其注解中包含 <code>imageregistry: https://hub.docker.com/</code>：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">annotations-demo</span></span><br><span class="line">  <span class="attr">annotations:</span></span><br><span class="line">    <span class="attr">imageregistry:</span> <span class="string">&quot;https://hub.docker.com/&quot;</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">nginx:1.7.9</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span></span><br></pre></td></tr></table></figure><h1 id="词汇表"><a href="#词汇表" class="headerlink" title="词汇表"></a>词汇表</h1><p><a href="https://kubernetes.io/zh/docs/reference/glossary/?fundamental=true">https://kubernetes.io/zh/docs/reference/glossary/?fundamental=true</a></p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="https://kubernetes.io/zh/docs/home/">Kubernetes 文档</a></p><p><a href="https://zhuanlan.zhihu.com/p/44133059">Kubernetes vs OpenStack</a></p><p><a href="https://www.wendev.site/2021/11/22/%E5%8F%B2%E4%B8%8A%E6%9C%80%E5%85%A8%E9%9D%A2%E7%9A%84Kubernetes%EF%BC%88K8S%EF%BC%89%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0/">史上最全面的Kubernetes（K8S）入门笔记</a></p><p><a href="https://minikube.sigs.k8s.io/docs/start/">https://minikube.sigs.k8s.io/docs/start/</a></p><p><a href="https://www.wendev.site/2021/11/22/%E5%8F%B2%E4%B8%8A%E6%9C%80%E5%85%A8%E9%9D%A2%E7%9A%84Kubernetes%EF%BC%88K8S%EF%BC%89%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0/">https://www.wendev.site/2021/11/22/%E5%8F%B2%E4%B8%8A%E6%9C%80%E5%85%A8%E9%9D%A2%E7%9A%84Kubernetes%EF%BC%88K8S%EF%BC%89%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0/</a></p><p><a href="https://www.zhihu.com/question/37498459">https://www.zhihu.com/question/37498459</a></p><p><a href="https://www.1024sou.com/article/321121.html">https://www.1024sou.com/article/321121.html</a></p><p><a href="https://blog.csdn.net/dualvencsdn/article/details/79207281">https://blog.csdn.net/dualvencsdn/article/details/79207281</a></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;终于下定决心搞清楚k8s的架构、原理，本blog k8s系列文章仅做浏览官网时的笔记，同样需要学习k8s的同学，可以直接去 &lt;a href=&quot;https://kubernetes.io/zh/docs/concepts/&quot;&gt;Kubernetes官网&lt;/a&gt;查看各种文档。&lt;/p&gt;
&lt;h1 id=&quot;Kubernetes-是什么？&quot;&gt;&lt;a href=&quot;#Kubernetes-是什么？&quot; class=&quot;headerlink&quot; title=&quot;Kubernetes 是什么？&quot;&gt;&lt;/a&gt;Kubernetes 是什么？&lt;/h1&gt;&lt;p&gt;Kubernetes 是一个可移植的、可扩展的开源平台，用于&lt;strong&gt;管理容器化的工作负载和服务&lt;/strong&gt;，可促进声明式配置和自动化。 Kubernetes 拥有一个庞大且快速增长的生态系统。Kubernetes 的服务、支持和工具广泛可用。&lt;/p&gt;</summary>
    
    
    
    
    <category term="Kubernetes" scheme="http://chengqian90.com/tags/Kubernetes/"/>
    
    <category term="k8s" scheme="http://chengqian90.com/tags/k8s/"/>
    
  </entry>
  
  <entry>
    <title>Python eventlet浅析</title>
    <link href="http://chengqian90.com/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Python%20eventlet%E6%B5%85%E6%9E%90.html"/>
    <id>http://chengqian90.com/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Python%20eventlet%E6%B5%85%E6%9E%90.html</id>
    <published>2021-04-21T03:24:08.000Z</published>
    <updated>2022-03-08T16:23:40.436Z</updated>
    
    <content type="html"><![CDATA[<p>eventlet库在Python构建的项目中，使用频率还是很高的，因此需要梳理一下eventlet库的使用方式。</p><span id="more"></span><h2 id="协程"><a href="#协程" class="headerlink" title="协程"></a>协程</h2><p><a href="https://www.cnblogs.com/Survivalist/p/11527949.html">https://www.cnblogs.com/Survivalist/p/11527949.html</a></p><p><a href="https://www.liaoxuefeng.com/wiki/897692888725344/923057403198272">https://www.liaoxuefeng.com/wiki/897692888725344/923057403198272</a></p><p><a href="https://zh.wikipedia.org/wiki/%E5%8D%8F%E7%A8%8B">https://zh.wikipedia.org/wiki/%E5%8D%8F%E7%A8%8B</a></p><h2 id="优秀资料"><a href="#优秀资料" class="headerlink" title="优秀资料"></a>优秀资料</h2><p><a href="https://www.cnblogs.com/Security-Darren/p/4170031.html">Python——eventlet</a></p><p><a href="http://luckylau.tech/2017/03/06/Python%E7%9A%84eventlet%E4%BD%BF%E7%94%A8%E4%B8%8E%E7%90%86%E8%A7%A3/">Python的eventlet使用与理解</a></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;eventlet库在Python构建的项目中，使用频率还是很高的，因此需要梳理一下eventlet库的使用方式。&lt;/p&gt;</summary>
    
    
    
    <category term="Python" scheme="http://chengqian90.com/categories/Python/"/>
    
    
    <category term="eventlet" scheme="http://chengqian90.com/tags/eventlet/"/>
    
  </entry>
  
  <entry>
    <title>Linux shell json解析工具——jq</title>
    <link href="http://chengqian90.com/Linux%E5%B7%A5%E5%85%B7/Linux%20shell%20json%E8%A7%A3%E6%9E%90%E5%B7%A5%E5%85%B7%E2%80%94%E2%80%94jq.html"/>
    <id>http://chengqian90.com/Linux%E5%B7%A5%E5%85%B7/Linux%20shell%20json%E8%A7%A3%E6%9E%90%E5%B7%A5%E5%85%B7%E2%80%94%E2%80%94jq.html</id>
    <published>2021-04-14T12:30:52.000Z</published>
    <updated>2022-03-08T16:23:40.433Z</updated>
    
    <content type="html"><![CDATA[<p>json格式是数据传输过程中一种通用的格式，对于Python而言，由于有多种json包，解析json并不是什么难事。</p><p>在Linux shell中，同样有一种强大的json解析工具——jq。jq没有相关依赖，仅一个二进制文件。</p><span id="more"></span><h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><p>官网：<a href="https://stedolan.github.io/jq/download/">https://stedolan.github.io/jq/download/</a></p><h3 id="Linux"><a href="#Linux" class="headerlink" title="Linux"></a>Linux</h3><ul><li>jq 1.5 is in the official <a href="https://packages.debian.org/jq">Debian</a> and <a href="http://packages.ubuntu.com/jq">Ubuntu</a> repositories. Install using <code>sudo apt-get install jq</code>.</li><li>jq 1.5 is in the official <a href="http://pkgs.fedoraproject.org/cgit/jq.git/">Fedora</a> repository. Install using <code>sudo dnf install jq</code>.</li><li>jq 1.4 is in the official <a href="https://software.opensuse.org/package/jq">openSUSE</a> repository. Install using <code>sudo zypper install jq</code>.</li><li>jq 1.5 is in the official <a href="https://www.archlinux.org/packages/?sort=&q=jq&maintainer=&flagged=">Arch</a> repository. Install using <code>sudo pacman -Sy jq</code>.</li></ul><h3 id="OS-X"><a href="#OS-X" class="headerlink" title="OS X"></a>OS X</h3><ul><li>Use <a href="http://brew.sh/">Homebrew</a> to install jq 1.5 with <code>brew install jq</code>.</li></ul><h3 id="FreeBSD"><a href="#FreeBSD" class="headerlink" title="FreeBSD"></a>FreeBSD</h3><ul><li>Use <a href="https://www.freshports.org/textproc/jq/">FreshPorts</a> to install jq 1.4 with <code>pkg install jq</code>.</li></ul><h3 id="Solaris"><a href="#Solaris" class="headerlink" title="Solaris"></a>Solaris</h3><ul><li><code>pkgutil -i jq</code> in <a href="https://www.opencsw.org/p/jq">OpenCSW</a> for Solaris 10+, Sparc and x86.</li></ul><h3 id="Windows"><a href="#Windows" class="headerlink" title="Windows"></a>Windows</h3><ul><li>Use <a href="https://chocolatey.org/">Chocolatey NuGet</a> to install jq 1.5 with <code>chocolatey install jq</code>.</li></ul><h2 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h2><p>命令格式</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jq [options...] filter [files...]</span><br></pre></td></tr></table></figure><p>可以使用下面几种格式</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">jq -c &#x27;&#x27; a.json</span><br><span class="line">jq &#x27;&#x27; a.json</span><br><span class="line"></span><br><span class="line">jq -c &#x27;.foo&#x27; a.json</span><br><span class="line">cat a.json | jq -c &#x27;.foo&#x27;</span><br></pre></td></tr></table></figure><p><strong>参数说明：</strong><br>–compact-output / -c<br>默认情况下，jq会将json格式化为多行树状结构输出，但有时需要将一个json串在一行输出，即可使用该参数</p><p><strong>过滤器说明</strong></p><ul><li><p>.foo, .foo.bar<br>获取json中key的值，可过滤出多级json串中的key值。</p></li><li><p>.foo, .bar<br>同时获取json中多个key的值。但过滤出的多个值会分多行显示。</p></li><li><p>{foo: .foo, bar: .bar}<br>获取json中部分key的值，并组合为新的object形式的json串。foo与bar即新json串的key，.foo与.bar即原json串中需要获取值的key。<br>注意，生成的json串内容顺序是倒序的，上例中会生成：{“bar”:””, “foo”:””}</p></li><li><p>[.foo, .bar]<br>获取json中部分key的值，并组合为新的数组形式的json串。.foo与.bar即原json串中需要获取值的key。<br>注意，生成的json串内容顺序是正序的，上例中会生成：[“foov”, “barv”]</p></li></ul><p>jq 通过命令行选项来控制对输入输出的处理。几个重要的选项如下</p><ul><li><p><code>-r</code> 选项 or <code>jq --raw-output</code>。</p><p>该选项控制 jq 是输出 raw 格式内容或 JSON 格式内容。所谓的 JSON 格式是指符合 JSON 标准的格式。例如，假设我们要查询 JSON 字符串{“name”:”tom”}中 name 的值. 使用-r 选项时返回的是’tom’. 不使用-r 选项时，返回的是’”tom”‘.返回值多了一对双引号。即：<strong>输出值无引号</strong>，Print strings without quotes</p></li><li><p><code>-s</code> 选项。 </p><p>jq 可以同时处理空格分割的多个 JSON 字符串输入。默认情况下，jq 会将 filter 分别对每个 JSON 输入应用，并返回结果。使用-s 选项，jq 会将所有的 JSON 输入放入一个数组中并在这个数组上使用 filter。“-s”选项不但影响到 filter 的写法。如果在 filter 中需要对数据进行选择和映射，其还会影响最终结果。</p></li><li><p><code>–arg</code> 选项。</p><p>jq 通过该选项提供了和宿主脚本语言交互的能力。该选项将值(v)绑定到一个变量(a)上。在后面的 filter 中可以直接通过变量引用这个值。例如，filter ‘.$a’表示查询属性名称等于变量 a 的值的属性。</p></li></ul><h3 id="JSON-format"><a href="#JSON-format" class="headerlink" title="JSON format"></a>JSON format</h3><p>以下面的字符串为例</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> cat json_raw.txt</span></span><br><span class="line">&#123;&quot;routeTableId&quot;:&quot;rt-kjjhbqkw8dk3&quot;,&quot;vpcId&quot;:&quot;vpc-ydbn98nzsw67&quot;,&quot;description&quot;:&#123;&quot;time_zone&quot;:&quot;shanghai&quot;&#125;,&quot;routeRules&quot;:[&#123;&quot;routeRuleId&quot;:&quot;rr-psj2t3mbqhmq&quot;,&quot;sourceAddress&quot;:&quot;192.168.0.0/20&quot;,&quot;destinationAddress&quot;:&quot;0.0.0.0/0&quot;,&quot;nexthopId&quot;:&quot;nat-byqr8xwnbh2e&quot;,&quot;nexthopType&quot;:&quot;nat&quot;,&quot;description&quot;:&quot;&quot;,&quot;pathType&quot;:&quot;normal&quot;,&quot;routeTableId&quot;:&quot;rt-kjjhbqkw8dk3&quot;&#125;,&#123;&quot;routeRuleId&quot;:&quot;&quot;,&quot;sourceAddress&quot;:&quot;0.0.0.0/0&quot;,&quot;destinationAddress&quot;:&quot;192.168.0.0/20&quot;,&quot;nexthopId&quot;:&quot;&quot;,&quot;nexthopType&quot;:&quot;sys&quot;,&quot;description&quot;:&quot;&quot;,&quot;routeTableId&quot;:&quot;rt-kjjhbqkw8dk3&quot;&#125;]&#125;</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> cat json_raw.txt | jq .</span></span><br><span class="line">&#123;</span><br><span class="line">    &quot;routeTableId&quot;:&quot;rt-kjjhbqkw8dk3&quot;,</span><br><span class="line">    &quot;vpcId&quot;:&quot;vpc-ydbn98nzsw67&quot;,</span><br><span class="line">    &quot;description&quot;:&#123;</span><br><span class="line">        &quot;time_zone&quot;:&quot;shanghai&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;routeRules&quot;:[</span><br><span class="line">        &#123;</span><br><span class="line">            &quot;routeRuleId&quot;:&quot;rr-psj2t3mbqhmq&quot;,</span><br><span class="line">            &quot;sourceAddress&quot;:&quot;192.168.0.0/20&quot;,</span><br><span class="line">            &quot;destinationAddress&quot;:&quot;0.0.0.0/0&quot;,</span><br><span class="line">            &quot;nexthopId&quot;:&quot;nat-byqr8xwnbh2e&quot;,</span><br><span class="line">            &quot;nexthopType&quot;:&quot;nat&quot;,</span><br><span class="line">            &quot;description&quot;:&quot;&quot;,</span><br><span class="line">            &quot;pathType&quot;:&quot;normal&quot;,</span><br><span class="line">            &quot;routeTableId&quot;:&quot;rt-kjjhbqkw8dk3&quot;</span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            &quot;routeRuleId&quot;:&quot;&quot;,</span><br><span class="line">            &quot;sourceAddress&quot;:&quot;0.0.0.0/0&quot;,</span><br><span class="line">            &quot;destinationAddress&quot;:&quot;192.168.0.0/20&quot;,</span><br><span class="line">            &quot;nexthopId&quot;:&quot;&quot;,</span><br><span class="line">            &quot;nexthopType&quot;:&quot;sys&quot;,</span><br><span class="line">            &quot;description&quot;:&quot;&quot;,</span><br><span class="line">            &quot;routeTableId&quot;:&quot;rt-kjjhbqkw8dk3&quot;</span><br><span class="line">        &#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="JSON-parse"><a href="#JSON-parse" class="headerlink" title="JSON parse"></a>JSON parse</h3><p>根据key获取value</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> cat json_raw.txt | jq <span class="string">&quot;.vpcId&quot;</span></span></span><br><span class="line">&quot;vpc-ydbn98nzsw67&quot;</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> cat json_raw.txt | jq <span class="string">&quot;.vpcId,.routeTableId&quot;</span></span></span><br><span class="line">&quot;vpc-ydbn98nzsw67&quot;</span><br><span class="line">&quot;rt-kjjhbqkw8dk3&quot;</span><br></pre></td></tr></table></figure><p>key不存在时会返回null</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> cat json_raw.txt | jq <span class="string">&quot;.test&quot;</span></span></span><br><span class="line">null</span><br></pre></td></tr></table></figure><h3 id="JSON-nested-parse"><a href="#JSON-nested-parse" class="headerlink" title="JSON nested parse"></a>JSON nested parse</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> cat json_raw.txt | jq <span class="string">&quot;.description.time_zone&quot;</span></span></span><br><span class="line">&quot;shanghai&quot;</span><br></pre></td></tr></table></figure><h3 id="JSON-parse-array"><a href="#JSON-parse-array" class="headerlink" title="JSON parse array"></a>JSON parse array</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> cat json_raw.txt | jq <span class="string">&quot;.routeRules[].sourceAddress&quot;</span></span></span><br><span class="line">&quot;192.168.0.0/20&quot;</span><br><span class="line">&quot;0.0.0.0/0&quot;</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> cat json_raw.txt | jq <span class="string">&quot;.routeRules[1].sourceAddress&quot;</span></span></span><br><span class="line">&quot;0.0.0.0/0&quot;</span><br></pre></td></tr></table></figure><h3 id="内建函数"><a href="#内建函数" class="headerlink" title="内建函数"></a>内建函数</h3><p>jq还有一些内建函数如 keys、has。</p><p>keys是用来获取JSON中的key元素的</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> cat json_raw.txt | jq <span class="string">&#x27;keys&#x27;</span></span></span><br><span class="line">[</span><br><span class="line">  &quot;description&quot;,</span><br><span class="line">  &quot;routeRules&quot;,</span><br><span class="line">  &quot;routeTableId&quot;,</span><br><span class="line">  &quot;vpcId&quot;</span><br><span class="line">]</span><br></pre></td></tr></table></figure><p>has是用来是判断是否存在某个key</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> cat json_raw.txt | jq <span class="string">&#x27;has(&quot;description&quot;)&#x27;</span></span></span><br><span class="line">true</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> cat json_raw.txt | jq <span class="string">&#x27;has(&quot;test&quot;)&#x27;</span></span></span><br><span class="line">false</span><br></pre></td></tr></table></figure><h3 id="其他用法"><a href="#其他用法" class="headerlink" title="其他用法"></a>其他用法</h3><p>利用jq的管道取出特定的字段</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> cat test.json | jq <span class="string">&quot;.LoadBalancers.LoadBalancer | .[0].LoadBalancerId&quot;</span></span></span><br><span class="line">&quot;123&quot;</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">$</span><span class="bash"> cat test.json | jq <span class="string">&quot;.LoadBalancers.LoadBalancer[0].LoadBalancerId&quot;</span></span></span><br><span class="line">&quot;123&quot;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>自定义输出的字段名，拼接取得的字符串成新json：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> cat test.json | jq <span class="string">&quot;.LoadBalancers.LoadBalancer | &#123;&quot;</span>id1<span class="string">&quot; : .[0].LoadBalancerId, name1: .[0].LoadBalancerName&#125;&quot;</span></span></span><br><span class="line">&#123;</span><br><span class="line">  &quot;name1&quot;: &quot;1.test.com&quot;,</span><br><span class="line">  &quot;id1&quot;: &quot;123&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> cat test.json | jq <span class="string">&quot;[.LoadBalancers.LoadBalancer[] | &#123;&quot;</span>id<span class="string">&quot; : .LoadBalancerId, name: .LoadBalancerName&#125;]&quot;</span></span></span><br><span class="line">[</span><br><span class="line">    &#123;</span><br><span class="line">        &quot;name&quot;:&quot;1.test.com&quot;,</span><br><span class="line">        &quot;id&quot;:&quot;123&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">        &quot;name&quot;:&quot;2.test.com&quot;,</span><br><span class="line">        &quot;id&quot;:&quot;456&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">        &quot;name&quot;:&quot;3.test.com&quot;,</span><br><span class="line">        &quot;id&quot;:&quot;789&quot;</span><br><span class="line">    &#125;</span><br><span class="line">]</span><br></pre></td></tr></table></figure><p>查看元素个数</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> cat test.json | jq <span class="string">&quot;.LoadBalancers | length&quot;</span></span></span><br><span class="line">1</span><br></pre></td></tr></table></figure><p>jq功能超级强大，甚至包括index，add，逻辑判断，正则表达式，debug，try-catch，while，split等等，具体可参考 <a href="https://stedolan.github.io/jq/manual/%10%E3%80%82">https://stedolan.github.io/jq/manual/。</a></p><h2 id="基础表达式"><a href="#基础表达式" class="headerlink" title="基础表达式"></a>基础表达式</h2><p>基础表达式（Basic filters)是 jq 提供的基本过滤器，用来访问 JSON 对象中的属性。基础表达式也是实现更复杂查询功能的基础。基础表达式主要有以下几种：</p><ul><li>‘.’ 符号。单独的一个’.’符号用来表示对作为表达式输入的整个 JSON 对象的引用。</li><li>JSON 对象操作。jq 提供两种基本表达式用来访问 JSON 对象的属性：’.<attributename>’和’.<attributename>?’。正常情况下，这两个表达式的行为相同：都是访问对象属性，如果 JSON 对象不包含指定的属性则返回 null。区别在于，当输入不是 JSON 对象或数组时，第一个表达式会抛出异常。第二个表达式无任何输出。</li><li>数组操作。jq 提供三种基础表达式来操作数组：<ul><li>迭代器操作(‘.[]’). 该表达式的输入可以是数组或者 JSON 对象。输出的是基于数组元素或者 JSON 对象属性值的 iterator。</li><li>访问特定元素的操作(‘.[index]’或’.[attributename]’)。用来访问数组元素或者 JSON 对象的属性值。输出是单个值</li><li>数组切片操作(‘.[startindex:endindex]’)，其行为类似于 python 语言中数组切片操作。</li></ul></li><li>表达式操作(‘,’和 ‘|’)。表达式操作是用来关联多个基础表达式。其中逗号表示对同一个输入应用多个表达式。管道符表示将前一个表达式的输出用作后一个表达式的输入。当前一个表达式产生的结果是迭代器时，会将迭代器中的每一个值用作后一个表达式的输入从而形成新的表达式。例如’.[]|.+1′, 在这个表达式中，第一个子表达式’.[]’在输入数组上构建迭代器，第二个子表达式则在迭代器的每个元素上加 1。</li></ul><h2 id="内置运算支持"><a href="#内置运算支持" class="headerlink" title="内置运算支持"></a>内置运算支持</h2><p>jq 内部支持的数据类型有：数字，字符串，数组和对象(object)。并且在这些数据类型的基础上， jq 提供了一些基本的操作符来实现一些基本的运算和数据操作。列举如下：</p><ul><li>数学运算。对于数字类型，jq 实现了基本的加减乘除(/)和求余(%)运算。对于除法运算，jq 最多支持 16 位小数。</li><li>字符串操作。jq 提供字符串的连接操作(运算符为’+’，例如：”tom “+”jerry”结果为”tom jerry”)，字符串的复制操作(例如：’a’*3 结果为’aaa’)，以及字符串分割操作(将字符串按照指定的分割符分成数组，例如”sas”/”s”的结果为[“”,”a”,””]，而”sas”/”a”的结果为[“s”,”s”]。</li><li>数组操作。jq 提供两种数组运算：并集(‘+’)运算，结果数组中包含参与运算的数组的所有元素。差集运算(‘-‘)，例如：有数组 a,b, a-b 的结果为所有在 a 中且不包含在 b 中的元素组成的数组。</li><li>对象操作。jq 实现了两个 JSON 对象的合并操作(merge)。当两个参与运算的对象包含相同的属性时则保留运算符右侧对象的属性值。有两种合并运算符：’+’和’<em>’。所不同的是，运算符’+’只做顶层属性的合并，运算符’</em>’则是递归合并。例如：有对象 a={“a”:{“b”:1}}, b={“a”:{“c”:2}}，a+b 的结果为{“a”:{“c”:2}}，而 a*b 的结果为{“a”:{“b”:1,”c”:2}}</li><li>比较操作：jq 内部支持的比较操作符有==, !=,&gt;,&gt;=,&lt;=和&lt;。其中，’==’的规则和 javascript 中的恒等(‘===’)类似，只有两个操作数的类型和值均相同时其结果才是 true。</li><li>逻辑运算符: and/or/not。在 jq 逻辑运算中，除了 false 和 null 外，其余的任何值都等同于 true。</li><li>默认操作符(‘//’), 表达式’a//b’表示当表达式 a 的值不是 false 或 null 时，a//b 等于 a，否则等于 b。</li></ul><p>jq 中有一种很特殊的运算规则：当运算符的一个或两个操作数是迭代器时，其运算以类似与笛卡尔乘积的方式进行，即把两个操作数中的每一个元素拿出来分别运算。例如：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">result is 5 6 7 8</span></span><br><span class="line">jq -n &#x27;([1,2]|.[])+([4,6]|.[])&#x27;</span><br></pre></td></tr></table></figure><p>jq 内部支持两种控制结构：<strong>判断语句</strong>和<strong>异常处理</strong>。</p><p>判断语句的完整结构为 if then-elif then-else-end。当判断条件的结果为多个值时（迭代器），会对每个值执行一次判断。</p><p>异常处理语句的结构为 try &lt;表达式 a&gt; catch &lt;表达式 b&gt;. 当表达式 a 发生异常时，执行表达式 b，且输入为捕捉到的异常信息。如果不需要额外的处理，只是简单的抑制异常信息的输入，可以没有 catch 语句（如 try .a)。这时，整个表达式可以简写为’&lt;表达式 a&gt;?’(如：.a?)。</p><p>jq 内部还支持函数。在使用 jq 函数时，我们应该注意区分两个概念：输入和参数。输入可能是整个表达式的输入数据也可能是表达式别的部分的输出。而参数和函数一起构成新的 filter 来处理输入。和其他编程语言不同的是，在调用函数时，多个参数之间以分号分隔。jq 通过内置函数提供了数据处理时常用的操作，例如：过滤，映射，路径操作等。</p><h3 id="映射操作"><a href="#映射操作" class="headerlink" title="映射操作"></a>映射操作</h3><p>在数据处理过程中，我们经常需求将数据从一种形式转换成另外一种形式，或者改变数据的值。jq 提供了两个内置映射函数来实现这种转换：map 和 map_values。其中，map 处理的对象是数组，而 map_values 则处理对象属性的值。map 函数的参数为 filter 表达式。在该 filter 表达式中,’.’代表被映射的元素或值。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">输入：[1,2,3,4]</span></span><br><span class="line">jq 表达式：jq -r &#x27;map(.+1)&#x27;</span><br><span class="line"><span class="meta">#</span><span class="bash">输出：[2,3,4,5]</span></span><br></pre></td></tr></table></figure><h3 id="过滤操作"><a href="#过滤操作" class="headerlink" title="过滤操作"></a>过滤操作</h3><p>在 jq 中有两种类型的选择过滤操作。第一种是基于数据类型的过滤，如表达式’.[]|arrays’的结果只包含数组。可以用来过滤的类型过滤器有：arrays, objects, iterables, booleans, numbers, normals, finites, strings, nulls, values, scalars。</p><p>第二种是 select 函数。select 接受一个条件表达式作为参数。其输入可以是迭代器，或者和 map 函数配合使用来处理数组。当输入中的某个元素使 select 参数中的条件表达式结果为真时，则在结果中保留该元素，否则不保留该元素。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">输入：[1,2,3,4]</span></span><br><span class="line">jq -r &#x27;map(select(.&gt;2))&#x27;</span><br><span class="line"><span class="meta">#</span><span class="bash">输出：[3,4]</span></span><br><span class="line">jq -r &#x27;.[]|select(.&gt;2)&#x27;</span><br><span class="line"><span class="meta">#</span><span class="bash">输出：3 4</span></span><br></pre></td></tr></table></figure><h3 id="路径操作"><a href="#路径操作" class="headerlink" title="路径操作"></a>路径操作</h3><p>和 xpath 类似，在 jq 中的 path 也是指从根到某个叶子属性的访问路径。在 jq 中有两种表示路径的方式：数组表示法和属性表示法。属性表示法类似于我们在 filter 中访问某个属性值的方式，如’.a.b’。数组表示法是将路径中的每一部分表示为数组的一个元素。jq 提供了一个内置函数 path 用来实现路径从属性表示法到数组表示法的转换。</p><p>jq 还提供了函数用来读取路径的值(getpath), 设置路径的值(setpath)和删除路径(del)。不过遗憾的是，这三个函数对路径的处理并不一致。其中 getpath 和 setpath 只接受数组表示法的路径，而 del 函数只能正确处理属性表示法的路径。</p><p>jq 还提供了一个函数 paths 用来枚举可能存在的路径。在没有参数的情况下，paths 函数将输出 JSON 数据中所有可能的路径。paths 函数可以接受一个过滤器，来只输出满足条件的路径。</p><h3 id="存在判断函数"><a href="#存在判断函数" class="headerlink" title="存在判断函数"></a>存在判断函数</h3><p>jq 中提供了一系列的函数用来判断某个元素或者属性是否存在于输入数据中。其中函数 has 和 in 用来判断 JSON 对象或数组是否包含特定的属性或索引。函数 contains 和 inside 用来判断参数是否完全包含在输入数据中。对于不同的数据类型，判断是否完全包含的规则不同。对于字符串，如果 A 是 B 的子字符串，则认为 A 完全包含于 B。对于对象类型，如果对象 A 的所有属性在对象 B 中都能找到且值相同，则认为 A 完全包含于 B。</p><h3 id="数组函数"><a href="#数组函数" class="headerlink" title="数组函数"></a>数组函数</h3><p>除了前面讲述的基本操作符外，jq 提供内置函数用于完成数组的扁平化（flatten），反序（reverse），排序(sort, sort_by)，比较（min,min_by,max,max_by)和查找（indices,index 和 rindex)。其中 indices 函数的输入数据可以是数组，也可以是字符串。和 index 函数不同的是，其结果是一个包含所有参数在输入数据中位置的数组，具体请参看下面的例子。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">结果是[1,2,3,4]</span></span><br><span class="line">jq -nr &#x27;[1,[2,3],4]|flatten&#x27;</span><br><span class="line"><span class="meta">#</span><span class="bash">结果是[3,2,1]</span></span><br><span class="line">jq -nr &#x27;[1,2,3]|reverse&#x27;</span><br><span class="line">jq -nr &#x27;[3,1,2]|sort&#x27;</span><br><span class="line">jq -nr &#x27;[&#123;&quot;a&quot;:1&#125;,&#123;&quot;a&quot;:2&#125;]|sort_by(.a)&#x27;</span><br><span class="line"><span class="meta">#</span><span class="bash">下面两个表达式的结果都是[1,3]</span></span><br><span class="line">jq -nr &#x27;&quot;abcb&quot;|indices(&quot;b&quot;)&#x27;</span><br><span class="line">jq -nr &#x27;[1,3,2,3]|indices(3)&#x27;</span><br></pre></td></tr></table></figure><p>jq 还提供了许多其他的内置函数，具体请参考 jq 的在线文档。</p><h2 id="jq-高级特性"><a href="#jq-高级特性" class="headerlink" title="jq 高级特性"></a>jq 高级特性</h2><h3 id="变量"><a href="#变量" class="headerlink" title="变量"></a>变量</h3><p>jq 内部支持两种变量的定义方式。第一种我们在前边 jq 的调用部分讲过，可以通过命令行参数（–arg)定义。这种方式用来从外部（如：shell)传入数据以供 filter 表达式使用。</p><p>第二种方式，在 jq 表达式内部，我们可以自己声明变量用来保存表达式的结果以供表达式其余部分使用。</p><p>jq 中定义变量的语句为: fiterexp as $variablename</p><h3 id="定义和使用变量"><a href="#定义和使用变量" class="headerlink" title="定义和使用变量"></a>定义和使用变量</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">在下面的表达式中变量<span class="variable">$arraylen</span> 用来保存数组长度，整个表达式结果为 4</span></span><br><span class="line">jq -nr &#x27;[1,2,3]|length as $arraylen|$arraylen+1&#x27;</span><br><span class="line"><span class="meta">#</span><span class="bash">可以同时定义多个变量</span></span><br><span class="line">jq -nr &#x27;&#123;&quot;firstname&quot;:&quot;tom&quot;,&quot;lastname&quot;:&quot;clancy&quot;&#125;|. as &#123;firstname:$fn, lastname:$ln&#125;|&quot;author is &quot;+$fn+&quot;*&quot;+$ln&#x27;</span><br></pre></td></tr></table></figure><p>jq 中同样存在变量作用域问题。在 jq 中，有两种方法分隔变量作用域。第一种是用括号包围部分表达式。括号内部的表达式与外部的表达式不在同一个作用域范围内。第二种方法是定义函数。默认情况下，声明的变量对其后的表达式可见。但是，如果变量在特定作用域内声明，则对作用域外部的表达式不可见，例如：</p><h3 id="变量作用域"><a href="#变量作用域" class="headerlink" title="变量作用域"></a>变量作用域</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">会抛出 arraylen 没定义的异常</span></span><br><span class="line">jq -nr &#x27;[1,2,3]|(length as $arraylen|$arraylen)|$arraylen+1&#x27;</span><br><span class="line"><span class="meta"> </span></span><br><span class="line"><span class="meta">#</span><span class="bash">正常执行，结果为 4.</span></span><br><span class="line">jq -nr &#x27;[1,2,3]|(length as $arraylen|$arraylen+1)&#x27;</span><br><span class="line"><span class="meta"> </span></span><br><span class="line"><span class="meta">#</span><span class="bash">函数作用域。该表达式会抛出异常，因为变量<span class="variable">$fn</span> 是在函数 fname 中定义，对最后一个子表达式<span class="comment">##来说，$fn 是不可见的。</span></span></span><br><span class="line">jq -nr &#x27;&#123;&quot;firstname&quot;:&quot;tom&quot;,&quot;lastname&quot;:&quot;clancy&quot;&#125;|def fname:. as &#123;firstname:$fn, lastname:$ln&#125;|$fn; fname|$fn&#x27;</span><br></pre></td></tr></table></figure><h3 id="Reduce"><a href="#Reduce" class="headerlink" title="Reduce"></a>Reduce</h3><p>我们知道 jq 有一种特殊的数据类型：迭代器。通常，有迭代器参与的运算，其结果也是一个迭代器。jq 提供了一些特殊的语法和内置函数用来缩减迭代器运算结果的个数。</p><p>reduce 关键字用来通过运算将迭代器的所有值合并为一个值。其调用形式为：reduce <itexp> as $var (INIT; UPDATE)。其中，表达式 itexp 产生的迭代器被赋值给变量 var, UPDATE 是关于变量 var 的表达式。INIT 是该表达式的初始输入。相对于 itexp 结果中的每个元素，UPDATE 表达式被调用一次，计算出结果用作下一次 UPDATE 调用的输入。</p><h4 id="reduce-关键字"><a href="#reduce-关键字" class="headerlink" title="reduce 关键字"></a>reduce 关键字</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">结果是 6</span></span><br><span class="line">jq -nr &#x27;reduce ([1,2,3]|.[]) as $item (0; .+$item)&#x27;</span><br><span class="line"><span class="meta">#</span><span class="bash">上面的表达式等同于</span></span><br><span class="line">jq -nr &#x27;0 | (3 as $item|.+$item)|(2 as $item | . + $item)|(1 as $item | . + $item)&#x27;</span><br></pre></td></tr></table></figure><p>关键字 foreach 的作用和 reduce 类似。其调用形式为 foreach EXP as $var (INIT; UPDATE; EXTRACT)。和 reduce 关键字不同的是，foreach 关键字的每次迭代是先调用 UPDATE 再调用 EXTRACT，并以一个迭代器保留每一次的中间结果。该迭代器最后作为整个表达式的结果输出。</p><h4 id="foreach-关键字"><a href="#foreach-关键字" class="headerlink" title="foreach 关键字"></a>foreach 关键字</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">下面的表达式，结果是 1 3 6</span></span><br><span class="line">jq -nr &#x27;foreach ([1,2,3]|.[]) as $item (0; .+$item;.)&#x27;</span><br></pre></td></tr></table></figure><p>内置函数 limit(n;exp)用来取得表达式 exp 结果的前 n 个值。</p><p>内置函数 first, last 和 nth。这几个函数用来取迭代器中某一个特定的元素。这几个函数既可以以函数的形式调用，也可以作为子表达式调用。请看下面的示例：</p><h4 id="firs-last-和-nth"><a href="#firs-last-和-nth" class="headerlink" title="firs, last 和 nth"></a>firs, last 和 nth</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">下面的表达式按照函数的形式调用 first,结果为 1</span></span><br><span class="line">jq -nr &#x27;first([1,2,3]|.[])&#x27;</span><br><span class="line"><span class="meta">#</span><span class="bash">下面的表达式以 filter 形式调用 first</span></span><br><span class="line">jq -nr &#x27;[1,2,3]|.[]|first&#x27;</span><br><span class="line"><span class="meta"> </span></span><br><span class="line"><span class="meta">#</span><span class="bash">nth 函数的使用，结果为 2</span></span><br><span class="line">jq -nr &#x27;nth(1;[1,2,3]|.[])&#x27;</span><br></pre></td></tr></table></figure><h3 id="自定义函数和模块化"><a href="#自定义函数和模块化" class="headerlink" title="自定义函数和模块化"></a>自定义函数和模块化</h3><p>作为一个类似于编程语言的表达式系统，jq 也提供了定义函数的能力。其语法规则为：def funcname(arguments) : funcbodyexp; 在定义函数时，需要注意下面几条规则。</p><ul><li>函数名或者参数列表后面应该跟冒号以标志函数体开始。</li><li>如果不需要参数，可以直接把整个参数列表部分省去。</li><li>参数列表中，参数之间以分号(“;”)分隔。</li><li>函数体只能是一个表达式，且表达式需以分号结尾</li><li>如果在表达式内部定义函数，整个子表达式部分不能只包含函数定义，否则 jq 会抛出语法错误</li></ul><p>在很多情况下，函数的参数都是被当作表达式引用的，类似于编程其他语言中的 callback 函数。</p><h4 id="map-函数的源代码"><a href="#map-函数的源代码" class="headerlink" title="map 函数的源代码"></a>map 函数的源代码</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">def map(f): [.[] | f];</span><br><span class="line"><span class="meta">#</span><span class="bash">下面表达式的结果是 20，因为当作参数传入的表达式在函数 foo 中被引用两次</span></span><br><span class="line">5|def foo(f): f|f;foo(.*2)</span><br></pre></td></tr></table></figure><p>如果希望传入的参数只被当作一个简单的值来使用，则需要把参数的值定义为一个同名变量，并按照使用变量的方式引用。</p><h4 id="值参数"><a href="#值参数" class="headerlink" title="值参数"></a>值参数</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">下面表达式结果为 10,传入的表达式<span class="string">&#x27;.*2&#x27;</span>在函数 foo 中首先被求值。</span></span><br><span class="line">5|def foo(f): f as $f|$f|$f;foo(.*2)</span><br><span class="line"><span class="meta">#</span><span class="bash">上面的表达式可以简写为如下形式,注意，引用参数时必须带$。</span></span><br><span class="line">5|def foo($f): $f|$f;foo(.*2)</span><br><span class="line"><span class="meta">#</span><span class="bash">否则等于直接引用参数中的表达式。</span></span><br><span class="line"><span class="meta">#</span><span class="bash">例如下面的表达式结果为 20</span></span><br><span class="line">5|def foo($f): $f|f;foo(.*2)</span><br></pre></td></tr></table></figure><p>函数内部可以定义子函数。利用这个特性我们可以实现递归函数。</p><h4 id="递归函数实现数组求和"><a href="#递归函数实现数组求和" class="headerlink" title="递归函数实现数组求和"></a>递归函数实现数组求和</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">下面表达式的结果是 15</span></span><br><span class="line">jq -nr &#x27;[1,2,3,4,5]|def total: def _t: .|first+(if length&gt;1 then .[1:]|_t else 0 end); _t;total&#x27;</span><br></pre></td></tr></table></figure><p>除了在表达式内部定义函数外，我们可以把自定义函数写在外部文件中形成单独的类库。jq 有一套完整的模块系统来支持自定义类库。</p><p>首先，可以通过命令行参数’-L’来指定 jq 搜索模块时需要搜索的路径。</p><p>其次，在模块内部，可以通过 import 指令和 include 指令来实现互相引用。在引用指令中，有几个特殊的路径前缀需要说明。</p><ul><li>‘～’，表示当前用户的 home 目录</li><li>‘$ORIGIN’表示 jq 命令的可执行文件所在的目录</li><li>‘.’表示当前目录，该前缀只能用在 include 指令中。</li></ul><p>当通过 import 指令引用一个模块 foo/bar 时, jq 会在搜素路径中查找 foo/bar.jq 或者 foo/bar/bar.jq。</p><p>转自：<a href="https://justcode.ikeepstudying.com/2018/02/shell%EF%BC%9A%E6%97%A0%E6%AF%94%E5%BC%BA%E5%A4%A7%E7%9A%84shell%E4%B9%8Bjson%E8%A7%A3%E6%9E%90%E5%B7%A5%E5%85%B7jq-linux%E5%91%BD%E4%BB%A4%E8%A1%8C%E8%A7%A3%E6%9E%90json-jq%E8%A7%A3%E6%9E%90-json/">无比强大的shell之json解析工具jq</a></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;json格式是数据传输过程中一种通用的格式，对于Python而言，由于有多种json包，解析json并不是什么难事。&lt;/p&gt;
&lt;p&gt;在Linux shell中，同样有一种强大的json解析工具——jq。jq没有相关依赖，仅一个二进制文件。&lt;/p&gt;</summary>
    
    
    
    <category term="Linux工具" scheme="http://chengqian90.com/categories/Linux%E5%B7%A5%E5%85%B7/"/>
    
    
    <category term="json" scheme="http://chengqian90.com/tags/json/"/>
    
    <category term="jq" scheme="http://chengqian90.com/tags/jq/"/>
    
  </entry>
  
  <entry>
    <title>Ipmitool工具</title>
    <link href="http://chengqian90.com/Linux%E5%B7%A5%E5%85%B7/IPMI%E4%B9%8BIpmitool%E5%B7%A5%E5%85%B7.html"/>
    <id>http://chengqian90.com/Linux%E5%B7%A5%E5%85%B7/IPMI%E4%B9%8BIpmitool%E5%B7%A5%E5%85%B7.html</id>
    <published>2021-04-02T01:57:52.000Z</published>
    <updated>2022-03-08T16:23:40.433Z</updated>
    
    <content type="html"><![CDATA[<h2 id="IPMI（Intelligent-Platform-Management-Interface）"><a href="#IPMI（Intelligent-Platform-Management-Interface）" class="headerlink" title="IPMI（Intelligent Platform Management Interface）"></a>IPMI（Intelligent Platform Management Interface）</h2><p>智能平台管理接口 (IPMI) 是一种开放标准的硬件管理接口规格，定义了嵌入式管理子系统进行通信的特定方法。IPMI 信息通过基板管理控制器 (BMC)（位于 IPMI 规格的硬件组件上）进行交流。使用低级硬件智能管理而不使用操作系统进行管理，具有两个主要优点： 首先，此配置允许进行带外服务器管理；其次，操作系统不必负担传输系统状态数据的任务。IPMI的核心是一个专用芯片/控制器(叫做服务器处理器或基板管理控制器(BMC))，其并不依赖于服务器的处理器、BIOS或操作系统来工作，可谓非常地独立，是一个单独在系统内运行的无代理管理子系统，</p><p>IPMI功能：</p><p>监控服务器的物理健康特征，如温度、电压、风扇工作状态、电源状态等；</p><p>可以通过串口、Modem以及Lan等远程环境管理服务器系统，如远程开关机；</p><span id="more"></span><h2 id="IPMITOOL"><a href="#IPMITOOL" class="headerlink" title="IPMITOOL"></a>IPMITOOL</h2><p>ipmitool 是一种可用在 linux 系统下的命令行方式的 ipmi 平台管理工具，它支持 ipmi 1.5 规范（最新的规范为 ipmi 2.0），通过它可以实现获取传感器的信息、显示系统日志内容、网络远程开关机等功能。使用：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ipmitool –I open sensor list <span class="comment">#命令可以获取传感器中的各种监测值和该值的监测阈值，包括（CPU温度，电压，风扇转速，电源调制模块温度，电源电压等信息。</span></span><br><span class="line">ipmitool –I open sensor thresh <span class="comment">#设置ID值等于id的监测项的各种限制值。</span></span><br><span class="line">ipmitool –I open chassis status <span class="comment">#查看底盘状态，其中包括了底盘电源信息，底盘工作状态等</span></span><br><span class="line">ipmitool –I open chassis restart_cause <span class="comment">#查看上次系统重启的原因</span></span><br></pre></td></tr></table></figure><p>#远程电源管理</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">ipmitool -I lanplus -H <span class="variable">$oob_ip</span> -U root -P 密码 power off (硬关机，直接切断电源)</span><br><span class="line">ipmitool -I lanplus -H <span class="variable">$oob_ip</span> -U root -P 密码 power soft (软关机，即如同轻按一下开机按钮)</span><br><span class="line">ipmitool -I lanplus -H <span class="variable">$oob_ip</span> -U root -P 密码 power on (硬开机)</span><br><span class="line">ipmitool -I lanplus -H <span class="variable">$oob_ip</span> -U root -P 密码 power reset (硬重启)</span><br><span class="line">ipmitool -I lanplus -H <span class="variable">$oob_ip</span> -U root -P 密码 power status (获取当前电源状态)</span><br><span class="line">ipmitool -I lanplus -H <span class="variable">$oob_ip</span> -U root -P 密码 chassis power cycle</span><br><span class="line">(注意power cycle 和power reset的区别在于前者从掉电到上电有１秒钟的间隔，而后者是很快上电)</span><br></pre></td></tr></table></figure><p>#远程引导（当次生效）</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ipmitool -I lan -H 服务器地址 -U root -P passwd chassis bootdev pxe (网络引导)</span><br><span class="line">ipmitool -I lan -H 服务器地址 -U root -P passwd chassis bootdev disk （硬盘引导）</span><br><span class="line">ipmitool -I lan -H 服务器地址 -U root -P passwd chassis bootdev cdrom （光驱引导）</span><br></pre></td></tr></table></figure><p>#读取系统状态类</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ipmitool sensor list  　<span class="comment">#显示系统所有传感器列表</span></span><br><span class="line">ipmitool fru list　　　<span class="comment">#显示系统所有现场可替代器件的列表</span></span><br><span class="line">ipmitool sdr list　　　<span class="comment">#显示系统所有SDRRepository设备列表　</span></span><br><span class="line">ipmitool  pef list      <span class="comment">#显示系统平台时间过滤的列表</span></span><br></pre></td></tr></table></figure><p>#系统日志类</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">ipmitool sel elist　　　<span class="comment">#显示所有系统事件日志</span></span><br><span class="line">ipmitool sel clear　　　<span class="comment">#删除所有系统时间日志</span></span><br><span class="line">ipmitool sel delete ID     <span class="comment">#删除第ID条SEL</span></span><br><span class="line">ipmitool sel time get     　<span class="comment">#显示当前BMC的时间</span></span><br><span class="line">ipmitool sel time <span class="built_in">set</span>  XXX  <span class="comment">#设置当前BMC的时间</span></span><br></pre></td></tr></table></figure><p>#启动设置类</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ipmitool chassis bootdev bios  <span class="comment">#重启后停在BIOS 菜单</span></span><br><span class="line">ipmitool chassis bootdev pxe　<span class="comment">#重启后从PXE启动</span></span><br></pre></td></tr></table></figure><p>#系统相关的命令</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ipmitool mc info       <span class="comment">#显示BMC版本信息</span></span><br><span class="line">ipmitool bmc reset cold      <span class="comment">#BMC 热启动</span></span><br><span class="line">ipmitool bmc reset warmBMC    <span class="comment">#冷启动</span></span><br></pre></td></tr></table></figure><p>#网络接口相关命令</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">ipmitool lan <span class="built_in">print</span> 1    <span class="comment">#显示channel1的网络配置信息</span></span><br><span class="line">ipmitool lan <span class="built_in">set</span>  1ipaddr 10.32.2.2    <span class="comment">#设置channel1的IP地址</span></span><br><span class="line">ipmitool lan  <span class="built_in">set</span> 1 netmask 255.255.0.0   <span class="comment">#设置channel1的netmask</span></span><br><span class="line">ipmitool lan <span class="built_in">set</span> 4 defgw ipaddr255.255.0.254    <span class="comment">#设置channel4的网关</span></span><br><span class="line">ipmitool lan <span class="built_in">set</span>  2 defgw macaddr  &lt;macaddr&gt;　<span class="comment">#设置channel2的网关mac address</span></span><br><span class="line">ipmitool lan <span class="built_in">set</span> 2 ipsrc dhcp         <span class="comment">#设置channel2的ip 源在DHCP</span></span><br><span class="line">ipmitool lan <span class="built_in">set</span> 3 ipsrc static        <span class="comment">#设置channel2的ip是静态获得的</span></span><br></pre></td></tr></table></figure><p>#通道相关命令</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ipmitool channel info　<span class="comment">#显示系统默认channel</span></span><br><span class="line">ipmitool channel  authcap channel-number privilege 　<span class="comment">#修改通道的优先级别</span></span><br><span class="line">ipmitool channel  getaccess channel-number user-id　<span class="comment">#读取用户在通道上的权限</span></span><br><span class="line">ipmitool channel setacccess channel-number  user-id callin=on ipmi=on link=onprivilege=5   <span class="comment">#设置用户在通道上的权限</span></span><br></pre></td></tr></table></figure><p>#看门狗相关命令</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ipmitool  mc watchdog get　<span class="comment">#读取当前看门狗的设置</span></span><br><span class="line">ipmitool watchdog  off   <span class="comment">#关掉看门狗</span></span><br><span class="line">ipmitool watchdog reset 　<span class="comment">#在最近设置的计数器的基础上重启看门狗</span></span><br></pre></td></tr></table></figure><p>#用户管理相关命令</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">ipmitool user list chan-id   <span class="comment">#显示某通道上的所有用户</span></span><br><span class="line">ipmitool <span class="built_in">set</span> password &lt;user id&gt;[&lt;password&gt;] <span class="comment">#修改某用户的密码</span></span><br><span class="line">ipmitool <span class="built_in">disable</span>      &lt;user id&gt;　　<span class="comment">#禁止掉某用户</span></span><br><span class="line">ipmitool <span class="built_in">enable</span>       &lt;user id&gt;　　<span class="comment">#使能某用户</span></span><br><span class="line">ipmitool priv         &lt;user id&gt; &lt;privilegelevel&gt; [&lt;channel number&gt;]　<span class="comment">#修改某用户在某通道上的权限</span></span><br><span class="line">ipmitool <span class="built_in">test</span>         &lt;user id&gt; &lt;16|20&gt;[&lt;password]&gt;　<span class="comment">#测试用户</span></span><br></pre></td></tr></table></figure><p>转自：<a href="https://blog.51cto.com/bovin/2128475">IPMI之Ipmitool工具</a></p>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;IPMI（Intelligent-Platform-Management-Interface）&quot;&gt;&lt;a href=&quot;#IPMI（Intelligent-Platform-Management-Interface）&quot; class=&quot;headerlink&quot; title=&quot;IPMI（Intelligent Platform Management Interface）&quot;&gt;&lt;/a&gt;IPMI（Intelligent Platform Management Interface）&lt;/h2&gt;&lt;p&gt;智能平台管理接口 (IPMI) 是一种开放标准的硬件管理接口规格，定义了嵌入式管理子系统进行通信的特定方法。IPMI 信息通过基板管理控制器 (BMC)（位于 IPMI 规格的硬件组件上）进行交流。使用低级硬件智能管理而不使用操作系统进行管理，具有两个主要优点： 首先，此配置允许进行带外服务器管理；其次，操作系统不必负担传输系统状态数据的任务。IPMI的核心是一个专用芯片/控制器(叫做服务器处理器或基板管理控制器(BMC))，其并不依赖于服务器的处理器、BIOS或操作系统来工作，可谓非常地独立，是一个单独在系统内运行的无代理管理子系统，&lt;/p&gt;
&lt;p&gt;IPMI功能：&lt;/p&gt;
&lt;p&gt;监控服务器的物理健康特征，如温度、电压、风扇工作状态、电源状态等；&lt;/p&gt;
&lt;p&gt;可以通过串口、Modem以及Lan等远程环境管理服务器系统，如远程开关机；&lt;/p&gt;</summary>
    
    
    
    <category term="Linux工具" scheme="http://chengqian90.com/categories/Linux%E5%B7%A5%E5%85%B7/"/>
    
    
    <category term="Ipmitool" scheme="http://chengqian90.com/tags/Ipmitool/"/>
    
    <category term="ipmi" scheme="http://chengqian90.com/tags/ipmi/"/>
    
  </entry>
  
  <entry>
    <title>Linux shell 多进程并发</title>
    <link href="http://chengqian90.com/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Linux%20shell%20%E5%A4%9A%E8%BF%9B%E7%A8%8B%E5%B9%B6%E5%8F%91.html"/>
    <id>http://chengqian90.com/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Linux%20shell%20%E5%A4%9A%E8%BF%9B%E7%A8%8B%E5%B9%B6%E5%8F%91.html</id>
    <published>2021-03-24T03:24:08.000Z</published>
    <updated>2022-03-08T16:23:40.436Z</updated>
    
    <content type="html"><![CDATA[<p>在实际编码中，要减少执行串行循环的耗时，自然要考虑如何用并行方式解决。</p><p>在bash中，使用后台任务来实现任务的“多进程化”。在不加控制的模式下，不管有多少任务，全部都后台执行。</p><span id="more"></span><h2 id="普通脚本"><a href="#普通脚本" class="headerlink" title="普通脚本"></a>普通脚本</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">!/bin/bash</span></span><br><span class="line"></span><br><span class="line">for ip in 10.227.49.&#123;1..254&#125;</span><br><span class="line">do</span><br><span class="line">    sleep 1</span><br><span class="line">    ping $ip -c 1 -w 1 &amp;&gt;/dev/null;</span><br><span class="line">    if [ $? -eq 0 ]; then</span><br><span class="line">        echo $ip is alive</span><br><span class="line">    fi</span><br><span class="line">done</span><br></pre></td></tr></table></figure><p>执行结果如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> time bash single_process.sh</span></span><br><span class="line">10.227.49.1 is alive</span><br><span class="line">10.227.49.11 is alive</span><br><span class="line">10.227.49.12 is alive</span><br><span class="line">10.227.49.13 is alive</span><br><span class="line">10.227.49.14 is alive</span><br><span class="line">10.227.49.15 is alive</span><br><span class="line">10.227.49.16 is alive</span><br><span class="line">10.227.49.17 is alive</span><br><span class="line">………………………………………………………</span><br><span class="line">………………………………………………………</span><br><span class="line">10.227.49.164 is alive</span><br><span class="line">10.227.49.165 is alive</span><br><span class="line">10.227.49.166 is alive</span><br><span class="line">10.227.49.167 is alive</span><br><span class="line">10.227.49.168 is alive</span><br><span class="line">10.227.49.169 is alive</span><br><span class="line">10.227.49.193 is alive</span><br><span class="line"></span><br><span class="line">real7m11.429s</span><br><span class="line">user0m0.191s</span><br><span class="line">sys0m0.241s</span><br></pre></td></tr></table></figure><p>此脚本执行时间为 7m11.429s，按照顺序依次执行。</p><h2 id="简单多并发"><a href="#简单多并发" class="headerlink" title="简单多并发"></a>简单多并发</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">!/bin/bash</span></span><br><span class="line"></span><br><span class="line">for ip in 10.227.49.&#123;1..254&#125;</span><br><span class="line">do</span><br><span class="line">&#123;</span><br><span class="line">    sleep 1</span><br><span class="line">    ping $ip -c 1 -w 1 &amp;&gt;/dev/null;</span><br><span class="line">    if [ $? -eq 0 ]; then</span><br><span class="line">        echo $ip is alive</span><br><span class="line">    fi</span><br><span class="line">&#125; &amp;</span><br><span class="line"></span><br><span class="line">done</span><br><span class="line">wait</span><br><span class="line">echo &quot;all of finished...&quot;</span><br></pre></td></tr></table></figure><p>执行看结果</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"># time bash mul_process.sh</span><br><span class="line">10.227.49.1 is alive</span><br><span class="line">10.227.49.13 is alive</span><br><span class="line">10.227.49.11 is alive</span><br><span class="line">10.227.49.12 is alive</span><br><span class="line">10.227.49.15 is alive</span><br><span class="line">10.227.49.14 is alive</span><br><span class="line">10.227.49.16 is alive</span><br><span class="line">10.227.49.17 is alive</span><br><span class="line">………………………………………………………</span><br><span class="line">………………………………………………………</span><br><span class="line">10.227.49.166 is alive</span><br><span class="line">10.227.49.168 is alive</span><br><span class="line">10.227.49.164 is alive</span><br><span class="line">10.227.49.169 is alive</span><br><span class="line">10.227.49.165 is alive</span><br><span class="line">10.227.49.167 is alive</span><br><span class="line">10.227.49.193 is alive</span><br><span class="line"></span><br><span class="line">real1.5s</span><br><span class="line">user0m0.122s</span><br><span class="line">sys0m0.113s</span><br></pre></td></tr></table></figure><p>可以看到，实际执行时间大大缩短，且乱序执行。</p><p><code>wait</code>是等待前面所有后台程序执行完毕，可以去掉<code>wait</code>试一下（脚本退出，但是依旧在输出）。</p><p>一般在脚本中，可以把<code>&#123;&#125;</code>内的逻辑放到一个函数中。</p><h2 id="并发数量"><a href="#并发数量" class="headerlink" title="并发数量"></a>并发数量</h2><p>无数量限制地执行多进程，可能会把物理资源全部占用，因此，最好的方式是控制脚本执行的后台进程个数。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">!/bin/bash</span></span><br><span class="line">                              //*感兴趣的请自行百度&quot;文件描述符&quot;和&quot;管道文件&quot;,这里不做解释</span><br><span class="line">fifo_file=/tmp/$$_fifofile    //*定义管道文件路径</span><br><span class="line">mkfifo $fifo_file             //*创建管道文件</span><br><span class="line">exec 54&lt;&gt; $fifo_file          //*打开这个管道文件</span><br><span class="line">rm -rf $fifo_file             //*删除这个管道文件</span><br><span class="line"></span><br><span class="line">for i in &#123;1..10&#125;              //*并发的数量10个,&quot;seq 1 10&quot;等同于&quot;&#123;1..10&#125;&quot;,前者可以使用变量赋值</span><br><span class="line">  do</span><br><span class="line">    echo &gt;&amp;54                 //*向管道文件里丢数据</span><br><span class="line">  done</span><br><span class="line"></span><br><span class="line">for i in &#123;1..65535&#125;           //*定义任务数量</span><br><span class="line">  do</span><br><span class="line">    read -u 54                //*从管道文件里读取文件,读取到内容就向下走,读取不到就停留等待</span><br><span class="line">    &#123;</span><br><span class="line">      tcping -t1 118.25.100.250 $i</span><br><span class="line">    &#125;&amp;</span><br><span class="line">    echo &gt;&amp;54                 //*由于管道文件的数据拿一个少一个,所以我们要把数据再还给管道文件</span><br><span class="line">  done</span><br><span class="line">wait                          //*等待所有后台任务执行完毕</span><br><span class="line">exec 54&lt;&amp;-                    //*释放之前被删除的管道文件</span><br><span class="line">echo &quot;all of finished...&quot;</span><br></pre></td></tr></table></figure><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p><a href="https://linux-sh.cn/archives/319/">shell脚本实现多进程并发</a></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;在实际编码中，要减少执行串行循环的耗时，自然要考虑如何用并行方式解决。&lt;/p&gt;
&lt;p&gt;在bash中，使用后台任务来实现任务的“多进程化”。在不加控制的模式下，不管有多少任务，全部都后台执行。&lt;/p&gt;</summary>
    
    
    
    <category term="Linux" scheme="http://chengqian90.com/categories/Linux/"/>
    
    
    <category term="shell" scheme="http://chengqian90.com/tags/shell/"/>
    
    <category term="多进程" scheme="http://chengqian90.com/tags/%E5%A4%9A%E8%BF%9B%E7%A8%8B/"/>
    
  </entry>
  
  <entry>
    <title>Linux shell Array详解</title>
    <link href="http://chengqian90.com/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Linux%20shell%20Array%E8%AF%A6%E8%A7%A3.html"/>
    <id>http://chengqian90.com/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Linux%20shell%20Array%E8%AF%A6%E8%A7%A3.html</id>
    <published>2021-03-19T03:24:08.000Z</published>
    <updated>2022-03-08T16:23:40.436Z</updated>
    
    <content type="html"><![CDATA[<h2 id="声明"><a href="#声明" class="headerlink" title="声明"></a>声明</h2><p>数组中可以存放多个值。Bash Shell 只支持一维数组（不支持多维数组），初始化时不需要定义数组大小。</p><span id="more"></span><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">array_name=(value1 value2 ... valuen)</span><br></pre></td></tr></table></figure><p><strong>实例</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">my_array=(&quot;A&quot; &quot;B&quot; &quot;C&quot; &quot;D&quot;)</span><br><span class="line">my_array[0]=&#x27;value0&#x27;</span><br></pre></td></tr></table></figure><h2 id="使用方式"><a href="#使用方式" class="headerlink" title="使用方式"></a>使用方式</h2><h3 id="输出所有的value、长度"><a href="#输出所有的value、长度" class="headerlink" title="输出所有的value、长度"></a><strong>输出所有的value、长度</strong></h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">1）输出下标</span></span><br><span class="line">echo $&#123;!myarray[@]&#125;</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash">1）输出所有value</span></span><br><span class="line">echo $&#123;my_array[@]&#125;</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash">2）输出array长度</span></span><br><span class="line">echo $&#123;#my_array[@]&#125;</span><br><span class="line">或者</span><br><span class="line">echo $&#123;#my_array[*]&#125; </span><br></pre></td></tr></table></figure><h3 id="遍历"><a href="#遍历" class="headerlink" title="遍历"></a><strong>遍历</strong></h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">for var in $&#123;my_array[@]&#125; </span><br><span class="line">do</span><br><span class="line">   echo &quot;打印的内容：&quot;$var </span><br><span class="line">done</span><br></pre></td></tr></table></figure><p>若a=(1 2 3 4)表示所有元素，则其只能用${a[*]}或者${a[@]}来表示。在a=(1 2 3 4)中，$a只是表示第一个元素1。</p><p>若a=”1 2 3 4”表示所有元素，则其可以用${a[*]}或者${a[@]}或者$a来表示。</p><h3 id="字符串转为数组"><a href="#字符串转为数组" class="headerlink" title="字符串转为数组"></a>字符串转为数组</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">IFS=&#x27;, &#x27; read -r -a array &lt;&lt;&lt; &quot;$string&quot;</span><br><span class="line">echo $&#123;array[@]&#125;</span><br></pre></td></tr></table></figure><p>‘string’以逗号作为分隔形成数组。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p><a href="https://blog.csdn.net/h106140873/article/details/97234808">Linux Shell Array的用法</a> </p>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;声明&quot;&gt;&lt;a href=&quot;#声明&quot; class=&quot;headerlink&quot; title=&quot;声明&quot;&gt;&lt;/a&gt;声明&lt;/h2&gt;&lt;p&gt;数组中可以存放多个值。Bash Shell 只支持一维数组（不支持多维数组），初始化时不需要定义数组大小。&lt;/p&gt;</summary>
    
    
    
    <category term="Linux" scheme="http://chengqian90.com/categories/Linux/"/>
    
    
    <category term="array" scheme="http://chengqian90.com/tags/array/"/>
    
    <category term="shell" scheme="http://chengqian90.com/tags/shell/"/>
    
  </entry>
  
  <entry>
    <title>Linux shell Map详解</title>
    <link href="http://chengqian90.com/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Linux%20shell%20Map%E8%AF%A6%E8%A7%A3.html"/>
    <id>http://chengqian90.com/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Linux%20shell%20Map%E8%AF%A6%E8%A7%A3.html</id>
    <published>2021-03-19T03:24:08.000Z</published>
    <updated>2022-03-08T16:23:40.436Z</updated>
    
    <content type="html"><![CDATA[<h2 id="声明"><a href="#声明" class="headerlink" title="声明"></a>声明</h2><p>在使用map时，需要先声明，否则结果可能与预期不同，array可以不声明。</p><span id="more"></span><p><strong>方式1</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">declare -A myMap</span><br><span class="line">myMap[&quot;my03&quot;]=&quot;03&quot;</span><br></pre></td></tr></table></figure><p><strong>方式2</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">declare -A myMap=([&quot;my01&quot;]=&quot;01&quot; [&quot;my02&quot;]=&quot;02&quot;)</span><br></pre></td></tr></table></figure><h2 id="初始化"><a href="#初始化" class="headerlink" title="初始化"></a>初始化</h2><p>与array类似，可以使用括号直接初始化，也可以通过添加的方式来初始化数据，与array不同的是，括号直接初始化时使用的为一个键值对，添加元素时，下标可以不是整数。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">myMap[&quot;my03&quot;]=&quot;03&quot;</span><br><span class="line">myMap[&quot;my04&quot;]=&quot;04&quot;</span><br></pre></td></tr></table></figure><p><strong>删除</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">d_key=&#x27;my03&#x27;</span><br><span class="line">unset mymap[$d_key]</span><br></pre></td></tr></table></figure><h2 id="使用方式"><a href="#使用方式" class="headerlink" title="使用方式"></a>使用方式</h2><p><strong>输出所有的key、value、长度</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 1）输出所有的key</span></span><br><span class="line"><span class="meta">#</span><span class="bash">若未使用<span class="built_in">declare</span>声明map，则此处将输出0，与预期输出不符，此处输出语句格式比arry多了一个！</span></span><br><span class="line">echo $&#123;!myMap[@]&#125;</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash">2）输出所有value</span></span><br><span class="line"><span class="meta">#</span><span class="bash">与array输出格式相同</span></span><br><span class="line">echo $&#123;myMap[@]&#125;</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash">3）输出map长度</span></span><br><span class="line"><span class="meta">#</span><span class="bash">与array输出格式相同</span></span><br><span class="line">echo $&#123;#myMap[@]&#125;</span><br></pre></td></tr></table></figure><p><strong>遍历</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">1)遍历，根据key找到对应的value</span></span><br><span class="line">for key in $&#123;!myMap[*]&#125;;do</span><br><span class="line"> echo $key</span><br><span class="line"> echo $&#123;myMap[$key]&#125;</span><br><span class="line">done</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash">2)遍历所有的key</span></span><br><span class="line">for key in $&#123;!myMap[@]&#125;;do</span><br><span class="line"> echo $key</span><br><span class="line"> echo $&#123;myMap[$key]&#125;</span><br><span class="line">done</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash">3)遍历所有的value</span></span><br><span class="line">for val in $&#123;myMap[@]&#125;;do</span><br><span class="line"> echo $val</span><br><span class="line">done</span><br></pre></td></tr></table></figure><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p><a href="https://www.jb51.net/article/186118.htm">Linux Shell Map的用法详解</a></p>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;声明&quot;&gt;&lt;a href=&quot;#声明&quot; class=&quot;headerlink&quot; title=&quot;声明&quot;&gt;&lt;/a&gt;声明&lt;/h2&gt;&lt;p&gt;在使用map时，需要先声明，否则结果可能与预期不同，array可以不声明。&lt;/p&gt;</summary>
    
    
    
    <category term="Linux" scheme="http://chengqian90.com/categories/Linux/"/>
    
    
    <category term="shell" scheme="http://chengqian90.com/tags/shell/"/>
    
    <category term="map" scheme="http://chengqian90.com/tags/map/"/>
    
  </entry>
  
  <entry>
    <title>Centos更换yum源为163源</title>
    <link href="http://chengqian90.com/%E6%9D%82%E8%B0%88/Centos%E6%9B%B4%E6%8D%A2yum%E6%BA%90%E4%B8%BA163%E6%BA%90.html"/>
    <id>http://chengqian90.com/%E6%9D%82%E8%B0%88/Centos%E6%9B%B4%E6%8D%A2yum%E6%BA%90%E4%B8%BA163%E6%BA%90.html</id>
    <published>2021-03-15T03:57:52.000Z</published>
    <updated>2022-03-08T16:23:40.435Z</updated>
    
    <content type="html"><![CDATA[<p>此教程适用如下架构</p><ul><li>i386</li><li>x86_64</li><li>SRPMS</li></ul><p><strong>使用说明</strong></p><p>首先备份/etc/yum.repos.d/CentOS-Base.repo</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.backup</span><br></pre></td></tr></table></figure><p>不同的系统下载不同的yum源</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">// centos7</span><br><span class="line">wget http://mirrors.163.com/.help/CentOS7-Base-163.repo</span><br><span class="line"></span><br><span class="line">// centos6</span><br><span class="line">wget http://mirrors.163.com/.help/CentOS6-Base-163.repo</span><br><span class="line"></span><br><span class="line">// centos5</span><br><span class="line">wget http://mirrors.163.com/.help/CentOS5-Base-163.repo</span><br></pre></td></tr></table></figure><p>生成缓存</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">yum clean all</span><br><span class="line">yum makecache</span><br></pre></td></tr></table></figure><p><strong>参考</strong></p><p><a href="http://mirrors.163.com/.help/centos.html">CentOS镜像使用帮助</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;此教程适用如下架构&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;i386&lt;/li&gt;
&lt;li&gt;x86_64&lt;/li&gt;
&lt;li&gt;SRPMS&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;使用说明&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;首先备份/etc/yum.repos.d/CentOS-Base.re</summary>
      
    
    
    
    <category term="杂谈" scheme="http://chengqian90.com/categories/%E6%9D%82%E8%B0%88/"/>
    
    
    <category term="Centos" scheme="http://chengqian90.com/tags/Centos/"/>
    
    <category term="yum" scheme="http://chengqian90.com/tags/yum/"/>
    
  </entry>
  
  <entry>
    <title>Linux 进度条实现原理</title>
    <link href="http://chengqian90.com/%E6%9D%82%E8%B0%88/Linux%E8%BF%9B%E5%BA%A6%E6%9D%A1%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86.html"/>
    <id>http://chengqian90.com/%E6%9D%82%E8%B0%88/Linux%E8%BF%9B%E5%BA%A6%E6%9D%A1%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86.html</id>
    <published>2021-03-03T08:31:52.000Z</published>
    <updated>2021-03-03T09:18:36.000Z</updated>
    
    <content type="html"><![CDATA[<p>进度条的的动态增长是利用人的视觉短暂停留效果的，<strong>不断从输出缓冲区刷新出相同的内容</strong>，在肉眼看来进度条在不断的增长。</p><span id="more"></span><h2 id="缓冲区"><a href="#缓冲区" class="headerlink" title="缓冲区"></a>缓冲区</h2><p>linux下的每一个进程会维护一个print/scanf的缓冲区，缓冲区有一个概念叫做缓冲方式，就是说达到一定的方式，缓冲区的内容才会被刷新。</p><p>标准C库函数常见的三种缓冲方式：</p><ol><li>行缓冲：遇到”\n”,就会刷新缓冲区</li><li>全缓冲：把缓冲区写满，再进行刷新缓冲区</li><li>无缓冲：系统调用函数无缓冲区（如：write）</li></ol><p><strong>默认情况下，一般采用行缓冲模式</strong>。<br>当程序退出时缓冲区自动刷新，所以，为了每次打印每行的内容，需要利用fflush()函数来进行强制刷新缓冲区。</p><h2 id="带颜色的printf-fprintf打印"><a href="#带颜色的printf-fprintf打印" class="headerlink" title="带颜色的printf/fprintf打印"></a>带颜色的printf/fprintf打印</h2><p>终端的字符颜色由<strong>转义序列</strong>(Escape Sequence)控制，是文本模式下的系统显示功能，<strong>与具体语言无关</strong>。</p><p>转义序列以控制字符’ESC’开头，该字符的ASCII码十进制表示为27，十六进制表示为0x1B，<strong>八进制表示为033</strong>。多数转义序列超过两个字符，故通常以’ESC’和左括号’[‘开头。该起始序列称为<strong>控制序列引导符</strong>(CSI，Control Sequence Intro)，通常由’<strong>\033[</strong>‘或’<strong>\e[</strong>‘代替。</p><p>通过转义序列设置终端显示属性时，可采用以下格式：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">\033[ Param &#123;;Param;...&#125;m</span><br><span class="line">或</span><br><span class="line">\e[ Param &#123;;Param;...&#125;m</span><br></pre></td></tr></table></figure><p>‘\033[‘或’\e[‘引导转义序列，’m’表示设置属性并结束转义序列。</p><p>Param为属性值，{…}表示可选(多个参数之间用分号隔开，与顺序无关)。</p><p>例如：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> <span class="built_in">echo</span> -e <span class="string">&quot;\e[31;47m test colour . \e[0m&quot;</span></span></span><br></pre></td></tr></table></figure><p>即设置输出为红色字体(31)，白色背景(47)。选项’-e’为echo命令<strong>激活特殊字符的解析器</strong>。</p><p><strong>注意，转义序列可被控制字符’CAN’(Cancel )和’SUB’(Substitute)中断。</strong></p><p>转义序列相关的常用参数如下(通过<code>man console_codes</code>命令可查看更多的参数描述)：</p><table><thead><tr><th>类别</th><th>颜色</th></tr></thead><tbody><tr><td>显示方式</td><td>0（默认值）、1（高亮）、22（非粗体）、4（下划线）、24（非下划线）、5（闪烁）、25（非闪烁）、7（反显）、27（非反显）</td></tr><tr><td>前景色</td><td>30（黑色）、31（红色）、32（绿色）、 33（黄色）、34（蓝色）、35（洋红）、36（青色）、37（白色）</td></tr><tr><td>背景色</td><td>40（黑色）、41（红色）、42（绿色）、 43（黄色）、44（蓝色）、45（洋红）、46（青色）、47（白色）</td></tr></tbody></table><p>颜色：0(黑)、1(红)、2(绿)、 3(黄)、4(蓝)、5(洋红)、6(青)、7(白)</p><p>前景色为30+颜色值，如31表示前景色为红色；背景色为40+颜色值，如41表示背景色为红色。</p><p>因此，通过转义序列设置终端显示属性时，常见格式为：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">\033[显示方式;前景色;背景色m输出字符串\033[0m</span><br><span class="line">或</span><br><span class="line">\e[显示方式;前景色;背景色m输出字符串\033[0m</span><br></pre></td></tr></table></figure><p>   其中 ，’\033[0m’用于恢复默认的终端输出属性，否则会影响后续的输出。</p><h2 id="实现方式"><a href="#实现方式" class="headerlink" title="实现方式"></a>实现方式</h2><h3 id="C语言实现"><a href="#C语言实现" class="headerlink" title="C语言实现"></a>C语言实现</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;unistd.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">char</span> buf[<span class="number">102</span>]=&#123;<span class="number">0</span>&#125;;<span class="comment">//101个数字+&#x27;\0&#x27;</span></span><br><span class="line">    <span class="keyword">char</span> *str=<span class="string">&quot;-\|/&quot;</span>;</span><br><span class="line">    <span class="keyword">int</span> i=<span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span>(;i&lt;=<span class="number">100</span>;++i)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;\033[034m[%-100s],[%d%%],[%c]\033[0m\r&quot;</span>,buf,i,str[i%<span class="number">4</span>]);</span><br><span class="line"></span><br><span class="line">        fflush(<span class="built_in">stdout</span>);</span><br><span class="line">        usleep(<span class="number">20000</span>);</span><br><span class="line">        buf[i]=<span class="string">&#x27;#&#x27;</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;\n&quot;</span>);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="SHELLE实现"><a href="#SHELLE实现" class="headerlink" title="SHELLE实现"></a>SHELLE实现</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">!/bin/bash</span></span><br><span class="line"></span><br><span class="line">i=0</span><br><span class="line">b=&quot;&quot;</span><br><span class="line">array=(&#x27;-&#x27; &#x27;\\&#x27; &#x27;|&#x27; &#x27;/&#x27;)</span><br><span class="line"></span><br><span class="line">while [ $i -le 100 ]</span><br><span class="line">do</span><br><span class="line">    let idx=i%4</span><br><span class="line">    printf &quot;\e[31m\033[40m[%-100s]\e[32m\033[47m [%d%%] \e[30m \033[47m [%c] \e[0m\r&quot; &quot;$b&quot; &quot;$i&quot; &quot;$&#123;array[$idx]&#125;&quot;</span><br><span class="line">    b+=&#x27;#&#x27;</span><br><span class="line">    usleep 200000</span><br><span class="line">    let i++</span><br><span class="line">done</span><br></pre></td></tr></table></figure><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://www.cnblogs.com/clover-toeic/p/4031618.html">通过printf设置Linux终端输出的颜色和显示方式</a></p><p><a href="https://blog.csdn.net/qq_37964547/article/details/80959530">用shell脚本实现彩色进度条</a></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;进度条的的动态增长是利用人的视觉短暂停留效果的，&lt;strong&gt;不断从输出缓冲区刷新出相同的内容&lt;/strong&gt;，在肉眼看来进度条在不断的增长。&lt;/p&gt;</summary>
    
    
    
    <category term="杂谈" scheme="http://chengqian90.com/categories/%E6%9D%82%E8%B0%88/"/>
    
    
    <category term="进度条" scheme="http://chengqian90.com/tags/%E8%BF%9B%E5%BA%A6%E6%9D%A1/"/>
    
    <category term="Linux" scheme="http://chengqian90.com/tags/Linux/"/>
    
  </entry>
  
  <entry>
    <title>解决github clone过慢的问题</title>
    <link href="http://chengqian90.com/%E6%9D%82%E8%B0%88/%E8%A7%A3%E5%86%B3github%20clone%E8%BF%87%E6%85%A2%E7%9A%84%E9%97%AE%E9%A2%98.html"/>
    <id>http://chengqian90.com/%E6%9D%82%E8%B0%88/%E8%A7%A3%E5%86%B3github%20clone%E8%BF%87%E6%85%A2%E7%9A%84%E9%97%AE%E9%A2%98.html</id>
    <published>2021-03-02T01:57:52.000Z</published>
    <updated>2021-03-03T07:58:30.000Z</updated>
    
    <content type="html"><![CDATA[<p>文件解决访问github过慢、clone github库过慢的问题</p><span id="more"></span><p>访问时，将<code>github.com</code>替换为<code>github.com.cnpmjs.com</code>。</p><p>clone github库时，使用同样的方式，</p><p>例如</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git clone https://github.com.cnpmjs.org/LiuChengqian90/LiuChengqian90.github.io.git</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">&lt;p&gt;文件解决访问github过慢、clone github库过慢的问题&lt;/p&gt;</summary>
    
    
    
    <category term="杂谈" scheme="http://chengqian90.com/categories/%E6%9D%82%E8%B0%88/"/>
    
    
    <category term="GitHub" scheme="http://chengqian90.com/tags/GitHub/"/>
    
    <category term="clone" scheme="http://chengqian90.com/tags/clone/"/>
    
  </entry>
  
  <entry>
    <title>已被macOS使用，不能打开—解决方法</title>
    <link href="http://chengqian90.com/%E6%9D%82%E8%B0%88/macOS%E5%8D%A0%E7%94%A8.html"/>
    <id>http://chengqian90.com/%E6%9D%82%E8%B0%88/macOS%E5%8D%A0%E7%94%A8.html</id>
    <published>2021-01-11T01:57:52.000Z</published>
    <updated>2021-03-02T12:17:05.000Z</updated>
    
    <content type="html"><![CDATA[<p>macOS 里往 NTFS 格式的移动硬盘拷贝文件，打开时有可能会出现 ”已被macOS使用，不能打开“的问题。</p><span id="more"></span><p>利用SHELL “ls -al” 查看文件发现有”@”标志（带有扩展属性）</p><p>利用 xattr 命令(<code>xattr -l $filename</code>)查看扩展属性 ，确认是否有 ”com.apple.FinderInfo“ 属性，其内容为 ”brokMACS“。有的话，利用xattr删除即可，<code>xattr -d $filename</code>。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;macOS 里往 NTFS 格式的移动硬盘拷贝文件，打开时有可能会出现 ”已被macOS使用，不能打开“的问题。&lt;/p&gt;</summary>
    
    
    
    <category term="杂谈" scheme="http://chengqian90.com/categories/%E6%9D%82%E8%B0%88/"/>
    
    
    <category term="MAC" scheme="http://chengqian90.com/tags/MAC/"/>
    
  </entry>
  
  <entry>
    <title>nsenter命令</title>
    <link href="http://chengqian90.com/Linux%E5%B7%A5%E5%85%B7/nsenter%E5%91%BD%E4%BB%A4.html"/>
    <id>http://chengqian90.com/Linux%E5%B7%A5%E5%85%B7/nsenter%E5%91%BD%E4%BB%A4.html</id>
    <published>2021-01-04T01:57:52.000Z</published>
    <updated>2021-03-02T12:17:05.000Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://man7.org/linux/man-pages/man1/nsenter.1.html">nsenter</a>命令是一个可以在指定进程的命令空间下运行指定程序的命令，它位于util-linux包中。</p><p>一般可以用于在容器外 debug 容器中运行的程序。</p><span id="more"></span><p>其命令行格式</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">nsenter [options] [program [arguments]]</span><br><span class="line"></span><br><span class="line">options:</span><br><span class="line">-t, --target pid：指定被进入命名空间的目标进程的pid</span><br><span class="line">-m, --mount[=file]：进入mount命令空间。如果指定了file，则进入file的命令空间</span><br><span class="line">-u, --uts[=file]：进入uts命令空间。如果指定了file，则进入file的命令空间</span><br><span class="line">-i, --ipc[=file]：进入ipc命令空间。如果指定了file，则进入file的命令空间</span><br><span class="line">-n, --net[=file]：进入net命令空间。如果指定了file，则进入file的命令空间</span><br><span class="line">-p, --pid[=file]：进入pid命令空间。如果指定了file，则进入file的命令空间</span><br><span class="line">-U, --user[=file]：进入user命令空间。如果指定了file，则进入file的命令空间</span><br><span class="line">-G, --setgid gid：设置运行程序的gid</span><br><span class="line">-S, --setuid uid：设置运行程序的uid</span><br><span class="line">-r, --root[=directory]：设置根目录</span><br><span class="line">-w, --wd[=directory]：设置工作目录</span><br><span class="line"></span><br><span class="line">如果没有给出program，则默认执行$SHELL。</span><br></pre></td></tr></table></figure><p>查询容器的PID</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> docker inspect --format &#123;&#123;.State.Pid&#125;&#125; &lt;container_name_or_ID&gt;</span></span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> nsenter -m -u -i -n -p -t <span class="variable">$PID</span> hostname</span></span><br></pre></td></tr></table></figure><p>或者可以直接进入容器network ns，例如</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> nsenter --net=/var/run/docker/netns/1-7fe9ew67wh ip a</span></span><br></pre></td></tr></table></figure><p>其原理基本就是<a href="http://chengqian90.com/Linux%E5%86%85%E6%A0%B8/Linux-Namespace%E7%AE%80%E4%BB%8B.html">Linux Namespace</a>。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;&lt;a href=&quot;https://man7.org/linux/man-pages/man1/nsenter.1.html&quot;&gt;nsenter&lt;/a&gt;命令是一个可以在指定进程的命令空间下运行指定程序的命令，它位于util-linux包中。&lt;/p&gt;
&lt;p&gt;一般可以用于在容器外 debug 容器中运行的程序。&lt;/p&gt;</summary>
    
    
    
    <category term="Linux工具" scheme="http://chengqian90.com/categories/Linux%E5%B7%A5%E5%85%B7/"/>
    
    
    <category term="nsenter" scheme="http://chengqian90.com/tags/nsenter/"/>
    
  </entry>
  
</feed>
